{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Performance of Sparse Recovery Using L1 Minimization\n",
    "====================================================\n",
    "\n",
    "*Important:* Please read the [installation page](http://gpeyre.github.io/numerical-tours/installation_python/) for details about how to install the toolboxes.\n",
    "$\\newcommand{\\dotp}[2]{\\langle #1, #2 \\rangle}$\n",
    "$\\newcommand{\\enscond}[2]{\\lbrace #1, #2 \\rbrace}$\n",
    "$\\newcommand{\\pd}[2]{ \\frac{ \\partial #1}{\\partial #2} }$\n",
    "$\\newcommand{\\umin}[1]{\\underset{#1}{\\min}\\;}$\n",
    "$\\newcommand{\\umax}[1]{\\underset{#1}{\\max}\\;}$\n",
    "$\\newcommand{\\umin}[1]{\\underset{#1}{\\min}\\;}$\n",
    "$\\newcommand{\\uargmin}[1]{\\underset{#1}{argmin}\\;}$\n",
    "$\\newcommand{\\norm}[1]{\\|#1\\|}$\n",
    "$\\newcommand{\\abs}[1]{\\left|#1\\right|}$\n",
    "$\\newcommand{\\choice}[1]{ \\left\\{  \\begin{array}{l} #1 \\end{array} \\right. }$\n",
    "$\\newcommand{\\pa}[1]{\\left(#1\\right)}$\n",
    "$\\newcommand{\\diag}[1]{{diag}\\left( #1 \\right)}$\n",
    "$\\newcommand{\\qandq}{\\quad\\text{and}\\quad}$\n",
    "$\\newcommand{\\qwhereq}{\\quad\\text{where}\\quad}$\n",
    "$\\newcommand{\\qifq}{ \\quad \\text{if} \\quad }$\n",
    "$\\newcommand{\\qarrq}{ \\quad \\Longrightarrow \\quad }$\n",
    "$\\newcommand{\\ZZ}{\\mathbb{Z}}$\n",
    "$\\newcommand{\\CC}{\\mathbb{C}}$\n",
    "$\\newcommand{\\RR}{\\mathbb{R}}$\n",
    "$\\newcommand{\\EE}{\\mathbb{E}}$\n",
    "$\\newcommand{\\Zz}{\\mathcal{Z}}$\n",
    "$\\newcommand{\\Ww}{\\mathcal{W}}$\n",
    "$\\newcommand{\\Vv}{\\mathcal{V}}$\n",
    "$\\newcommand{\\Nn}{\\mathcal{N}}$\n",
    "$\\newcommand{\\NN}{\\mathcal{N}}$\n",
    "$\\newcommand{\\Hh}{\\mathcal{H}}$\n",
    "$\\newcommand{\\Bb}{\\mathcal{B}}$\n",
    "$\\newcommand{\\Ee}{\\mathcal{E}}$\n",
    "$\\newcommand{\\Cc}{\\mathcal{C}}$\n",
    "$\\newcommand{\\Gg}{\\mathcal{G}}$\n",
    "$\\newcommand{\\Ss}{\\mathcal{S}}$\n",
    "$\\newcommand{\\Pp}{\\mathcal{P}}$\n",
    "$\\newcommand{\\Ff}{\\mathcal{F}}$\n",
    "$\\newcommand{\\Xx}{\\mathcal{X}}$\n",
    "$\\newcommand{\\Mm}{\\mathcal{M}}$\n",
    "$\\newcommand{\\Ii}{\\mathcal{I}}$\n",
    "$\\newcommand{\\Dd}{\\mathcal{D}}$\n",
    "$\\newcommand{\\Ll}{\\mathcal{L}}$\n",
    "$\\newcommand{\\Tt}{\\mathcal{T}}$\n",
    "$\\newcommand{\\si}{\\sigma}$\n",
    "$\\newcommand{\\al}{\\alpha}$\n",
    "$\\newcommand{\\la}{\\lambda}$\n",
    "$\\newcommand{\\ga}{\\gamma}$\n",
    "$\\newcommand{\\Ga}{\\Gamma}$\n",
    "$\\newcommand{\\La}{\\Lambda}$\n",
    "$\\newcommand{\\si}{\\sigma}$\n",
    "$\\newcommand{\\Si}{\\Sigma}$\n",
    "$\\newcommand{\\be}{\\beta}$\n",
    "$\\newcommand{\\de}{\\delta}$\n",
    "$\\newcommand{\\De}{\\Delta}$\n",
    "$\\newcommand{\\phi}{\\varphi}$\n",
    "$\\newcommand{\\th}{\\theta}$\n",
    "$\\newcommand{\\om}{\\omega}$\n",
    "$\\newcommand{\\Om}{\\Omega}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This tour explores theoritical garantees for the performance of recovery\n",
    "using $\\ell^1$ minimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition ndgrid(AbstractArray{T<:Any, 1}) in module NtToolBox at /Users/gpeyre/.julia/v0.5/NtToolBox/src/ndgrid.jl:3 overwritten at /Users/gpeyre/.julia/v0.5/NtToolBox/src/ndgrid.jl:3.\n",
      "WARNING: Method definition ndgrid(AbstractArray{#T<:Any, 1}, AbstractArray{#T<:Any, 1}) in module NtToolBox at /Users/gpeyre/.julia/v0.5/NtToolBox/src/ndgrid.jl:6 overwritten at /Users/gpeyre/.julia/v0.5/NtToolBox/src/ndgrid.jl:6.\n",
      "WARNING: Method definition ndgrid_fill(Any, Any, Any, Any) in module NtToolBox at /Users/gpeyre/.julia/v0.5/NtToolBox/src/ndgrid.jl:13 overwritten at /Users/gpeyre/.julia/v0.5/NtToolBox/src/ndgrid.jl:13.\n",
      "WARNING: Method definition ndgrid(AbstractArray{#T<:Any, 1}...) in module NtToolBox at /Users/gpeyre/.julia/v0.5/NtToolBox/src/ndgrid.jl:19 overwritten at /Users/gpeyre/.julia/v0.5/NtToolBox/src/ndgrid.jl:19.\n",
      "WARNING: Method definition meshgrid(AbstractArray{T<:Any, 1}) in module NtToolBox at /Users/gpeyre/.julia/v0.5/NtToolBox/src/ndgrid.jl:33 overwritten at /Users/gpeyre/.julia/v0.5/NtToolBox/src/ndgrid.jl:33.\n",
      "WARNING: Method definition meshgrid(AbstractArray{#T<:Any, 1}, AbstractArray{#T<:Any, 1}) in module NtToolBox at /Users/gpeyre/.julia/v0.5/NtToolBox/src/ndgrid.jl:36 overwritten at /Users/gpeyre/.julia/v0.5/NtToolBox/src/ndgrid.jl:36.\n",
      "WARNING: Method definition meshgrid(AbstractArray{#T<:Any, 1}, AbstractArray{#T<:Any, 1}, AbstractArray{#T<:Any, 1}) in module NtToolBox at /Users/gpeyre/.julia/v0.5/NtToolBox/src/ndgrid.jl:44 overwritten at /Users/gpeyre/.julia/v0.5/NtToolBox/src/ndgrid.jl:44.\n"
     ]
    }
   ],
   "source": [
    "using PyPlot\n",
    "using NtToolBox\n",
    "# using Autoreload\n",
    "# arequire(\"NtToolBox\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Sparse $\\ell^1$ Recovery\n",
    "--------------------------\n",
    "We consider the inverse problem of estimating an unknown signal $x_0 \\in\n",
    "\\RR^N$ from noisy measurements $y=\\Phi x_0 + w \\in \\RR^P$ where $\\Phi \\in \\RR^{P \\times N}$\n",
    "is a measurement matrix with $P \\leq N$, and $w$ is some noise.\n",
    "\n",
    "\n",
    "This tour is focused on recovery using $\\ell^1$ minimization\n",
    "$$ x^\\star \\in \\uargmin{x \\in \\RR^N} \\frac{1}{2}\\norm{y-\\Phi x}^2 + \\la \\normu{x}. $$\n",
    "\n",
    "\n",
    "Where there is no noise, we consider the problem $ \\Pp(y) $\n",
    "$$ x^\\star \\in \\uargmin{\\Phi x = y} \\normu{x}. $$\n",
    "\n",
    "\n",
    "We are not concerned here about the actual way to solve this convex\n",
    "problem (see the other numerical tours on sparse regularization) but\n",
    "rather on the theoritical analysis of wether $x^\\star$ is close to\n",
    "$x_0$.\n",
    "\n",
    "\n",
    "More precisely, we consider the following three key properties\n",
    "\n",
    "\n",
    "* *Noiseless identifiability*: $x_0$ is the unique solution of $\n",
    "\\Pp(y) $ for $y=\\Phi x_0$.\n",
    "* *Robustess to small noise*: one has $\\norm{x^\\star - x_0} =\n",
    "O(\\norm{w})$ for $y=\\Phi x_0+w$ if $\\norm{w}$ is smaller than\n",
    "an arbitrary small constant that depends on $x_0$ if $\\la$ is well chosen according to $\\norm{w}$.\n",
    "* *Robustess to bounded noise:* same as above, but $\\norm{w}$ can be\n",
    "arbitrary.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Note that noise robustness implies identifiability, but the converse\n",
    "is not true in general.\n",
    "\n",
    "\n",
    "Coherence Criteria\n",
    "------------------\n",
    "The simplest criteria for identifiality are based on the coherence of the\n",
    "matrix $\\Phi$ and depends only on the sparsity $\\norm{x_0}_0$ of the\n",
    "original signal. This criteria is thus not very precise and gives very pessimistic\n",
    "bounds.\n",
    "\n",
    "\n",
    "The coherence of the matrix $\\Phi = ( \\phi_i )_{i=1}^N \\in \\RR^{P \\times\n",
    "N}$ with unit norm colum $\\norm{\\phi_i}=1$ is\n",
    "$$ \\mu(\\Phi) = \\umax{i \\neq j} \\abs{\\dotp{\\phi_i}{\\phi_j}}. $$\n",
    "\n",
    "\n",
    "\n",
    "Compute the correlation matrix (remove the diagonal of 1's)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::#3) (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_diag = C -> C - diagm(diag(C))\n",
    "Correlation = Phi -> remove_diag(abs(Phi'*Phi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Compute the coherence $\\mu(\\Phi)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::#5) (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = Phi -> maximum(Correlation(Phi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The condition\n",
    "$$ \\normz{x_0} < \\frac{1}{2}\\pa{1 + \\frac{1}{\\mu(\\Phi)}} $$\n",
    "implies that $x_0$ is identifiable, and also implies to robustess to small and bounded noise.\n",
    "\n",
    "\n",
    "Equivalently, this condition can be written as $\\text{Coh}(\\normz{x_0})<1$\n",
    "where\n",
    "$$ \\text{Coh}(k) = \\frac{k \\mu(\\Phi)}{ 1 - (k-1)\\mu(\\Phi) } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::#7) (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Coh = (Phi, k) -> (k*mu(Phi))/(1 - (k - 1)*mu(Phi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Generate a matrix with random unit columns in $\\RR^P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250×1000 Array{Float64,2}:\n",
       " -0.00153558   -0.0873719   -0.0267141   …  -0.00418114    0.0431689 \n",
       "  0.016081      0.0658395    0.0183717      -0.0977312    -0.173786  \n",
       " -0.0202818     0.10513     -0.0061723       0.0903024     0.0475056 \n",
       "  0.0174428     0.0767283    0.0283078       0.0351142     0.0178382 \n",
       " -0.0156658    -0.113847     0.0829878      -0.0569733    -0.082541  \n",
       " -0.159691      0.0178282    0.102784    …   0.0324298     0.0500197 \n",
       "  0.109889     -0.00281318   0.0497717       0.0133811     0.0990111 \n",
       "  0.158323     -0.00278128   0.0263971      -0.00234905    0.0866833 \n",
       "  0.000221441   0.00898388   0.0364112      -0.0818329    -0.0140391 \n",
       " -0.023077     -0.101275    -0.0164376      -0.0694768     0.056435  \n",
       "  0.0391143     0.0801067   -0.00795326  …   0.0105741    -0.0107431 \n",
       "  0.0457144    -0.00871715  -0.0343846       0.0428562    -0.0408472 \n",
       "  0.00232064    0.0631691   -0.0595921      -0.000329357   0.0098766 \n",
       "  ⋮                                      ⋱                           \n",
       "  0.0489705    -0.0196438    0.00785909      1.66286e-5   -0.0416976 \n",
       "  0.0460609    -0.0325308   -0.108784       -0.0299601    -0.0500156 \n",
       "  0.0730461    -0.0729764   -0.0382131   …   0.00106382   -0.0420094 \n",
       "  0.0996469    -0.0980691   -0.0351391       0.0462986     0.0486122 \n",
       "  0.0918515     0.106906    -0.0167351      -0.0218581    -0.101535  \n",
       " -0.0554057     0.00990167   0.0265645      -0.0473953     0.0306916 \n",
       "  0.0601045    -0.0544066   -0.0442649      -0.0428824     0.0270975 \n",
       "  0.0339008     0.0220354    0.0601455   …  -0.0811251    -0.013028  \n",
       "  0.0160892     0.0403653    0.00898637      0.0820708     0.00224229\n",
       " -0.0368455    -0.040219    -0.0506181       0.0362769    -0.0364124 \n",
       "  0.0991768     0.0148596    0.067233        0.0141599    -0.0624272 \n",
       "  0.00481869   -0.0303919   -0.00353946      0.0225215    -0.056659  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize = Phi -> Phi ./ repeat(sqrt(sum(Phi.^2, 1)), inner = [size(Phi)[1], 1]);\n",
    "\n",
    "\n",
    "PhiRand = (P, N) -> normalize(randn(P, N))\n",
    "Phi = PhiRand(250, 1000)\n",
    "# P = 250; N = 1000\n",
    "# Phi = randn(P, N)\n",
    "# repeat(sqrt(sum(Phi.^2, 1)), inner = [size(Phi)[1], 1])\n",
    "# sum(Phi.^2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Compute the coherence and the maximum possible sparsity to ensure\n",
    "recovery using the coherence bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence:    0.32\n",
      "Sparsity max: 2\n"
     ]
    }
   ],
   "source": [
    "c = mu(Phi)\n",
    "println(@sprintf(\"Coherence:    %.2f\", c))\n",
    "println(@sprintf(\"Sparsity max: %d\", floor(1/2*(1 + 1/c))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Exercise 1__\n",
    "\n",
    "Display how the average coherence of a random matrix\n",
    "decays with the redundancy $\\eta = P/N$ of\n",
    "the matrix $\\Phi$. Can you derive an empirical law between\n",
    "$P$ and the maximal sparsity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "include(\"NtSolutions/sparsity_6_l1_recovery/exo1.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Insert your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Support and Sign-based Criteria\n",
    "-------------------------------\n",
    "In the following we will consider the support\n",
    "$$ \\text{supp}(x_0) = \\enscond{i}{x_0(i) \\neq 0} $$\n",
    "of the vector $x_0$. The co-support is its complementary $I^c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "supp   = s -> find(abs(s) .> 1e-5)\n",
    "cosupp = s -> find(abs(s) .< 1e-5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Given some support $ I \\subset \\{0,\\ldots,N-1\\} $, we will denote as\n",
    "$ \\Phi = (\\phi_m)_{m \\in I} \\in \\RR^{N \\times \\abs{I}}$ the\n",
    "sub-matrix extracted from $\\Phi$ using the columns indexed by $I$.\n",
    "\n",
    "\n",
    "J.J. Fuchs introduces a criteria $F$ for identifiability that depends on the\n",
    "sign of $x_0$.\n",
    "\n",
    "\n",
    "J.J. Fuchs. _Recovery of exact sparse representations in the presence of\n",
    "bounded noise._ IEEE Trans. Inform. Theory, 51(10), p. 3601-3608, 2005\n",
    "\n",
    "\n",
    "Under the condition that $\\Phi_I$ has full rank, the $F$ measure\n",
    "of a sign vector $s \\in \\{+1,0,-1\\}^N$ with $\\text{supp}(s)=I$ reads\n",
    "$$ \\text{F}(s) = \\norm{ \\Psi_I s_I }_\\infty\n",
    "      \\qwhereq \\Psi_I = \\Phi_{I^c}^* \\Phi_I^{+,*} $$\n",
    "where $ A^+ = (A^* A)^{-1} A^* $ is the pseudo inverse of a\n",
    "matrix $A$.\n",
    "\n",
    "\n",
    "The condition\n",
    "$$ \\text{F}(\\text{sign}(x_0))<1 $$\n",
    "implies that $x_0$ is identifiable, and also implies to robustess to\n",
    "small noise. It does not however imply robustess to a bounded noise.\n",
    "\n",
    "\n",
    "Compute $\\Psi_I$ matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "PsiI = (Phi,I) -> Phi[:, setdiff(1:size(Phi)[2], I)]' * pinv(Phi[:,I])';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Compute $\\text{F}(s)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "F = (Phi, s) -> norm(PsiI(Phi, supp(s))*s[supp(s)], Inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The Exact Recovery Criterion (ERC) of a support $I$,\n",
    "introduced by Tropp in\n",
    "\n",
    "\n",
    "J. A. Tropp. _Just relax: Convex programming methods for identifying\n",
    "sparse signals._ IEEE Trans. Inform. Theory, vol. 52, num. 3, pp. 1030-1051, Mar. 2006.\n",
    "\n",
    "\n",
    "Under the condition that $\\Phi_I$ has full rank, this condition reads\n",
    "$$ \\text{ERC}(I) = \\norm{\\Psi_{I}}_{\\infty,\\infty}\n",
    "      =  \\umax{j \\in I^c} \\norm{ \\Phi_I^+ \\phi_j }_1. $$\n",
    "where $\\norm{A}_{\\infty,\\infty}$ is the $\\ell^\\infty-\\ell^\\infty$\n",
    "operator norm of a matrix $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "erc =(Phi, I) -> norm(PsiI(Phi,I), Inf);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The condition\n",
    "$$ \\text{ERC}(\\text{supp}(x_0))<1 $$\n",
    "implies that $x_0$ is identifiable, and also implies to robustess to\n",
    "small and bounded noise.\n",
    "\n",
    "\n",
    "One can prove that the ERC is the maximum of the F criterion for all signs of the given\n",
    "support\n",
    "$$ \\text{ERC}(I) = \\umax{ s, \\text{supp}(s) \\subset I } \\text{F}(s). $$\n",
    "\n",
    "\n",
    "The weak-ERC is an approximation of the ERC using only the correlation\n",
    "matrix\n",
    "$$ \\text{w-ERC}(I) = \\frac{\n",
    "      \\umax{j \\in I^c} \\sum_{i \\in I} \\abs{\\dotp{\\phi_i}{\\phi_j}}\n",
    " }{\n",
    "      1-\\umax{j \\in I} \\sum_{i \\neq j \\in I} \\abs{\\dotp{\\phi_i}{\\phi_j}}\n",
    " }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "g = (C, I) -> sum(C[:,I], 2)\n",
    "werc_g = (g, I, J) -> maximum(g[J]) / (1 - maximum(g[I]))\n",
    "werc = (Phi, I) -> werc_g(g(Correlation(Phi), I), I, setdiff(1:size(Phi)[2], I) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "One has, if $\\text{w-ERC}(I)>0$,  for $ I = \\text{supp}(s) $,\n",
    "$$ \\text{F}(s) \\leq \\text{ERC}(I) \\leq \\text{w-ERC}(I) \\leq\n",
    "      \\text{Coh}(\\abs{I}). $$\n",
    "\n",
    "\n",
    "This shows in particular that the condition\n",
    "$$ \\text{w-ERC}(\\text{supp}(x_0))<1 $$\n",
    "implies identifiability and robustess to small and bounded noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Exercise 2__\n",
    "\n",
    "Show that this inequality holds on a given matrix.\n",
    "What can you conclude about the sharpness of these criteria ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "include(\"NtSolutions/sparsity_6_l1_recovery/exo2.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Insert your code here.\n",
    "\n",
    "N = 2000\n",
    "P = N - 10\n",
    "Phi = PhiRand(N, P)\n",
    "s = zeros(N)\n",
    "s[1:6] = 1\n",
    "I = supp(s)\n",
    "k = length(I)\n",
    "\n",
    "println(@sprintf(\"N = %d, P = %d, |I| = %d\", N, P, k))\n",
    "println(@sprintf(\"F(s)     = %.2f\",  F(Phi, s)))\n",
    "println(@sprintf(\"ERC(I)   = %.2f\",  erc(Phi, I)))\n",
    "println(@sprintf(\"w-ERC(s) = %.2f\", werc(Phi, I)))\n",
    "println(@sprintf(\"Coh(|s|) = %.2f\", Coh(Phi, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Exercise 3__\n",
    "\n",
    "For a given matrix $\\Phi$ generated using PhiRand, draw as a function of the sparsity $k$\n",
    "the probability that a random sign vector $s$ of sparsity\n",
    "$\\norm{s}_0=k$ satisfies the conditions $\\text{F}(x_0)<1$,\n",
    "$\\text{ERC}(x_0)<1$ and $\\text{w-ERC}(x_0)<1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "include(\"NtSolutions/sparsity_6_l1_recovery/exo3.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Insert your code here.\n",
    "\n",
    "N = 600\n",
    "P = Int(N/2)\n",
    "Phi = PhiRand(P, N)\n",
    "klist = Array{Int64,1}(round(linspace(1, P/7., 20)))\n",
    "ntrials = 60\n",
    "proba = zeros(length(klist), 3)\n",
    "\n",
    "for i in 1:length(klist)\n",
    "    proba[i, 1:3] = 0\n",
    "    k = Int(klist[i])\n",
    "    for j in 1:ntrials\n",
    "        s = zeros(N)\n",
    "        I = randperm(N)\n",
    "        I = I[1:k]\n",
    "        l = randn(k, 1)\n",
    "        s[I] = l./abs(l)\n",
    "        proba[i, 1] = proba[i, 1] + (F(Phi, s) .< 1)\n",
    "        proba[i, 2] = proba[i, 2] + (erc(Phi, I) .< 1)\n",
    "        proba[i, 3] = proba[i, 3] + (werc(Phi, I) .> 0).*(werc(Phi, I) .< 1)\n",
    "    end\n",
    "end\n",
    "        \n",
    "figure(figsize = (8, 5))\n",
    "plot(klist, proba/ntrials, linewidth = 2)\n",
    "xlabel(\"k\")\n",
    "legend([\"F <1\", \"ERC <1\", \"w-ERC <1\"])\n",
    "title(@sprintf(\"N = %d, P = %d\", N, P))\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Restricted Isometry Criteria\n",
    "----------------------------\n",
    "The restricted isometry constants $\\de_k^1,\\de_k^2$ of a matrix $\\Phi$ are the\n",
    "smallest $\\de^1,\\de^2$ that satisfy\n",
    "$$ \\forall x \\in \\RR^N, \\quad \\norm{x}_0 \\leq k \\qarrq\n",
    "      (1-\\de^1)\\norm{x}^2 \\leq \\norm{\\Phi x}^2 \\leq (1+\\de^2)\\norm{x}^2.  $$\n",
    "\n",
    "\n",
    "E. Candes shows in\n",
    "\n",
    "\n",
    "E. J. Cand s. _The restricted isometry property and its implications for\n",
    "compressed sensing_. Compte Rendus de l'Academie des Sciences, Paris, Serie I, 346 589-592\n",
    "\n",
    "\n",
    "that if\n",
    "$$ \\de_{2k} \\leq \\sqrt{2}-1 ,$$\n",
    "then $\\norm{x_0} \\leq k$ implies identifiability as well as robustness to small and bounded noise.\n",
    "\n",
    "\n",
    "The stability constant $\\la^1(A), \\la^2(A)$ of a matrix\n",
    "$A = \\Phi_I$ extracted from $\\Phi$ is the smallest $\\tilde \\la_1,\\tilde \\la_2$ such that\n",
    "$$ \\forall \\al \\in \\RR^{\\abs{I}}, \\quad\n",
    "      (1-\\tilde\\la_1)\\norm{\\al}^2 \\leq \\norm{A \\al}^2 \\leq (1+\\tilde \\la_2)\\norm{\\al}^2.  $$\n",
    "\n",
    "\n",
    "These constants $\\la^1(A), \\la^2(A)$ are easily computed from the\n",
    "largest and smallest eigenvalues of $A^* A \\in \\RR^{\\abs{I} \\times \\abs{I}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "minmax = v -> (1 - minimum(v), maximum(v) - 1)\n",
    "ric = A -> minmax(eig(A'*A)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The restricted isometry constant of $\\Phi$ are computed as the largest\n",
    "stability constants of extracted matrices\n",
    "$$ \\de^\\ell_k = \\umax{ \\abs{I}=k } \\la^\\ell( \\Phi_I ).  $$\n",
    "\n",
    "\n",
    "The eigenvalues of $\\Phi$ are essentially contained in the\n",
    "interval $ [a,b] $ where $a=(1-\\sqrt{\\be})^2$ and $b=(1+\\sqrt{\\be})^2$\n",
    "with $\\beta = k/P$\n",
    "More precisely, as $k=\\be P$ tends to infinity, the distribution of the\n",
    "eigenvalues tends to the Marcenko-Pastur law\n",
    "$ f_\\be(\\la) = \\frac{1}{2\\pi \\be \\la}\\sqrt{ (\\la-b)^+ (a-\\la)^+ }. $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Exercise 4__\n",
    "\n",
    "Display, for an increasing value of $k$ the histogram of repartition\n",
    "of the eigenvalues $A^* A$ where $A$ is a Gaussian matrix of size $(P,k)$ and\n",
    "variance $1/P$. For this, accumulate the eigenvalues for many\n",
    "realizations of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "include(\"NtSolutions/sparsity_6_l1_recovery/exo4.jl\")\n",
    "\n",
    "# klist = [10, 30, 50]\n",
    "# P = 200\n",
    "# ntrials = 200\n",
    "# tmin = 0\n",
    "# tmax = 2.5\n",
    "# q = 50\n",
    "# t = linspace(tmin, tmax, q)\n",
    "# t1 = linspace(tmin, tmax, 1000)\n",
    "# dt = (tmax - tmin)/q\n",
    "\n",
    "# for j in 1 : length(klist)\n",
    "#     k = klist[j]\n",
    "    \n",
    "#     # simulation    \n",
    "#     v = []\n",
    "#     for i in 1 : ntrials\n",
    "#         v = [v; svd(randn(P, k)./sqrt(P))[2].^2]\n",
    "#     end\n",
    "    \n",
    "#     figure(figsize = (10, 10))\n",
    "#     subplot(length(klist), 1, j)\n",
    "#     h = hist(v, t)[2]\n",
    "#     h = h/sum(h)/dt\n",
    "#     h = [h; 0]\n",
    "#     bar(t[1 : end], h, width = 1/20, color = \"darkblue\", edgecolor = \"black\")\n",
    "    \n",
    "#     # theoritical law\n",
    "#     beta = k/P\n",
    "#     a = (1 - sqrt(beta))^2\n",
    "#     b = (1 + sqrt(beta))^2\n",
    "#     z = sqrt(max(t1 - a, zeros(length(t1))).*max(b - t1, zeros(length(t1))))./(2*pi.*beta.*t1)\n",
    "    \n",
    "#     plot(t1, z, \"r\", linewidth = 3)\n",
    "#     xlim(tmin, tmax)\n",
    "#     ylim(0, maximum(h)*1.05)\n",
    "#     title(@sprintf(\"P = %d, k = %d\", P, k))\n",
    "    \n",
    "#     show()\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Insert your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Exercise 5__\n",
    "\n",
    "Estimate numerically lower bound on $\\de_k^1,\\de_k^2$ by Monte-Carlo\n",
    "sampling of sub-matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "include(\"NtSolutions/sparsity_6_l1_recovery/exo5.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Insert your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Sparse Spikes Deconvolution\n",
    "---------------------------\n",
    "We now consider a convolution dictionary $ \\Phi $.\n",
    "Such a dictionary is used with sparse regulariz\n",
    "\n",
    "\n",
    "Second derivative of Gaussian kernel $g$ with a given variance $\\si^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sigma = 6\n",
    "g = x -> (1 - x.^2./sigma^2).*exp(-x.^2./(2*sigma^2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create a matrix $\\Phi$ so that $\\Phi x = g \\star x$ with periodic\n",
    "boundary conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "include(\"ndgrid.jl\")\n",
    "P = 1024\n",
    "(Y, X) = meshgrid(0:P-1, 0:P-1)\n",
    "Phi = normalize(g((X - Y + P/2.)%P-P/2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To improve the conditionning of the dictionary, we sub-sample its atoms,\n",
    "so that $ P = \\eta N > N $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "eta = 2\n",
    "N = P/eta\n",
    "Phi = Phi[:, 1:eta:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Plot the correlation function associated to the filter.\n",
    "Can you determine the value of the coherence $\\mu(\\Phi)$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "c = Phi'*Phi\n",
    "c = abs(c[:, Int(size(c)[2]/2)])\n",
    "\n",
    "\n",
    "figure(figsize = (8, 5))\n",
    "plot(c[Base.div(length(c), 2) - 50 : Base.div(length(c), 2) + 50], \".-\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create a data a sparse $x_0$ with two diracs of opposite signes with spacing $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "twosparse = d -> circshift([1; zeros(d, 1); -1; zeros(Int(N) - d - 2, 1)], round(N/2 - d/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Display $x_0$ and $\\Phi x_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x0 = twosparse(50)\n",
    "\n",
    "\n",
    "figure(figsize = (10, 7))\n",
    "subplot(2, 1, 1)\n",
    "plot(x0[:], \"r\", linewidth = 2)\n",
    "subplot(2, 1, 2)\n",
    "plot((Phi*x0)[:], \"b\", linewidth = 2)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Exercise 6__\n",
    "\n",
    "Plot the evolution of the criteria F, ERC and Coh as a function of $d$.\n",
    "Do the same plot for other signs patterns for $x_0$.\n",
    "Do the same plot for a Dirac comb with a varying spacing $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "include(\"NtSolutions/sparsity_6_l1_recovery/exo6.jl\")\n",
    "\n",
    "# g = (C, I) -> sum(C[:, I], 2)\n",
    "\n",
    "# figure(figsize = (8, 5))\n",
    "# dlist = Array{Int64,1}(1 : N/20 - 1)\n",
    "# criter = zeros(length(dlist), 3)\n",
    "\n",
    "# for i in 1 : length(dlist)\n",
    "#     s = twosparse(dlist[i])\n",
    "#     I = (supp(s))\n",
    "#     criter[i, :] = [F(Phi, s), erc(Phi,I), werc(Phi,I)]\n",
    "# end\n",
    "    \n",
    "# criter[criter .< 0] = float(\"inf\")\n",
    "\n",
    "# plot(dlist, criter, linewidth = 2)\n",
    "# plot(dlist, dlist.*0 + 1, \"k--\", linewidth = 2)\n",
    "# xlim(1, maximum(dlist))\n",
    "# ylim(minimum(criter), maximum(criter))\n",
    "# xlabel(\"d\")\n",
    "# legend([\"F\", \"ERC\", \"w-ERC\"])\n",
    "           \n",
    "# show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Insert your code here."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
