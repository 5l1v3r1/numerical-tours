
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN">
<html xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      --><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script><p style="font-size:0px">
         \[
         \newcommand{\NN}{\mathbb{N}}
         \newcommand{\CC}{\mathbb{C}}
         \newcommand{\GG}{\mathbb{G}}
         \newcommand{\LL}{\mathbb{L}}
         \newcommand{\PP}{\mathbb{P}}
         \newcommand{\QQ}{\mathbb{Q}}
         \newcommand{\RR}{\mathbb{R}}
         \newcommand{\VV}{\mathbb{V}}
         \newcommand{\ZZ}{\mathbb{Z}}
         \newcommand{\FF}{\mathbb{F}}
         \newcommand{\KK}{\mathbb{K}}
         \newcommand{\UU}{\mathbb{U}}
         \newcommand{\EE}{\mathbb{E}}
         
         \newcommand{\Aa}{\mathcal{A}}
         \newcommand{\Bb}{\mathcal{B}}
         \newcommand{\Cc}{\mathcal{C}}
         \newcommand{\Dd}{\mathcal{D}}
         \newcommand{\Ee}{\mathcal{E}}
         \newcommand{\Ff}{\mathcal{F}}
         \newcommand{\Gg}{\mathcal{G}}
         \newcommand{\Hh}{\mathcal{H}}
         \newcommand{\Ii}{\mathcal{I}}
         \newcommand{\Jj}{\mathcal{J}}
         \newcommand{\Kk}{\mathcal{K}}
         \newcommand{\Ll}{\mathcal{L}}
         \newcommand{\Mm}{\mathcal{M}}
         \newcommand{\Nn}{\mathcal{N}}
         \newcommand{\Oo}{\mathcal{O}}
         \newcommand{\Pp}{\mathcal{P}}
         \newcommand{\Qq}{\mathcal{Q}}
         \newcommand{\Rr}{\mathcal{R}}
         \newcommand{\Ss}{\mathcal{S}}
         \newcommand{\Tt}{\mathcal{T}}
         \newcommand{\Uu}{\mathcal{U}}
         \newcommand{\Vv}{\mathcal{V}}
         \newcommand{\Ww}{\mathcal{W}}
         \newcommand{\Xx}{\mathcal{X}}
         \newcommand{\Yy}{\mathcal{Y}}
         \newcommand{\Zz}{\mathcal{Z}}
         
         \newcommand{\al}{\alpha}
         \newcommand{\la}{\lambda}
         \newcommand{\ga}{\gamma}
         \newcommand{\Ga}{\Gamma}
         \newcommand{\La}{\Lambda}
         \newcommand{\Si}{\Sigma}
         \newcommand{\si}{\sigma}
         \newcommand{\be}{\beta}
         \newcommand{\de}{\delta}
         \newcommand{\De}{\Delta}
         \renewcommand{\phi}{\varphi}
         \renewcommand{\th}{\theta}
         \newcommand{\om}{\omega}
         \newcommand{\Om}{\Omega}
         \renewcommand{\epsilon}{\varepsilon}
         
         \newcommand{\Calpha}{\mathrm{C}^\al}
         \newcommand{\Cbeta}{\mathrm{C}^\be}
         \newcommand{\Cal}{\text{C}^\al}
         \newcommand{\Cdeux}{\text{C}^{2}}
         \newcommand{\Cun}{\text{C}^{1}}
         \newcommand{\Calt}[1]{\text{C}^{#1}}
         
         \newcommand{\lun}{\ell^1}
         \newcommand{\ldeux}{\ell^2}
         \newcommand{\linf}{\ell^\infty}
         \newcommand{\ldeuxj}{{\ldeux_j}}
         \newcommand{\Lun}{\text{\upshape L}^1}
         \newcommand{\Ldeux}{\text{\upshape L}^2}
         \newcommand{\Lp}{\text{\upshape L}^p}
         \newcommand{\Lq}{\text{\upshape L}^q}
         \newcommand{\Linf}{\text{\upshape L}^\infty}
         \newcommand{\lzero}{\ell^0}
         \newcommand{\lp}{\ell^p}
         
         
         \renewcommand{\d}{\ins{d}}
         
         \newcommand{\Grad}{\text{Grad}}
         \newcommand{\grad}{\text{grad}}
         \renewcommand{\div}{\text{div}}
         \newcommand{\diag}{\text{diag}}
         
         \newcommand{\pd}[2]{ \frac{ \partial #1}{\partial #2} }
         \newcommand{\pdd}[2]{ \frac{ \partial^2 #1}{\partial #2^2} }
         
         \newcommand{\dotp}[2]{\langle #1,\,#2\rangle}
         \newcommand{\norm}[1]{|\!| #1 |\!|}
         \newcommand{\normi}[1]{\norm{#1}_{\infty}}
         \newcommand{\normu}[1]{\norm{#1}_{1}}
         \newcommand{\normz}[1]{\norm{#1}_{0}}
         \newcommand{\abs}[1]{\vert #1 \vert}
         
         
         \newcommand{\argmin}{\text{argmin}}
         \newcommand{\argmax}{\text{argmax}}
         \newcommand{\uargmin}[1]{\underset{#1}{\argmin}\;}
         \newcommand{\uargmax}[1]{\underset{#1}{\argmax}\;}
         \newcommand{\umin}[1]{\underset{#1}{\min}\;}
         \newcommand{\umax}[1]{\underset{#1}{\max}\;}
         
         \newcommand{\pa}[1]{\left( #1 \right)}
         \newcommand{\choice}[1]{ \left\{  \begin{array}{l} #1 \end{array} \right. }
         
         \newcommand{\enscond}[2]{ \left\{ #1 \;:\; #2 \right\} }
         
         \newcommand{\qandq}{ \quad \text{and} \quad }
         \newcommand{\qqandqq}{ \qquad \text{and} \qquad }
         \newcommand{\qifq}{ \quad \text{if} \quad }
         \newcommand{\qqifqq}{ \qquad \text{if} \qquad }
         \newcommand{\qwhereq}{ \quad \text{where} \quad }
         \newcommand{\qqwhereqq}{ \qquad \text{where} \qquad }
         \newcommand{\qwithq}{ \quad \text{with} \quad }
         \newcommand{\qqwithqq}{ \qquad \text{with} \qquad }
         \newcommand{\qforq}{ \quad \text{for} \quad }
         \newcommand{\qqforqq}{ \qquad \text{for} \qquad }
         \newcommand{\qqsinceqq}{ \qquad \text{since} \qquad }
         \newcommand{\qsinceq}{ \quad \text{since} \quad }
         \newcommand{\qarrq}{\quad\Longrightarrow\quad}
         \newcommand{\qqarrqq}{\quad\Longrightarrow\quad}
         \newcommand{\qiffq}{\quad\Longleftrightarrow\quad}
         \newcommand{\qqiffqq}{\qquad\Longleftrightarrow\qquad}
         \newcommand{\qsubjq}{ \quad \text{subject to} \quad }
         \newcommand{\qqsubjqq}{ \qquad \text{subject to} \qquad }
         \]
         
      </p>
      <title>Entropic Regularization of Optimal Transport</title>
      <NOSCRIPT>
         <DIV STYLE="color:#CC0000; text-align:center"><B>Warning: <A HREF="http://www.math.union.edu/locate/jsMath">jsMath</A> 
               	requires JavaScript to process the mathematics on this page.<BR> 
               	If your browser supports JavaScript, be sure it is enabled.</B></DIV>
         <HR>
      </NOSCRIPT>
      <meta name="generator" content="MATLAB 8.2">
      <meta name="date" content="2014-10-20">
      <meta name="m-file" content="index">
      <LINK REL="stylesheet" HREF="../style.css" TYPE="text/css">
   </head>
   <body>
      <div class="content">
         <h1>Entropic Regularization of Optimal Transport</h1>
         <introduction>
            <p>This numerical tours exposes the general methodology of regularizing the optimal transport (OT) linear program using entropy.
               This allows to derive fast computation algorithm based on iterative projections according to a Kulback-Leiber divergence.
               \[ \DeclareMathOperator{\KL}{KL} \newcommand{\KLdiv}[2]{\KL\pa{#1 | #2}} \newcommand{\KLproj}{P^{\tiny\KL}} \def\ones{\mathbb{I}}
               \]
            </p>
         </introduction>
         <h2>Contents</h2>
         <div>
            <ul>
               <li><a href="#1">Installing toolboxes and setting up the path.</a></li>
               <li><a href="#8">Entropic Regularization of Optimal Transport</a></li>
               <li><a href="#13">Iterative Bregman Projection Algorithm</a></li>
               <li><a href="#16">Iterative Projection for Regularized Transport</a></li>
               <li><a href="#29">Bibliography</a></li>
            </ul>
         </div>
         <h2>Installing toolboxes and setting up the path.<a name="1"></a></h2>
         <p>You need to download the following files: <a href="../toolbox_signal.zip">signal toolbox</a> and <a href="../toolbox_general.zip">general toolbox</a>.
         </p>
         <p>You need to unzip these toolboxes in your working directory, so that you have <tt>toolbox_signal</tt> and <tt>toolbox_general</tt> in your directory.
         </p>
         <p><b>For Scilab user:</b> you must replace the Matlab comment '%' by its Scilab counterpart '//'.
         </p>
         <p><b>Recommandation:</b> You should create a text file named for instance <tt>numericaltour.sce</tt> (in Scilab) or <tt>numericaltour.m</tt> (in Matlab) to write all the Scilab/Matlab command you want to execute. Then, simply run <tt>exec('numericaltour.sce');</tt> (in Scilab) or <tt>numericaltour;</tt> (in Matlab) to run the commands.
         </p>
         <p>Execute this line only if you are using Matlab.</p><pre class="codeinput">getd = @(p)path(p,path); <span class="comment">% scilab users must *not* execute this</span>
</pre><p>Then you can add the toolboxes to the path.</p><pre class="codeinput">getd(<span class="string">'toolbox_signal/'</span>);
getd(<span class="string">'toolbox_general/'</span>);
</pre><h2>Entropic Regularization of Optimal Transport<a name="8"></a></h2>
         <p>We consider two input histograms \(p,q \in \Si_N\), where we denote the simplex in \(\RR^N\) \[ \Si_{N} = \enscond{ p \in
            (\RR^+)^N }{ \sum_i p_i = 1 }.  \] We consider the following discrete regularized transport \[  W_\ga(p,q) = \umin{\pi \in
            \Pi(p,q)} \dotp{C}{\pi} - \ga E(\pi).  \] where the polytope of coupling is defined as \[ \Pi(p,q) = \enscond{\pi \in (\RR^+)^{N
            \times N}}{ \pi \ones = p, \pi^* \ones = q },  \] and for \(f \in (\RR^+)^{P}\) for some \(P &gt; 0\), we define its entropy
            as \[ E(f) = - \sum_{i=1}^N f_i ( \log(f_i) - 1). \]
         </p>
         <p>When \(\ga=0\) one recovers the classical (discrete) optimal transport. We refer to the monograph <a href="#biblio">[Villani]</a> for more details about OT. The idea of regularizing transport to allows for faster computation is introduced in <a href="#biblio">[Cuturi]</a>.
         </p>
         <p>Here the matrix \(C \in (\RR^+)^{N \times N} \) defines the ground cost, i.e. \(C_{i,j}\) is the cost of moving mass from
            a bin indexed by \(i\) to a bin indexed by \(j\).
         </p>
         <p>The regularized transportation problem can be re-written as a projection \[ W_\ga(p,q) = \ga&nbsp;\umin{\pi \in \Pi(p,q)} \KLdiv{\pi}{\bar
            \pi} 	\qwhereq 	\bar\pi_{i,j} = e^{ -\frac{C_{i,j}}{\ga} }  \] of \(\bar\pi\) according to the Kullback-Leibler divergence.
            The Kullback-Leibler divergence between \(f, \bar f \in (\RR^+)^P\) is \[ \KLdiv{f}{\bar f} = \sum_{i=1}^P f_{i} \pa{&nbsp;\log\pa{
            \frac{f_i}{\bar f_i} } - 1}. \] With a slight abuse of notation, we extend these definitions for vectors \(\pi \in \RR^{N
            \times N}\) (and also higher \(d\)-dimensional tensor arrays), so that \(P=N^2\) (or more generally \(P=N^d\)) by replacing
            the sum over elements \(f_i\) by \(\pi_{i,j}\) with \(i,j=1,\ldots,N\).
         </p>
         <p>Given a convex set \(\Cc \subset \RR^N\), the projection according to the Kullback-Leiber divergence is defined as \[ \KLproj_\Cc(\bar
            f) = \uargmin{ f \in \Cc } \KLdiv{f}{\bar f}. \]
         </p>
         <h2>Iterative Bregman Projection Algorithm<a name="13"></a></h2>
         <p>Given affine constraint sets \( (\Cc_1,\ldots,\Cc_K) \), we aim at computing \[   \KLproj_\Cc(\bar \pi) \qwhereq \Cc = \Cc_1
            \cap \ldots \cap \Cc_K. \]
         </p>
         <p>This can be achieved, starting by \(\pi_0=\bar\pi\), by iterating \[ \forall \ell \geq 0, \quad \pi_{\ell+1} =  \KLproj_{\Cc_\ell}(\pi_\ell),
            \] where the index of the constraints should be understood modulo \(K\), i.e. we set \( \Cc_{\ell+K}=\Cc_\ell \).
         </p>
         <p>One can indeed show that \(\pi_\ell \rightarrow \KLproj_\Cc(\bar \pi)\). We refer to <a href="#biblio">[BauschkeLewis]</a> for more details about this algorithm and its extension to compute the projection on the intersection of convex sets (Dikstra
            algorithm).
         </p>
         <h2>Iterative Projection for Regularized Transport<a name="16"></a></h2>
         <p>We can re-cast the regularized optimal transport problem within this framework by introducing \[ \Cc_1 = \enscond{\pi \in
            (\RR^+)^{N \times N} }{\pi \ones = p} \qandq  \Cc_2 = \enscond{\pi \in (\RR^+)^{N \times N} }{\pi^* \ones = q}\]
         </p>
         <p>The KL projection on \(\Cc_1\) sets are easily computed by divisive normalization of rows. Indeed, denoting \( \pi = \KLproj_{\Cc_1}(\bar
            \pi) \), one has \[ \forall (i,j), \quad   \pi_{i,j} = \frac{ p_i \bar\pi_{i,j} }{ \sum_{s} \bar\pi_{i,s} } \] and similarely
            for \(\KLproj_{\Cc_1}(\bar \pi) \) by replacing rows by colums.
         </p>
         <p>Size \(N\) of the histograms.</p><pre class="codeinput">N = 200;
</pre><p>Define \(\KLproj_{\Cc_1}\).</p><pre class="codeinput">ProjC1 = @(pi,p)pi .* repmat( p./max(sum(pi,2), 1e-10), [1 N] );
</pre><p>Define \(\KLproj_{\Cc_2}\).</p><pre class="codeinput">ProjC2 = @(pi,q)pi .* repmat( q'./max(sum(pi,1), 1e-10), [N 1] );
</pre><p>We use here a 1-D square Euclidean metric.</p><pre class="codeinput">x = (0:N-1)'/N; y = x;
Y = repmat(y', [N 1]);
X = repmat(x, [1 N]);
C = abs(X-Y).^2;
</pre><p>Define the histogram \(p,q\)</p><pre class="codeinput">Gaussian = @(x0,sigma)exp( -(x-x0).^2/(2*sigma^2) );
normalize = @(p)p/sum(p(:));
x0 = .2; y0 = .8;  sigma = .07;
p = Gaussian(x0,sigma);
q = Gaussian(y0,sigma);
</pre><p>Add some minimal mass and normalize.</p><pre class="codeinput">vmin = .02;
p = normalize( p+max(p)*vmin);
q = normalize( q+max(q)*vmin);
</pre><p>Display them.</p><pre class="codeinput">clf;
subplot(2,1,1);
bar(x, p, <span class="string">'k'</span>); axis <span class="string">tight</span>;
subplot(2,1,2);
bar(y, q, <span class="string">'k'</span>); axis <span class="string">tight</span>;
</pre><img vspace="5" hspace="5" src="index_01.png"> <p><i>Exercice 1:</i> (<a href="../missing-exo/">check the solution</a>) Perform the iterations, and display the decay of the errors \[ \norm{\pi_\ell \ones - p}   \qandq   \norm{\pi_\ell^* \ones
            - q} \] in log scale.
         </p><pre class="codeinput">exo1;
</pre><img vspace="5" hspace="5" src="index_02.png"> <p>Display the optimal \(\pi\).</p><pre class="codeinput">clf;
imageplot(pi);
</pre><img vspace="5" hspace="5" src="index_03.png"> <p>For visualization purpose, to more clearly see the optimal map, do a normalization.</p><pre class="codeinput">normalizeMax = @(pi)pi ./ repmat( max(pi,[],1), [N 1] );
clf;
imageplot(normalizeMax(pi));
</pre><img vspace="5" hspace="5" src="index_04.png"> <p><i>Exercice 2:</i> (<a href="../missing-exo/">check the solution</a>) Display the transport map for several values of \(\gamma\).
         </p><pre class="codeinput">exo2;
<span class="comment">%</span>
</pre><img vspace="5" hspace="5" src="index_05.png"> <h2>Bibliography<a name="29"></a></h2>
         <p><a name="biblio"></a></p>
         <div>
            <ul>
               <li>[Villani]&nbsp;Villani, C. (2009). Optimal transport: old and new, volume 338. Springer Verlag.</li>
               <li>[Cuturi]&nbsp;Cuturi, M. (2013). Sinkhorn distances: Lightspeed computation of optimal transport. In Burges, C. J. C., Bottou,
                  L., Ghahramani, Z., and Weinberger, K. Q., editors, Proc. NIPS, pages 2292-2300.
               </li>
               <li>[AguehCarlier]&nbsp;Agueh, M. and Carlier, G. (2011). Barycenters in the Wasserstein space. SIAM J. on Mathematical Analysis, 43(2):904-924.</li>
               <li>[CuturiDoucet]&nbsp;Cuturi, M. and Doucet, A. (2014). Fast computation of wasserstein barycenters. In Proc. ICML.</li>
               <li>[BauschkeLewis]&nbsp;H. H. Bauschke and A. S. Lewis. Dykstra's algorithm with Bregman projections: a convergence proof. Optimization,
                  48(4):409-427, 2000.
               </li>
            </ul>
         </div>
         <p class="footer"><br>
            Copyright  (c) 2010 Gabriel Peyre<br></p>
      </div>
      <!--
##### SOURCE BEGIN #####
%% Entropic Regularization of Optimal Transport
% This numerical tours exposes the general methodology of regularizing the
% optimal transport (OT) linear program using entropy. This allows to
% derive fast computation algorithm based on iterative projections
% according to a Kulback-Leiber divergence. 
% \[ \DeclareMathOperator{\KL}{KL}
% \newcommand{\KLdiv}[2]{\KL\pa{#1 | #2}}
% \newcommand{\KLproj}{P^{\tiny\KL}}
% \def\ones{\mathbb{I}} \]

%% Installing toolboxes and setting up the path.

%%
% You need to download the following files: 
% <../toolbox_signal.zip signal toolbox> and 
% <../toolbox_general.zip general toolbox>.

%%
% You need to unzip these toolboxes in your working directory, so
% that you have 
% |toolbox_signal| and 
% |toolbox_general|
% in your directory.

%%
% *For Scilab user:* you must replace the Matlab comment '%' by its Scilab
% counterpart '//'.

%%
% *Recommandation:* You should create a text file named for instance |numericaltour.sce| (in Scilab) or |numericaltour.m| (in Matlab) to write all the
% Scilab/Matlab command you want to execute. Then, simply run |exec('numericaltour.sce');| (in Scilab) or |numericaltour;| (in Matlab) to run the commands. 

%%
% Execute this line only if you are using Matlab.

getd = @(p)path(p,path); % scilab users must *not* execute this

%%
% Then you can add the toolboxes to the path.

getd('toolbox_signal/');
getd('toolbox_general/');

%% Entropic Regularization of Optimal Transport
% We consider two input histograms \(p,q \in \Si_N\), where we denote the simplex in \(\RR^N\)
% \[ \Si_{N} = \enscond{ p \in (\RR^+)^N }{ \sum_i p_i = 1 }.  \]
% We consider the following discrete regularized transport
% \[  W_\ga(p,q) = \umin{\pi \in \Pi(p,q)} \dotp{C}{\pi} - \ga E(\pi).  \]
% where the polytope of coupling is defined as
% \[ \Pi(p,q) = \enscond{\pi \in (\RR^+)^{N \times N}}{ \pi \ones = p, \pi^* \ones = q },  \]
% and for \(f \in (\RR^+)^{P}\) for some \(P > 0\), we define its entropy as
% \[ E(f) = - \sum_{i=1}^N f_i ( \log(f_i) - 1). \]

%%
% When \(\ga=0\) one recovers the classical (discrete) optimal transport.
% We refer to the monograph <#biblio [Villani]> for more details about OT.
% The idea of regularizing transport to allows for faster computation is
% introduced in <#biblio [Cuturi]>.


%%
% Here the matrix \(C \in (\RR^+)^{N \times N} \) defines the ground cost, i.e.
% \(C_{i,j}\) is the cost of moving mass from a bin indexed by \(i\) to a bin indexed by \(j\).

%%
% The regularized transportation problem can be re-written as a projection 
% \[ W_\ga(p,q) = \ga \umin{\pi \in \Pi(p,q)} \KLdiv{\pi}{\bar \pi}
% 	\qwhereq
% 	\bar\pi_{i,j} = e^{ -\frac{C_{i,j}}{\ga} }  \]
% of \(\bar\pi\) according to the Kullback-Leibler divergence. The Kullback-Leibler divergence between \(f, \bar f \in (\RR^+)^P\) is 
% \[ \KLdiv{f}{\bar f} = \sum_{i=1}^P f_{i} \pa{ \log\pa{ \frac{f_i}{\bar f_i} } - 1}. \]
% With a slight abuse of notation, we extend these definitions for vectors \(\pi \in \RR^{N \times N}\) (and also higher \(d\)-dimensional tensor arrays), so that \(P=N^2\) (or more generally \(P=N^d\)) by replacing the sum over elements \(f_i\) by \(\pi_{i,j}\) with \(i,j=1,\ldots,N\). 

%%
% Given a convex set \(\Cc \subset \RR^N\), the projection according to the Kullback-Leiber divergence is defined as
% \[ \KLproj_\Cc(\bar f) = \uargmin{ f \in \Cc } \KLdiv{f}{\bar f}. \]

%% Iterative Bregman Projection Algorithm
% Given affine constraint sets \( (\Cc_1,\ldots,\Cc_K) \), we aim at computing 
% \[   \KLproj_\Cc(\bar \pi) \qwhereq \Cc = \Cc_1 \cap \ldots \cap \Cc_K. \]

%%
% This can be achieved, starting by \(\pi_0=\bar\pi\), by iterating
% \[ \forall \ell \geq 0, \quad \pi_{\ell+1} =  \KLproj_{\Cc_\ell}(\pi_\ell), \]
% where the index of the constraints should be understood modulo \(K\),
% i.e. we set \( \Cc_{\ell+K}=\Cc_\ell \).

%%
% One can indeed show that \(\pi_\ell \rightarrow \KLproj_\Cc(\bar \pi)\).
% We refer to <#biblio [BauschkeLewis]> for more details about this
% algorithm and its extension to compute the projection on the intersection of
% convex sets (Dikstra algorithm). 

%% Iterative Projection for Regularized Transport
% We can re-cast the regularized optimal transport problem within this
% framework by introducing
% \[ \Cc_1 = \enscond{\pi \in (\RR^+)^{N \times N} }{\pi \ones = p}
% \qandq 
%  \Cc_2 = \enscond{\pi \in (\RR^+)^{N \times N} }{\pi^* \ones = q}\]

%%
% The KL projection on \(\Cc_1\) sets are easily computed by divisive
% normalization of rows. Indeed, denoting 
% \( \pi = \KLproj_{\Cc_1}(\bar \pi) \), one has
% \[ \forall (i,j), \quad
%   \pi_{i,j} = \frac{ p_i \bar\pi_{i,j} }{ \sum_{s} \bar\pi_{i,s} } \]
% and similarely for \(\KLproj_{\Cc_1}(\bar \pi) \) by replacing rows by
% colums.

%%
% Size \(N\) of the histograms.

N = 200;

%%
% Define \(\KLproj_{\Cc_1}\).

ProjC1 = @(pi,p)pi .* repmat( p./max(sum(pi,2), 1e-10), [1 N] );

%%
% Define \(\KLproj_{\Cc_2}\).

ProjC2 = @(pi,q)pi .* repmat( q'./max(sum(pi,1), 1e-10), [N 1] );

%%
% We use here a 1-D square Euclidean metric.

x = (0:N-1)'/N; y = x;
Y = repmat(y', [N 1]);
X = repmat(x, [1 N]);
C = abs(X-Y).^2;

%%
% Define the histogram \(p,q\)

Gaussian = @(x0,sigma)exp( -(x-x0).^2/(2*sigma^2) );
normalize = @(p)p/sum(p(:));
x0 = .2; y0 = .8;  sigma = .07;
p = Gaussian(x0,sigma); 
q = Gaussian(y0,sigma); 

%%
% Add some minimal mass and normalize.

vmin = .02;
p = normalize( p+max(p)*vmin);
q = normalize( q+max(q)*vmin);


%%
% Display them.

clf;
subplot(2,1,1);
bar(x, p, 'k'); axis tight;
subplot(2,1,2);
bar(y, q, 'k'); axis tight;

%%
% _Exercice 1:_ (<../missing-exo/ check the solution>)
% Perform the iterations, and display the decay of the errors
% \[ \norm{\pi_\ell \ones - p} 
%   \qandq 
%   \norm{\pi_\ell^* \ones - q} \]
% in log scale.

exo1;

%%
% Display the optimal \(\pi\).

clf;
imageplot(pi);

%%
% For visualization purpose, to more clearly see the optimal map, do a
% normalization.

normalizeMax = @(pi)pi ./ repmat( max(pi,[],1), [N 1] );
clf;
imageplot(normalizeMax(pi));

%%
% _Exercice 2:_ (<../missing-exo/ check the solution>)
% Display the transport map for several values of \(\gamma\).

exo2;
% 

%% Bibliography
% <html><a name="biblio"></a></html>

%%
% * [Villani] Villani, C. (2009). Optimal transport: old and new, volume 338. Springer Verlag.
% * [Cuturi] Cuturi, M. (2013). Sinkhorn distances: Lightspeed computation of optimal transport. In Burges, C. J. C., Bottou, L., Ghahramani, Z., and Weinberger, K. Q., editors, Proc. NIPS, pages 2292-2300.
% * [AguehCarlier] Agueh, M. and Carlier, G. (2011). Barycenters in the Wasserstein space. SIAM J. on Mathematical Analysis, 43(2):904-924.
% * [CuturiDoucet] Cuturi, M. and Doucet, A. (2014). Fast computation of wasserstein barycenters. In Proc. ICML.
% * [BauschkeLewis] H. H. Bauschke and A. S. Lewis. Dykstra's algorithm with Bregman projections: a convergence proof. Optimization, 48(4):409-427, 2000.

##### SOURCE END #####
-->
   </body>
</html>