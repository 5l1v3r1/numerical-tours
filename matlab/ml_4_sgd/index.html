
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN">
<html xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      --><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script><p style="font-size:0px">
         \[
         \newcommand{\NN}{\mathbb{N}}
         \newcommand{\CC}{\mathbb{C}}
         \newcommand{\GG}{\mathbb{G}}
         \newcommand{\LL}{\mathbb{L}}
         \newcommand{\PP}{\mathbb{P}}
         \newcommand{\QQ}{\mathbb{Q}}
         \newcommand{\RR}{\mathbb{R}}
         \newcommand{\VV}{\mathbb{V}}
         \newcommand{\ZZ}{\mathbb{Z}}
         \newcommand{\FF}{\mathbb{F}}
         \newcommand{\KK}{\mathbb{K}}
         \newcommand{\UU}{\mathbb{U}}
         \newcommand{\EE}{\mathbb{E}}
         
         \newcommand{\Aa}{\mathcal{A}}
         \newcommand{\Bb}{\mathcal{B}}
         \newcommand{\Cc}{\mathcal{C}}
         \newcommand{\Dd}{\mathcal{D}}
         \newcommand{\Ee}{\mathcal{E}}
         \newcommand{\Ff}{\mathcal{F}}
         \newcommand{\Gg}{\mathcal{G}}
         \newcommand{\Hh}{\mathcal{H}}
         \newcommand{\Ii}{\mathcal{I}}
         \newcommand{\Jj}{\mathcal{J}}
         \newcommand{\Kk}{\mathcal{K}}
         \newcommand{\Ll}{\mathcal{L}}
         \newcommand{\Mm}{\mathcal{M}}
         \newcommand{\Nn}{\mathcal{N}}
         \newcommand{\Oo}{\mathcal{O}}
         \newcommand{\Pp}{\mathcal{P}}
         \newcommand{\Qq}{\mathcal{Q}}
         \newcommand{\Rr}{\mathcal{R}}
         \newcommand{\Ss}{\mathcal{S}}
         \newcommand{\Tt}{\mathcal{T}}
         \newcommand{\Uu}{\mathcal{U}}
         \newcommand{\Vv}{\mathcal{V}}
         \newcommand{\Ww}{\mathcal{W}}
         \newcommand{\Xx}{\mathcal{X}}
         \newcommand{\Yy}{\mathcal{Y}}
         \newcommand{\Zz}{\mathcal{Z}}
         
         \newcommand{\al}{\alpha}
         \newcommand{\la}{\lambda}
         \newcommand{\ga}{\gamma}
         \newcommand{\Ga}{\Gamma}
         \newcommand{\La}{\Lambda}
         \newcommand{\Si}{\Sigma}
         \newcommand{\si}{\sigma}
         \newcommand{\be}{\beta}
         \newcommand{\de}{\delta}
         \newcommand{\De}{\Delta}
         \renewcommand{\phi}{\varphi}
         \renewcommand{\th}{\theta}
         \newcommand{\om}{\omega}
         \newcommand{\Om}{\Omega}
         \renewcommand{\epsilon}{\varepsilon}
         
         \newcommand{\Calpha}{\mathrm{C}^\al}
         \newcommand{\Cbeta}{\mathrm{C}^\be}
         \newcommand{\Cal}{\text{C}^\al}
         \newcommand{\Cdeux}{\text{C}^{2}}
         \newcommand{\Cun}{\text{C}^{1}}
         \newcommand{\Calt}[1]{\text{C}^{#1}}
         
         \newcommand{\lun}{\ell^1}
         \newcommand{\ldeux}{\ell^2}
         \newcommand{\linf}{\ell^\infty}
         \newcommand{\ldeuxj}{{\ldeux_j}}
         \newcommand{\Lun}{\text{\upshape L}^1}
         \newcommand{\Ldeux}{\text{\upshape L}^2}
         \newcommand{\Lp}{\text{\upshape L}^p}
         \newcommand{\Lq}{\text{\upshape L}^q}
         \newcommand{\Linf}{\text{\upshape L}^\infty}
         \newcommand{\lzero}{\ell^0}
         \newcommand{\lp}{\ell^p}
         
         
         \renewcommand{\d}{\ins{d}}
         
         \newcommand{\Grad}{\text{Grad}}
         \newcommand{\grad}{\text{grad}}
         \renewcommand{\div}{\text{div}}
         \newcommand{\diag}{\text{diag}}
         
         \newcommand{\pd}[2]{ \frac{ \partial #1}{\partial #2} }
         \newcommand{\pdd}[2]{ \frac{ \partial^2 #1}{\partial #2^2} }
         
         \newcommand{\dotp}[2]{\langle #1,\,#2\rangle}
         \newcommand{\norm}[1]{|\!| #1 |\!|}
         \newcommand{\normi}[1]{\norm{#1}_{\infty}}
         \newcommand{\normu}[1]{\norm{#1}_{1}}
         \newcommand{\normz}[1]{\norm{#1}_{0}}
         \newcommand{\abs}[1]{\vert #1 \vert}
         
         \newcommand{\argmin}{\text{argmin}}
         \newcommand{\argmax}{\text{argmax}}
         \newcommand{\uargmin}[1]{\underset{#1}{\argmin}\;}
         \newcommand{\uargmax}[1]{\underset{#1}{\argmax}\;}
         \newcommand{\umin}[1]{\underset{#1}{\min}\;}
         \newcommand{\umax}[1]{\underset{#1}{\max}\;}
         
         \newcommand{\pa}[1]{\left( #1 \right)}
         \newcommand{\choice}[1]{ \left\{  \begin{array}{l} #1 \end{array} \right. }
         
         \newcommand{\enscond}[2]{ \left\{ #1 \;:\; #2 \right\} }
         
         \newcommand{\qandq}{ \quad \text{and} \quad }
         \newcommand{\qqandqq}{ \qquad \text{and} \qquad }
         \newcommand{\qifq}{ \quad \text{if} \quad }
         \newcommand{\qqifqq}{ \qquad \text{if} \qquad }
         \newcommand{\qwhereq}{ \quad \text{where} \quad }
         \newcommand{\qqwhereqq}{ \qquad \text{where} \qquad }
         \newcommand{\qwithq}{ \quad \text{with} \quad }
         \newcommand{\qqwithqq}{ \qquad \text{with} \qquad }
         \newcommand{\qforq}{ \quad \text{for} \quad }
         \newcommand{\qqforqq}{ \qquad \text{for} \qquad }
         \newcommand{\qqsinceqq}{ \qquad \text{since} \qquad }
         \newcommand{\qsinceq}{ \quad \text{since} \quad }
         \newcommand{\qarrq}{\quad\Longrightarrow\quad}
         \newcommand{\qqarrqq}{\quad\Longrightarrow\quad}
         \newcommand{\qiffq}{\quad\Longleftrightarrow\quad}
         \newcommand{\qqiffqq}{\qquad\Longleftrightarrow\qquad}
         \newcommand{\qsubjq}{ \quad \text{subject to} \quad }
         \newcommand{\qqsubjqq}{ \qquad \text{subject to} \qquad }
         
         \newcommand{\eqdef}{\equiv}
         \]
         
      </p>
      <title>Stochastic Gradient descent</title>
      <NOSCRIPT>
         <DIV STYLE="color:#CC0000; text-align:center"><B>Warning: <A HREF="http://www.math.union.edu/locate/jsMath">jsMath</A>
               	requires JavaScript to process the mathematics on this page.<BR>
               	If your browser supports JavaScript, be sure it is enabled.</B></DIV>
         <HR>
      </NOSCRIPT>
      <meta name="generator" content="MATLAB 9.0">
      <meta name="date" content="2017-08-11">
      <meta name="m-file" content="index">
      <LINK REL="stylesheet" HREF="../style.css" TYPE="text/css">
   </head>
   <body>
      <div class="content">
         <h1>Stochastic Gradient descent</h1>
         <introduction>
            <p>This tour details Stochastic Gradient Descent, applied to the binary logistic classification problem.</p>
         </introduction>
         <h2>Contents</h2>
         <div>
            <ul>
               <li><a href="#3">Installing toolboxes and setting up the path.</a></li>
               <li><a href="#11">Dataset Loading</a></li>
               <li><a href="#17">Batch Gradient Descent (BGD)</a></li>
               <li><a href="#22">Stochastic Gradient Descent (SGD)</a></li>
               <li><a href="#31">Stochastic Gradient Descent with Averaging (SGA)</a></li>
               <li><a href="#38">Stochastic Averaged Gradient Descent (SAG)</a></li>
            </ul>
         </div>
         <p>We recommend that after doing this Numerical Tours, you apply it to your own data, for instance using a dataset from <a href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/">LibSVM</a>.
         </p>
         <p><i>Disclaimer:</i> these machine learning tours are intended to be overly-simplistic implementations and applications of baseline machine learning
            methods. For more advanced uses and implementations, we recommend to use a state-of-the-art library, the most well known being
            <a href="http://scikit-learn.org/">Scikit-Learn</a></p>
         <h2>Installing toolboxes and setting up the path.<a name="3"></a></h2>
         <p>You need to download the following files: <a href="../toolbox_general.zip">general toolbox</a>.
         </p>
         <p>You need to unzip these toolboxes in your working directory, so that you have <tt>toolbox_general</tt> in your directory.
         </p>
         <p><b>For Scilab user:</b> you must replace the Matlab comment '%' by its Scilab counterpart '//'.
         </p>
         <p><b>Recommandation:</b> You should create a text file named for instance <tt>numericaltour.sce</tt> (in Scilab) or <tt>numericaltour.m</tt> (in Matlab) to write all the Scilab/Matlab command you want to execute. Then, simply run <tt>exec('numericaltour.sce');</tt> (in Scilab) or <tt>numericaltour;</tt> (in Matlab) to run the commands.
         </p>
         <p>Execute this line only if you are using Matlab.</p><pre class="codeinput">getd = @(p)path(p,path); <span class="comment">% scilab users must *not* execute this</span>
</pre><p>Then you can add the toolboxes to the path.</p><pre class="codeinput">getd(<span class="string">'toolbox_general/'</span>);
</pre><p>First define a few helpers.</p><pre class="codeinput">SetAR = @(ar)set(gca, <span class="string">'PlotBoxAspectRatio'</span>, [1 ar 1], <span class="string">'FontSize'</span>, 20);
Xm = @(X)X-repmat(mean(X,1), [size(X,1) 1]);
Cov = @(X)Xm(X)'*Xm(X);
</pre><h2>Dataset Loading<a name="11"></a></h2>
         <p>We load a subset of the <a href="http://osmot.cs.cornell.edu/kddcup/datasets.html">dataset Quantum Physics Dataset</a> of \(n=10000\) features in dimension \(78\). The goal in this task is to learn a classification rule that differentiates
            between two types of particles generated in high energy collider experiments.
         </p>
         <p>Load the dataset. Randomly permute it. Separate the features \(X\) from the data \(y\) to predict information.</p><pre class="codeinput">name = <span class="string">'quantum'</span>;
load([<span class="string">'ml-'</span> name]);
A = A(randperm(size(A,1)),:);
X = A(:,1:end-1);
y = A(:,end);
</pre><p>Set the classes indexes to be \(\{-1,+1\}\).</p><pre class="codeinput">y = rescale(y,-1,1);
</pre><p>Remove empty features, normalize \(X\).</p><pre class="codeinput">I = find(mean(abs(X))&gt;1e-1); X = X(:,I);
X = X-repmat(mean(X),[size(X,1),1]);
X = X ./ repmat( sqrt(sum(X.^2)/size(X,1)), [size(X,1),1] );
</pre><p>\(n\) is the number of samples, \(p\) is the dimensionality of the features,</p><pre class="codeinput">[n,p] = size(X);
</pre><p>Plot the classes.</p><pre class="codeinput">I = randperm(n); I = I(1:500);
options.disp_dim = 3;
clf; plot_multiclasses(X(I,:),y(I),options);
</pre><img vspace="5" hspace="5" src="index_01.png"> <h2>Batch Gradient Descent (BGD)<a name="17"></a></h2>
         <p>We first test the usual (batch) gradient descent (BGD) on the problem of supervised logistic classification.</p>
         <p>We refer to the dedicated numerical tour on logistic classification for background and more details about the derivations
            of the energy and its gradient.
         </p>
         <p>Logistic classification aims at solving the following convex program   \[ \umin{w} E(w) \eqdef \frac{1}{n} \sum_{i=1}^n L(\dotp{x_i}{w},y_i)
             \] where the logistic loss reads   \[ L( s,y ) \eqdef \log( 1+\exp(-sy) ) \]
         </p>
         <p>Define energy \(E\) and its gradient \(\nabla E\).</p><pre class="codeinput">L = @(s,y)1/n * sum( log( 1 + exp(-s.*y) ) );
E = @(w,X,y)L(X*w,y);
theta = @(v)1 ./ (1+exp(-v));
nablaL = @(s,r)- 1/n * y.* theta(-s.*y);
nablaE = @(w,X,y)X'*nablaL(X*w,y);
</pre><p><i>Exercice 1:</i> (<a href="../missing-exo/">check the solution</a>) Implement a gradient descent  \[ w_{\ell+1} = w_\ell - \tau_\ell \nabla E(w_\ell). \] Monitor the energy decay. Test different
            step size, and compare with the theory (in particular plot in log domain to illustrate the linear rate).
         </p><pre class="codeinput">exo1;
</pre><img vspace="5" hspace="5" src="index_02.png"> <h2>Stochastic Gradient Descent (SGD)<a name="22"></a></h2>
         <p>As any empirical risk minimization procedure, the logistic classification minimization problem can be written as \[ \umin{w}
            E(w) = \frac{1}{n} \sum_i E_i(w) \qwhereq E_i(w) = L(\dotp{x_i}{w},y_i). \]
         </p>
         <p>For very large \(n\) (which could in theory even be infinite, in which case the sum needs to be replaced by an expectation
            or equivalenty an integral), computing \(\nabla E\) is prohebitive. It is possible instead to use a stochastic gradient descent
            (SGD) scheme   \[ w_{\ell+1} = w_\ell - \tau_\ell \nabla E_{i(\ell)}(w_\ell) \] where, for each iteration index \(\ell\),
            \(i(\ell)\) is drawn uniformly at random in \(  \{1,\ldots,n\} \).
         </p>
         <p>Note that here \[ \nabla E_{i}(w) = x_i \nabla L( \dotp{x_i}{w}, y_i )   \qwhereq  \nabla L(u,v) = v \odot \th(-u)  \]</p><pre class="codeinput">nablaEi = @(w,i)-y(i) .* X(i,:)' * theta( -y(i) * (X(i,:)*w)  );
</pre><p>Note that each step of a batch gradient descent has complexity \(O(np)\), while a step of SGD only has complexity \(O(p)\).
            SGD is thus advantageous when \(n\) is very large, and one cannot afford to do several passes through the data. In some situation,
            SGD can provide accurate results even with \(\ell \ll n\), exploiting redundancy between the samples.
         </p>
         <p>A crucial question is the choice of step size schedule \(\tau_\ell\). It must tends to 0 in order to cancel the noise induced
            on the gradient by the stochastic sampling. But it should not go too fast to zero in order for the method to keep converging.
         </p>
         <p>A typical schedule that ensures both properties is to have asymptically \(\tau_\ell \sim \ell^{-1}\) for \(\ell\rightarrow
            +\infty\). We thus propose to use \[ \tau_\ell \eqdef \frac{\tau_0}{1 + \ell/\ell_0} \] where \(\ell_0\) indicates roughly
            the number of iterations serving as a "warmup" phase.
         </p>
         <p>One can prove the following convergence result  \[ \EE( E(w_\ell) ) - E(w^\star) = O\pa{ \frac{1}{\sqrt{\ell}} }, \] where
            \(\EE\) indicates an expectation with respect to the i.i.d. sampling performed at each iteration.
         </p>
         <p>Select default values for \( (\ell_0,\tau_0) \).</p><pre class="codeinput">l0 = 100;
tau0 = .05;
</pre><p><i>Exercice 2:</i> (<a href="../missing-exo/">check the solution</a>) Perform the Stochastic gradient descent. Display the evolution of the energy \(E(w_\ell)\). One can overlay on top (black
            dashed curve) the convergence of the batch gradient descent, with a carefull scaling of the number of iteration to account
            for the fact that the complexity of a batch iteration is \(n\) times larger. Perform several runs to illustrate the probabilistic
            nature of the method. Explore different values for \( (\ell_0,\tau_0) \).
         </p><pre class="codeinput">exo2;
</pre><img vspace="5" hspace="5" src="index_03.png"> <h2>Stochastic Gradient Descent with Averaging (SGA)<a name="31"></a></h2>
         <p>Stochastic gradient descent is slow because of the fast decay of \(\tau_\ell\) toward zero.</p>
         <p>To improve somehow the convergence speed, it is possible to average the past iterate, i.e. run a "classical" SGD on auxiliary
            variables \( (\tilde w_\ell)_\ell\)   \[ \tilde w_{\ell+1} = \tilde w_\ell - \tau_\ell \nabla E_{i(\ell)}(\tilde w_\ell) \]
            and output as estimated weight vector the average \[ w_\ell \eqdef \frac{1}{\ell} \sum_{k=1}^\ell \tilde w_\ell. \] This defines
            the Stochastic Gradient Descent with Averaging (SGA) algorithm.
         </p>
         <p>Note that it is possible to avoid explicitely storing all the iterates by simply updating a running average as follow \[ w_{\ell+1}
            = \frac{1}{\ell} \tilde w_\ell +  \frac{\ell-1}{\ell} w_\ell.  \]
         </p>
         <p>In this case, a typical choice of decay is rather of the form \[ \tau_\ell \eqdef \frac{\tau_0}{1 + \sqrt{\ell/\ell_0}}. \]
            Notice that the step size now goes much slower to 0, at rate \(\ell^{-1/2}\).
         </p>
         <p>Typically, because the averaging stabilizes the iterates, the choice of \((\ell_0,\tau_0)\) is less important than for SGD.</p>
         <p><a href="https://arxiv.org/pdf/1303.6149.pdf">Bach proves that</a> for logistic classification, it leads to a faster convergence (the constant involved are smaller) than SGD, since on contrast
            to SGD, SGA is adaptive to the local strong convexity of \(E\).
         </p>
         <p><i>Exercice 3:</i> (<a href="../missing-exo/">check the solution</a>) Implement the Stochastic gradient descent with averaging. Display the evolution of the energy \(E(w_\ell)\).
         </p><pre class="codeinput">exo3;
</pre><img vspace="5" hspace="5" src="index_04.png"> <h2>Stochastic Averaged Gradient Descent (SAG)<a name="38"></a></h2>
         <p>For problem size \(n\) where the dataset (of size \(n \times p\)) can fully fit into memory, it is possible to further improve
            the SGA method by bookeeping the previous gradient. This gives rise to the <a href="https://arxiv.org/pdf/1309.2388">Stochastic Averaged Gradient Descent (SAG)</a> algorithm.
         </p>
         <p>We stored all the previously computed gradient in \( (G^i)_{i=1}^n \), which necessitate \(n \times p\) memory. The iterates
            are defined by using a proxy \(g\) for the batch gradient, which is progressively enhanced during the iterates.
         </p>
         <p>The algorithm reads \[ h \leftarrow \nabla E_{i(\ell)}(\tilde w_\ell), \] \[ g  \leftarrow g - G^{i(\ell)} + h,   \] \[ G^{i(\ell)}
            \leftarrow h,  \] \[ w_{\ell+1} = w_\ell - \tau g.  \] Note that in contrast to SGD and SGA, this method uses a fixed step
            size \(\tau\). Similarely to the BGD, in order to ensure convergence, the step size \(\tau\) should be of the order of \(1/L\)
            where \(L\) is the Lipschitz constant of \(E\).
         </p>
         <p>This algorithm improves over SGA and BGD since it has a convergence rate of \(O(1/\ell\). Furthermore, in the presence of
            strong convexity (for instance when \(X\) is injective for logistic classification), it has a linear convergence rate, i.e.
             \[ \EE( E(w_\ell) ) - E(w^\star) = O\pa{ \rho^\ell }, \] for some \(0 &lt; \rho &lt; 1\).
         </p>
         <p>Note that this improvement over SGD and SGA is made possible only because SAG explictely use the fact that \(n\) is finite
            (while SGD and SGA can be extended to infinite \(n\) and more general minimization of expectations).
         </p>
         <p><i>Exercice 4:</i> (<a href="../missing-exo/">check the solution</a>) Implement SAG. Display the evolution of the energy \(E(w_\ell)\).
         </p><pre class="codeinput">exo4;
</pre><img vspace="5" hspace="5" src="index_05.png"> <p class="footer"><br>
            Copyright  (c) 2010 Gabriel Peyre<br></p>
      </div>
      <!--
##### SOURCE BEGIN #####
%% Stochastic Gradient descent
% This tour details Stochastic Gradient Descent, applied to the binary logistic classification problem.

%%
% We recommend that after doing this Numerical Tours, you apply it to your
% own data, for instance using a dataset from <https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/ LibSVM>.

%%
% _Disclaimer:_ these machine learning tours are intended to be
% overly-simplistic implementations and applications of baseline machine learning methods. 
% For more advanced uses and implementations, we recommend
% to use a state-of-the-art library, the most well known being
% <http://scikit-learn.org/ Scikit-Learn>

%% Installing toolboxes and setting up the path.

%%
% You need to download the following files: 
% <../toolbox_general.zip general toolbox>.

%%
% You need to unzip these toolboxes in your working directory, so
% that you have 
% |toolbox_general|
% in your directory.

%%
% *For Scilab user:* you must replace the Matlab comment '%' by its Scilab
% counterpart '//'.

%%
% *Recommandation:* You should create a text file named for instance |numericaltour.sce| (in Scilab) or |numericaltour.m| (in Matlab) to write all the
% Scilab/Matlab command you want to execute. Then, simply run |exec('numericaltour.sce');| (in Scilab) or |numericaltour;| (in Matlab) to run the commands. 

%%
% Execute this line only if you are using Matlab.

getd = @(p)path(p,path); % scilab users must *not* execute this

%%
% Then you can add the toolboxes to the path.

getd('toolbox_general/');

%%
% First define a few helpers.

SetAR = @(ar)set(gca, 'PlotBoxAspectRatio', [1 ar 1], 'FontSize', 20);
Xm = @(X)X-repmat(mean(X,1), [size(X,1) 1]);
Cov = @(X)Xm(X)'*Xm(X);


%% Dataset Loading
% We load a subset of the <http://osmot.cs.cornell.edu/kddcup/datasets.html
% dataset Quantum Physics Dataset>
% of \(n=10000\) features in dimension \(78\). The goal in this task is to learn a classification rule that differentiates between two types of particles generated in high energy collider experiments.


%%
% Load the dataset.
% Randomly permute it.
% Separate the features \(X\) from the data \(y\) to predict information.

name = 'quantum';
load(['ml-' name]);
A = A(randperm(size(A,1)),:);
X = A(:,1:end-1);
y = A(:,end);

%%
% Set the classes indexes to be \(\{-1,+1\}\).

y = rescale(y,-1,1);

%%
% Remove empty features, normalize \(X\).

I = find(mean(abs(X))>1e-1); X = X(:,I);
X = X-repmat(mean(X),[size(X,1),1]);
X = X ./ repmat( sqrt(sum(X.^2)/size(X,1)), [size(X,1),1] );

%%
% \(n\) is the number of samples, \(p\) is the dimensionality of the features,

[n,p] = size(X);

%%
% Plot the classes.

I = randperm(n); I = I(1:500);
options.disp_dim = 3;
clf; plot_multiclasses(X(I,:),y(I),options);

%% Batch Gradient Descent (BGD)
% We first test the usual (batch) gradient descent (BGD) on the problem of
% supervised logistic classification.

%%
% We refer to the dedicated numerical tour on logistic classification for
% background and more details about the derivations of the energy and its
% gradient.

%%
% Logistic classification aims at solving the following convex program
%   \[ \umin{w} E(w) \eqdef \frac{1}{n} \sum_{i=1}^n L(\dotp{x_i}{w},y_i)  \]
% where the logistic loss reads
%   \[ L( s,y ) \eqdef \log( 1+\exp(-sy) ) \]

%% 
% Define energy \(E\) and its gradient \(\nabla E\).

L = @(s,y)1/n * sum( log( 1 + exp(-s.*y) ) );
E = @(w,X,y)L(X*w,y);
theta = @(v)1 ./ (1+exp(-v));
nablaL = @(s,r)- 1/n * y.* theta(-s.*y);
nablaE = @(w,X,y)X'*nablaL(X*w,y);

%%
% _Exercice 1:_ (<../missing-exo/ check the solution>)
% Implement a gradient descent
%  \[ w_{\ell+1} = w_\ell - \tau_\ell \nabla E(w_\ell). \]
% Monitor the energy decay.
% Test different step size, and compare with the theory (in particular
% plot in log domain to illustrate the linear rate).

exo1;

%% Stochastic Gradient Descent (SGD)
% As any empirical risk minimization procedure, the 
% logistic classification minimization problem can be written as 
% \[ \umin{w} E(w) = \frac{1}{n} \sum_i E_i(w) \qwhereq E_i(w) = L(\dotp{x_i}{w},y_i). \]

%%
% For very large \(n\) (which could in theory even be infinite, in which case the sum needs to be replaced 
% by an expectation or equivalenty an integral), computing \(\nabla E\) is prohebitive.  
% It is possible instead to use a stochastic gradient descent (SGD) scheme
%   \[ w_{\ell+1} = w_\ell - \tau_\ell \nabla E_{i(\ell)}(w_\ell) \]
% where, for each iteration index \(\ell\), \(i(\ell)\)
% is drawn uniformly at random in \(  \{1,\ldots,n\} \). 

%%
% Note that here
% \[ \nabla E_{i}(w) = x_i \nabla L( \dotp{x_i}{w}, y_i )
%   \qwhereq  \nabla L(u,v) = v \odot \th(-u)  \]

nablaEi = @(w,i)-y(i) .* X(i,:)' * theta( -y(i) * (X(i,:)*w)  );

%%
% Note that each step of a batch gradient descent has complexity \(O(np)\),
% while a step of SGD only has complexity \(O(p)\). SGD is thus
% advantageous when \(n\) is very large, and one cannot afford to do
% several passes through the data. In some situation, SGD can provide
% accurate results even with \(\ell \ll n\), exploiting redundancy between
% the samples.  

%%
% A crucial question is the choice of step size schedule \(\tau_\ell\). It
% must tends to 0 in order to cancel the noise induced on the gradient by
% the stochastic sampling. But it should not go too fast to zero in order
% for the method to keep converging. 

%%
% A typical schedule that ensures both properties is to have asymptically \(\tau_\ell \sim \ell^{-1}\) for
% \(\ell\rightarrow +\infty\). We thus propose to use 
% \[ \tau_\ell \eqdef \frac{\tau_0}{1 + \ell/\ell_0} \]
% where \(\ell_0\) indicates roughly the number of iterations serving as a
% "warmup" phase.

%%
% One can prove the following convergence result
%  \[ \EE( E(w_\ell) ) - E(w^\star) = O\pa{ \frac{1}{\sqrt{\ell}} }, \]
% where \(\EE\) indicates an expectation with respect to the i.i.d.
% sampling performed at each iteration.

%%
% Select default values for \( (\ell_0,\tau_0) \).

l0 = 100;
tau0 = .05;

%%
% _Exercice 2:_ (<../missing-exo/ check the solution>)
% Perform the Stochastic gradient descent.
% Display the evolution of the energy \(E(w_\ell)\). 
% One can overlay on top (black dashed curve) the convergence of the batch gradient descent, with a carefull scaling of the 
% number of iteration to account for the fact that the complexity of a batch iteration is \(n\) times larger. 
% Perform several runs to illustrate the probabilistic nature of the method.
% Explore different values for \( (\ell_0,\tau_0) \).

exo2;

%% Stochastic Gradient Descent with Averaging (SGA)
% Stochastic gradient descent is slow because of the fast decay of
% \(\tau_\ell\) toward zero.

%%
% To improve somehow the convergence speed, it is possible to average the past
% iterate, i.e. run a "classical" SGD on auxiliary variables \( (\tilde w_\ell)_\ell\)
%   \[ \tilde w_{\ell+1} = \tilde w_\ell - \tau_\ell \nabla E_{i(\ell)}(\tilde w_\ell) \]
% and output as estimated weight vector the average
% \[ w_\ell \eqdef \frac{1}{\ell} \sum_{k=1}^\ell \tilde w_\ell. \]
% This defines the Stochastic Gradient Descent with Averaging (SGA)
% algorithm.

%%
% Note that it is possible to avoid explicitely storing all the iterates by simply
% updating a running average as follow
% \[ w_{\ell+1} = \frac{1}{\ell} \tilde w_\ell +  \frac{\ell-1}{\ell} w_\ell.  \]

%%
% In this case, a typical choice of decay is rather of the form 
% \[ \tau_\ell \eqdef \frac{\tau_0}{1 + \sqrt{\ell/\ell_0}}. \]
% Notice that the step size now goes much slower to 0, at rate \(\ell^{-1/2}\).

%%
% Typically, because the averaging stabilizes the iterates, the choice of
% \((\ell_0,\tau_0)\) is less important than for SGD. 

%%
% <https://arxiv.org/pdf/1303.6149.pdf Bach proves that> for logistic classification, 
% it leads to a faster convergence (the constant involved are
% smaller) than SGD, since 
% on contrast to SGD, SGA is adaptive to the local strong convexity of \(E\).

%%
% _Exercice 3:_ (<../missing-exo/ check the solution>)
% Implement the Stochastic gradient descent with averaging. 
% Display the evolution of the energy \(E(w_\ell)\).

exo3;


%% Stochastic Averaged Gradient Descent (SAG)
% For problem size \(n\) where the dataset (of size \(n \times p\)) can
% fully fit into memory, it is possible to further improve the SGA method
% by bookeeping the previous gradient. This gives rise to the 
% <https://arxiv.org/pdf/1309.2388 Stochastic Averaged Gradient Descent (SAG)> algorithm.

%%
% We stored all the previously computed gradient in \( (G^i)_{i=1}^n \),
% which necessitate \(n \times p\) memory. 
% The iterates are defined by using a proxy \(g\) for the batch gradient,
% which is progressively enhanced during the iterates.

%%
% The algorithm reads
% \[ h \leftarrow \nabla E_{i(\ell)}(\tilde w_\ell), \]
% \[ g  \leftarrow g - G^{i(\ell)} + h,   \]
% \[ G^{i(\ell)} \leftarrow h,  \]
% \[ w_{\ell+1} = w_\ell - \tau g.  \]
% Note that in contrast to SGD and SGA, this method uses a fixed step
% size \(\tau\). Similarely to the BGD, in order to ensure convergence, 
% the step size \(\tau\) should be of the order of \(1/L\)
% where \(L\) is the Lipschitz constant of \(E\).

%%
% This algorithm improves over SGA and BGD
% since it has a convergence rate of \(O(1/\ell\). 
% Furthermore, in the presence of strong convexity (for instance when \(X\) is
% injective for logistic classification), it has a linear convergence rate, 
% i.e. 
%  \[ \EE( E(w_\ell) ) - E(w^\star) = O\pa{ \rho^\ell }, \]
% for some \(0 < \rho < 1\). 

%%
% Note that this improvement over SGD and SGA is made possible only because
% SAG explictely use the fact that \(n\) is finite (while SGD and SGA can
% be extended to infinite \(n\) and more general minimization of
% expectations).


%%
% _Exercice 4:_ (<../missing-exo/ check the solution>)
% Implement SAG.
% Display the evolution of the energy \(E(w_\ell)\).

exo4;


##### SOURCE END #####
-->
   </body>
</html>