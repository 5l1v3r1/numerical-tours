
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN">
<html xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      --><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script><p style="font-size:0px">
         \[
         \newcommand{\NN}{\mathbb{N}}
         \newcommand{\CC}{\mathbb{C}}
         \newcommand{\GG}{\mathbb{G}}
         \newcommand{\LL}{\mathbb{L}}
         \newcommand{\PP}{\mathbb{P}}
         \newcommand{\QQ}{\mathbb{Q}}
         \newcommand{\RR}{\mathbb{R}}
         \newcommand{\VV}{\mathbb{V}}
         \newcommand{\ZZ}{\mathbb{Z}}
         \newcommand{\FF}{\mathbb{F}}
         \newcommand{\KK}{\mathbb{K}}
         \newcommand{\UU}{\mathbb{U}}
         \newcommand{\EE}{\mathbb{E}}
         
         \newcommand{\Aa}{\mathcal{A}}
         \newcommand{\Bb}{\mathcal{B}}
         \newcommand{\Cc}{\mathcal{C}}
         \newcommand{\Dd}{\mathcal{D}}
         \newcommand{\Ee}{\mathcal{E}}
         \newcommand{\Ff}{\mathcal{F}}
         \newcommand{\Gg}{\mathcal{G}}
         \newcommand{\Hh}{\mathcal{H}}
         \newcommand{\Ii}{\mathcal{I}}
         \newcommand{\Jj}{\mathcal{J}}
         \newcommand{\Kk}{\mathcal{K}}
         \newcommand{\Ll}{\mathcal{L}}
         \newcommand{\Mm}{\mathcal{M}}
         \newcommand{\Nn}{\mathcal{N}}
         \newcommand{\Oo}{\mathcal{O}}
         \newcommand{\Pp}{\mathcal{P}}
         \newcommand{\Qq}{\mathcal{Q}}
         \newcommand{\Rr}{\mathcal{R}}
         \newcommand{\Ss}{\mathcal{S}}
         \newcommand{\Tt}{\mathcal{T}}
         \newcommand{\Uu}{\mathcal{U}}
         \newcommand{\Vv}{\mathcal{V}}
         \newcommand{\Ww}{\mathcal{W}}
         \newcommand{\Xx}{\mathcal{X}}
         \newcommand{\Yy}{\mathcal{Y}}
         \newcommand{\Zz}{\mathcal{Z}}
         
         \newcommand{\al}{\alpha}
         \newcommand{\la}{\lambda}
         \newcommand{\ga}{\gamma}
         \newcommand{\Ga}{\Gamma}
         \newcommand{\La}{\Lambda}
         \newcommand{\Si}{\Sigma}
         \newcommand{\si}{\sigma}
         \newcommand{\be}{\beta}
         \newcommand{\de}{\delta}
         \newcommand{\De}{\Delta}
         \renewcommand{\phi}{\varphi}
         \renewcommand{\th}{\theta}
         \newcommand{\om}{\omega}
         \newcommand{\Om}{\Omega}
         \renewcommand{\epsilon}{\varepsilon}
         
         \newcommand{\Calpha}{\mathrm{C}^\al}
         \newcommand{\Cbeta}{\mathrm{C}^\be}
         \newcommand{\Cal}{\text{C}^\al}
         \newcommand{\Cdeux}{\text{C}^{2}}
         \newcommand{\Cun}{\text{C}^{1}}
         \newcommand{\Calt}[1]{\text{C}^{#1}}
         
         \newcommand{\lun}{\ell^1}
         \newcommand{\ldeux}{\ell^2}
         \newcommand{\linf}{\ell^\infty}
         \newcommand{\ldeuxj}{{\ldeux_j}}
         \newcommand{\Lun}{\text{\upshape L}^1}
         \newcommand{\Ldeux}{\text{\upshape L}^2}
         \newcommand{\Lp}{\text{\upshape L}^p}
         \newcommand{\Lq}{\text{\upshape L}^q}
         \newcommand{\Linf}{\text{\upshape L}^\infty}
         \newcommand{\lzero}{\ell^0}
         \newcommand{\lp}{\ell^p}
         
         
         \renewcommand{\d}{\ins{d}}
         
         \newcommand{\Grad}{\text{Grad}}
         \newcommand{\grad}{\text{grad}}
         \renewcommand{\div}{\text{div}}
         \newcommand{\diag}{\text{diag}}
         
         \newcommand{\pd}[2]{ \frac{ \partial #1}{\partial #2} }
         \newcommand{\pdd}[2]{ \frac{ \partial^2 #1}{\partial #2^2} }
         
         \newcommand{\dotp}[2]{\langle #1,\,#2\rangle}
         \newcommand{\norm}[1]{|\!| #1 |\!|}
         \newcommand{\normi}[1]{\norm{#1}_{\infty}}
         \newcommand{\normu}[1]{\norm{#1}_{1}}
         \newcommand{\normz}[1]{\norm{#1}_{0}}
         \newcommand{\abs}[1]{\vert #1 \vert}
         
         
         \newcommand{\argmin}{\text{argmin}}
         \newcommand{\argmax}{\text{argmax}}
         \newcommand{\uargmin}[1]{\underset{#1}{\argmin}\;}
         \newcommand{\uargmax}[1]{\underset{#1}{\argmax}\;}
         \newcommand{\umin}[1]{\underset{#1}{\min}\;}
         \newcommand{\umax}[1]{\underset{#1}{\max}\;}
         
         \newcommand{\pa}[1]{\left( #1 \right)}
         \newcommand{\choice}[1]{ \left\{  \begin{array}{l} #1 \end{array} \right. }
         
         \newcommand{\enscond}[2]{ \left\{ #1 \;:\; #2 \right\} }
         
         \newcommand{\qandq}{ \quad \text{and} \quad }
         \newcommand{\qqandqq}{ \qquad \text{and} \qquad }
         \newcommand{\qifq}{ \quad \text{if} \quad }
         \newcommand{\qqifqq}{ \qquad \text{if} \qquad }
         \newcommand{\qwhereq}{ \quad \text{where} \quad }
         \newcommand{\qqwhereqq}{ \qquad \text{where} \qquad }
         \newcommand{\qwithq}{ \quad \text{with} \quad }
         \newcommand{\qqwithqq}{ \qquad \text{with} \qquad }
         \newcommand{\qforq}{ \quad \text{for} \quad }
         \newcommand{\qqforqq}{ \qquad \text{for} \qquad }
         \newcommand{\qqsinceqq}{ \qquad \text{since} \qquad }
         \newcommand{\qsinceq}{ \quad \text{since} \quad }
         \newcommand{\qarrq}{\quad\Longrightarrow\quad}
         \newcommand{\qqarrqq}{\quad\Longrightarrow\quad}
         \newcommand{\qiffq}{\quad\Longleftrightarrow\quad}
         \newcommand{\qqiffqq}{\qquad\Longleftrightarrow\qquad}
         \newcommand{\qsubjq}{ \quad \text{subject to} \quad }
         \newcommand{\qqsubjqq}{ \qquad \text{subject to} \qquad }
         \]
         
      </p>
      <title>Tensor-driven Diffusion Flows</title>
      <NOSCRIPT>
         <DIV STYLE="color:#CC0000; text-align:center"><B>Warning: <A HREF="http://www.math.union.edu/locate/jsMath">jsMath</A> 
               	requires JavaScript to process the mathematics on this page.<BR> 
               	If your browser supports JavaScript, be sure it is enabled.</B></DIV>
         <HR>
      </NOSCRIPT>
      <meta name="generator" content="MATLAB 8.2">
      <meta name="date" content="2014-10-21">
      <meta name="m-file" content="index">
      <LINK REL="stylesheet" HREF="../style.css" TYPE="text/css">
   </head>
   <body>
      <div class="content">
         <h1>Tensor-driven Diffusion Flows</h1>
         <introduction>
            <p>This numerical tour explores the structure tensor to represent the geometry of images and textures. It applies it to perform
               anisotropic image diffusion. A good reference for diffusion flows in image processing is <a href="#biblio">[Weickert98]</a>.
            </p>
         </introduction>
         <h2>Contents</h2>
         <div>
            <ul>
               <li><a href="#1">Installing toolboxes and setting up the path.</a></li>
               <li><a href="#8">Helpers Functions</a></li>
               <li><a href="#21">Structure Tensor</a></li>
               <li><a href="#31">Eigen-decomposition and Anisotropy</a></li>
               <li><a href="#43">Tensor Driven Anisotropic Diffusion</a></li>
               <li><a href="#63">Bibliography</a></li>
            </ul>
         </div>
         <h2>Installing toolboxes and setting up the path.<a name="1"></a></h2>
         <p>You need to download the following files: <a href="../toolbox_signal.zip">signal toolbox</a> and <a href="../toolbox_general.zip">general toolbox</a>.
         </p>
         <p>You need to unzip these toolboxes in your working directory, so that you have <tt>toolbox_signal</tt> and <tt>toolbox_general</tt> in your directory.
         </p>
         <p><b>For Scilab user:</b> you must replace the Matlab comment '%' by its Scilab counterpart '//'.
         </p>
         <p><b>Recommandation:</b> You should create a text file named for instance <tt>numericaltour.sce</tt> (in Scilab) or <tt>numericaltour.m</tt> (in Matlab) to write all the Scilab/Matlab command you want to execute. Then, simply run <tt>exec('numericaltour.sce');</tt> (in Scilab) or <tt>numericaltour;</tt> (in Matlab) to run the commands.
         </p>
         <p>Execute this line only if you are using Matlab.</p><pre class="codeinput">getd = @(p)path(p,path); <span class="comment">% scilab users must *not* execute this</span>
</pre><p>Then you can add the toolboxes to the path.</p><pre class="codeinput">getd(<span class="string">'toolbox_signal/'</span>);
getd(<span class="string">'toolbox_general/'</span>);
</pre><h2>Helpers Functions<a name="8"></a></h2>
         <p>We define here a few features (convolution, gradient, etc.) that will be used in the sequel.</p>
         <p>Size of the image of \(N=n \times n\) pixels.</p><pre class="codeinput">n = 256;
</pre><p>Load an image \(f\).</p><pre class="codeinput">name = <span class="string">'hibiscus'</span>;
f = load_image(name,n);
f = rescale( sum(f,3) );
</pre><p>Display it.</p><pre class="codeinput">clf;
imageplot(f);
</pre><img vspace="5" hspace="5" src="index_01.png"> <p>We define circular convolution \[ (f \star h)_i = \sum_j f_j h_{i-j}. \] Note that here, \(f\) can be multi-channel, in which
            case each channel is convolved with \(h\). This will be useful to blur tensor fields.
         </p><pre class="codeinput">cconv = @(f,h)real(ifft2(fft2(f).*repmat(fft2(h),[1 1 size(f,3)])));
</pre><p>Define a Gaussian blurring kernel of width \(\si\): \[ h_\si(x) = \frac{1}{Z} e^{ -\frac{x_1^2+x_2^2}{2\si^2} }\] where \(Z\)
            ensures that \(\hat h_\si(0)=1\).
         </p><pre class="codeinput">t = [0:n/2 -n/2+1:-1];
[X2,X1] = meshgrid(t,t);
normalize = @(h)h/sum(h(:));
h = @(sigma)normalize( exp( -(X1.^2+X2.^2)/(2*sigma^2) ) );
</pre><p>Define the convolution with \(h_\si\).</p><pre class="codeinput">blur = @(f,sigma)cconv(f,h(sigma));
</pre><p>We use in the following a centered finite difference approximation of \(\nabla f\), which is a vector field in \(\RR^{n \times
            n \times 2}\).
         </p><pre class="codeinput">options.order = 2;
nabla = @(f)grad(f,options);
</pre><p>We define the tensor product associated to a vector \(u = (u_1,u_2), v=(u_1,u_2) \in \RR^{2}\) as the symetric matrix \[ 
                 u \otimes v = u v^* =       \begin{pmatrix} u_1 v_1 &amp; v_1 u_2 \\&nbsp;u_1 v_2 &amp; u_2 v_2 \end{pmatrix}   \in \RR^{2 \times
            2}. \] It is extended to vector fields \( (u(x))_x \in \RR^{N \times 2} \) as \[  (u \otimes v)(x) = u(x) \otimes v(x) \]
         </p>
         <p>A tensor field \(T\) is a collection of symmetric positive definite matrices \(T(x) \in \RR^{2 \times 2}\).</p>
         <p>A simple way to build a tensor field is by auto-tensorization of a vector field \(u(x)\), i.e. \(T = u \otimes u\).</p>
         <p>Define a shortcut for \(u \otimes u\) (we make use of symmetry to only store 3 components).</p><pre class="codeinput">tensorize = @(u)cat(3, u(:,:,1).^2, u(:,:,2).^2, u(:,:,1).*u(:,:,2));
</pre><p>Rotate a tensor field by \(\pi/2\) (for display only).</p><pre class="codeinput">rotate = @(T)cat(3, T(:,:,2), T(:,:,1), -T(:,:,3));
</pre><h2>Structure Tensor<a name="21"></a></h2>
         <p>The structure tensor is a field of symetric positive matrices that encodes the local orientation and anisotropy of an image.</p>
         <p>It was initially introduced for corner detection <a href="#biblio">[HarSteph88]</a> <a href="#biblio">[Forstner86]</a> and oriented texture analysis <a href="#biblio">[KassWit85]</a>.
         </p>
         <p>Given an image \(f\), its structure tensor with scale \( \sigma&gt;0 \) is defined as \[ T_\si = h_\si \star T_0 \qwhereq T_0
            = \nabla f \otimes \nabla f. \] For each location \(x\), \(T_\si(x)\) is thus a positive definite matrix.
         </p><pre class="codeinput">T = @(f,sigma)blur( tensorize( nabla(f) ), sigma);
</pre><p>The matrix \(T_\si(x)\) can be understood as the local covariance matrix of the set of gradient vector around \(x\).</p>
         <p>Another way to get some insight about this tensor field is to consider a localized version \(f_x\) of the image around point
            \(x\), defined by \(f_x(y) = h_\si(x-y)^{1/2} f(y)\), which is close to zero when \(y\) is far away from \(x\). One has the
            following Taylor expansion of the \(L^2\) norm between two close enough localizations: \[ \norm{f_x - f_{x+\de}}^2 = \de^*
            T_\si(x) \de + O(\norm{\de}^3). \]
         </p>
         <p>To better understand the behavior of \(T_\si\) as a function of \(\si\), one can computes its Taylor expansion for small \(\si\)
            \[ T_\si(x) = T_0(x) + \si^2 Hf(x)^2 + O(\si^3), \] where \(Hf(x) \in \RR^{2 \times 2}\) is the Hessian matrix of \(f\) at
            point \(x\). This shows that when \(\si\) increases, the intial rank-1 tensor \(T_0(x)\) becomes full rank because it integrates
            energy from \(Hf(x)^2\).
         </p>
         <p>A convenient way to display a tensor field such as \(T_\si\) is to draw an ellispe \(\Ee_x\) at each pixel \(x\) as the (scaled
            and translated) unit ball of the tensor \[ \Ee_x = \enscond{\de \in \RR^2}{ \de^* T_\si(x) \de \leq 1 }. \] This allows one
            to visualize the anisotropy and orientation encoded in the tensor field.
         </p>
         <p>Display \(T_\si\) for \(\si=0.1\) (the tensors are almost rank-1):</p><pre class="codeinput">options.sub = 8;
clf; sigma = .1;
plot_tensor_field(rotate(T(f,sigma)), f, options);
title([<span class="string">'\sigma='</span> num2str(sigma)]);
</pre><img vspace="5" hspace="5" src="index_02.png"> <p>For \(\si=4\):</p><pre class="codeinput">clf; sigma = 4;
plot_tensor_field(rotate(T(f,sigma)), f, options);
title([<span class="string">'\sigma='</span> num2str(sigma)]);
</pre><img vspace="5" hspace="5" src="index_03.png"> <p>For \(\si=10\):</p><pre class="codeinput">clf; sigma = 10;
plot_tensor_field(rotate(T(f,sigma)), f, options);
title([<span class="string">'\sigma='</span> num2str(sigma)]);
</pre><img vspace="5" hspace="5" src="index_04.png"> <h2>Eigen-decomposition and Anisotropy<a name="31"></a></h2>
         <p>A symmetric tensor field \(S(x)\) can be decomposed as \[ S(x) = \lambda_1(x) e_1(x) \otimes e_1(x) + \lambda_2(x) e_2(x)
            \otimes  e_2(x), \] where \((e_1(x),e_2(x))\) are the orthogonal eigenvector fields, \(0 \leq \lambda_2(x) \leq \lambda_1(x)\)
            are the eigenvalues.
         </p>
         <p>Compute the eigenvalues of \(S \in \RR^{2 \times 2}\) as \[ \la_i =  \frac{1}{2} \pa{ S_{1,1}+S_{2,2} \pm \sqrt{\Delta(S)}
            }       \qwhereq \Delta(S) = (S_{1,1}-S_{2,2})^2 + 4 S_{1,2}^2, \] where one should use the \(+\) sign for \(i=1\).
         </p><pre class="codeinput">delta = @(S)(S(:,:,1)-S(:,:,2)).^2 + 4*S(:,:,3).^2;
eigenval = @(S)deal( <span class="keyword">...</span>
    (S(:,:,1)+S(:,:,2)+sqrt(delta(S)))/2,  <span class="keyword">...</span>
    (S(:,:,1)+S(:,:,2)-sqrt(delta(S)))/2 );
</pre><p>Compute (at each location \(x\)) the leading eigenvector as \[ e_1 = \frac{1}{Z} \begin{pmatrix}       2 S_{1,2} \\      
            S_{2,2}-S_{1,1} + \sqrt{\Delta(S)}   \end{pmatrix} \] where \(Z\) is a normalization factor ensuring \(\norm{e_1}=1\).
         </p><pre class="codeinput">normalize = @(u)u./repmat(sqrt(sum(u.^2,3)), [1 1 2]);
eig1 = @(S)normalize( cat(3,2*S(:,:,3), S(:,:,2)-S(:,:,1)+sqrt(delta(S)) ) );
</pre><p>Vector \(e_2\) is obtained by applying a \(\pi/2\) rotation to \(e_1\), which defines the eigenbasis.</p><pre class="codeinput">ortho = @(u)deal(u, cat(3,-u(:,:,2), u(:,:,1)));
eigbasis = @(S)ortho(eig1(S));
</pre><p>Compute the eigendecomposition of \(T_\si\).</p><pre class="codeinput">sigma = 2;
S = T(f,sigma);
[lambda1,lambda2] = eigenval(S);
[e1,e2] = eigbasis(S);
</pre><p>Implement the reconstruction formula \[ S = \la_1 (e_1 \otimes e_1) + \la_2 (e_2 \otimes e_2). \]</p><pre class="codeinput">recompose = @(lambda1,lambda2,e1,e2)repmat(lambda1,[1 1 3]).*tensorize(e1) + repmat(lambda2,[1 1 3]).*tensorize(e2);
</pre><p>Check that the recomposition is exact.</p><pre class="codeinput">mynorm = @(x)norm(x(:));
S1 = recompose(lambda1,lambda2,e1,e2);
fprintf(<span class="string">'Should be 0: %.3f\n'</span>, mynorm(S-S1));
</pre><pre class="codeoutput">Should be 0: 0.000
</pre><p>The eigenvalues of \(T_\si\) can be used to detect interest point in the image:</p>
         <div>
            <ul>
               <li>A flat region is composed of pixels \(x\) with \(\la_1(x) \approx \la_2(x) \approx 0\).</li>
               <li>A straight edge is composed of pixels \(x\) with \(0 \approx \la_2(x) \ll \la_1(x)\).</li>
               <li>A corner is composed of pixels \(x\) with \(0 \ll \la_2(x) \approx \la_1(x)\).</li>
            </ul>
         </div>
         <p>This idea is at the heart of the Forstner/Harris corner detector <a href="#biblio">[HarSteph88]</a> <a href="#biblio">[Forstner86]</a>.
         </p>
         <p>Compute the energy and anisotropy \[ E(x) = \sqrt{\lambda_1(x)+\lambda_2(x)} \qandq   A(x) =  \frac{\lambda_1(x)-\la_2(x)}{\la_1(x)
            + \lambda_2(x)} \in [0,1]. \]
         </p><pre class="codeinput">E = sqrt(lambda1+lambda2);
A = (lambda1-lambda2)./(lambda1+lambda2);
</pre><p>Display it.</p><pre class="codeinput">clf;
imageplot({E A}, {<span class="string">'E'</span>, <span class="string">'A'</span>});
</pre><img vspace="5" hspace="5" src="index_05.png"> <h2>Tensor Driven Anisotropic Diffusion<a name="43"></a></h2>
         <p>A tensor field \(S\) can be used as anisotropic metric to drive a diffusion PDE flow. The good reference for such a flow is
            <a href="#biblio">[Weickert98]</a>.
         </p>
         <p>This defines an anisotropic diffusion flow \(t \mapsto f_t\) \[ \pd{f_t}{t}(x) = \text{div}\pa{ S(x) \nabla f_t(x) } \] where
            \(f_0\) is a given data at time \(t=0\).
         </p>
         <p>Note that this is actually a linear PDE, since \(S\) does not evolve in time. But in practice, \(S\) is usually computed from
            \(f_0\), so that the mapping \(f_0 \mapsto f_t\) is actually non-linear.
         </p>
         <p>This PDE is discretized in time using a explicit time stepping \[ f^{(\ell+1)}(x) = f^{(\ell)}(x) + \tau \text{div}\pa{ S(x)
            \nabla f^{(\ell)}(x) } \]
         </p>
         <p>The time step \(\tau\) should be small enough for the diffusion to be stable.</p>
         <p>To produce edge-enhancing diffusion, we define \(S\) from the structure tensor field \(T_\si\) by re-normalizing the eigenvalues.
            \[ S(x) = \phi(\lambda_1(x)) e_1(x)e_1(x)^* + e_2(x)e_2(x)^*, \] where \(\phi : \RR^+ \rightarrow \RR^+\) is defined, following
            <a href="#biblio">[Weickert98]</a>, as \[ \phi(s) = 1 - \text{exp}\pa{      -\frac{C_m}{(s/\la)^m} }. \] Here \(m\) is a given exponent, and the constant \(C_m\)
            ensures that \(s \phi(s)\) is increasing for \(s &lt; \la\) and decreasing for \(s &gt; \la\), which produces the edge-enhancing
            effect.
         </p>
         <p>Set the values of \(m\) and \(C_m\).</p><pre class="codeinput">m = 4;
Cm = 3.31488;
</pre><p>Define \(\phi\).</p><pre class="codeinput">phi = @(s,lambda)1-exp( -Cm./(s/lambda).^m );
</pre><p>Display \(\phi(s)\) and \(s\phi(s)\) for \(\la=1\).</p><pre class="codeinput">s = linspace(0,3,1024)';
clf;
plot(s, [phi(s,1) s.*phi(s,1)], <span class="string">'LineWidth'</span>, 2);
legend(<span class="string">'\phi(s)'</span>, <span class="string">'s \phi(s)'</span>);
</pre><img vspace="5" hspace="5" src="index_06.png"> <p>Select \(\lambda\).</p><pre class="codeinput">lambda = 1e-3;
</pre><p>Select \(\si\).</p><pre class="codeinput">sigma = 2;
</pre><p>Compute the eigen-decomposition of \(T_\si\).</p><pre class="codeinput">S = T(f,sigma);
[lambda1,lambda2] = eigenval(S);
[e1,e2] = eigbasis(S);
</pre><p>Compute \(S\).</p><pre class="codeinput">S = recompose(phi(lambda1,lambda),ones(n),e1,e2);
</pre><p>Note that this remapping of the eigenvalues of \(T\) to the eigenvalues of \(S\) exchanges the roles of the eigenaxes. This
            causes the diffusion to be stronger along the edges, and to be small perpenticular to it.
         </p>
         <p>This flow can thus be seen as an anisotropic version of the famous Perona-Malick flow <a href="#biblio">[PerMal90]</a>. Note that the Perona-Malick flow is often refered to as an <i>anisotropic diffusion</i>, but it is actually incorrect, because the diffusion tensor associated to is is actually isotropic, since it corresponds
            to using a time-dependent tensor field \[ S(x) = \phi(\norm{\nabla f_t(x)}) \text{Id}_2 . \]
         </p>
         <p>Shortcut for the multiplication \(S u\) of tensor \(S\) by vector field \(u\).</p><pre class="codeinput">Mult = @(S,u)cat(3, S(:,:,1).*u(:,:,1) + S(:,:,3).*u(:,:,2), <span class="keyword">...</span>
                          S(:,:,3).*u(:,:,1) + S(:,:,2).*u(:,:,2) );
</pre><p>Step size \(\tau\).</p><pre class="codeinput">tau = .05;
</pre><p>First initialize the image to diffuse at time \(t=0\).</p><pre class="codeinput">f1 = f;
</pre><p>Perform one step of the diffusion.</p><pre class="codeinput">f1 = f1 + tau * div( Mult(S, nabla(f1) ) );
</pre><p><i>Exercice 1:</i> (<a href="../missing-exo/">check the solution</a>) Perform the full diffusion up to a large enough time.
         </p><pre class="codeinput">exo1;
</pre><img vspace="5" hspace="5" src="index_07.png"> <h2>Bibliography<a name="63"></a></h2>
         <p><a name="biblio"></a></p>
         <div>
            <ul>
               <li>[Weickert98] Joachim Weickert, <a href="http://www.mia.uni-saarland.de/weickert/book.html"><i>Anisotropic Diffusion in Image Processing</i></a>, ECMI Series, Teubner-Verlag, Stuttgart, Germany, 1998.
               </li>
               <li>[KassWit85] Michael Kass, Andrew P. Witkin, <a href="http://dx.doi.org/10.1016/0734-189X(87)90043-0"><i>Analyzing Oriented Patterns</i></a>,  IJCAI, 1985: 944-952.
               </li>
               <li>[HarSteph88] C. Harris and M. Stephens, <a href="http://www.bmva.org/bmvc/1988/avc-88-023.pdf"><i>A combined corner and edge detector</i></a>. Proceedings of the 4th Alvey Vision Conference. pp. 147-151, 1988.
               </li>
               <li>[PerMal90] P. Perona and J. Malik, <a href="http://dx.doi.org/doi:10.1109/34.56205"><i>Scale-space and edge detection using anisotropic diffusion</i></a>. IEEE Transactions on Pattern Analysis and Machine Intelligence, 12 (7): 629-639, 1990.
               </li>
               <li>[Forstner86] W. Forstner, <i>A Feature Based Correspondence Algorithm for Image Matching</i>, Intl. Arch. of Photogrammetry and Remote Sensing, vol. 26, pp. 150-166, 1986
               </li>
            </ul>
         </div>
         <p class="footer"><br>
            Copyright  (c) 2010 Gabriel Peyre<br></p>
      </div>
      <!--
##### SOURCE BEGIN #####
%% Tensor-driven Diffusion Flows
% This numerical tour explores the structure tensor to represent the
% geometry of images and textures. It applies it to perform anisotropic
% image diffusion.
% A good reference for diffusion flows in image processing is <#biblio [Weickert98]>.

%% Installing toolboxes and setting up the path.

%%
% You need to download the following files: 
% <../toolbox_signal.zip signal toolbox> and 
% <../toolbox_general.zip general toolbox>.

%%
% You need to unzip these toolboxes in your working directory, so
% that you have 
% |toolbox_signal| and 
% |toolbox_general|
% in your directory.

%%
% *For Scilab user:* you must replace the Matlab comment '%' by its Scilab
% counterpart '//'.

%%
% *Recommandation:* You should create a text file named for instance |numericaltour.sce| (in Scilab) or |numericaltour.m| (in Matlab) to write all the
% Scilab/Matlab command you want to execute. Then, simply run |exec('numericaltour.sce');| (in Scilab) or |numericaltour;| (in Matlab) to run the commands. 

%%
% Execute this line only if you are using Matlab.

getd = @(p)path(p,path); % scilab users must *not* execute this

%%
% Then you can add the toolboxes to the path.

getd('toolbox_signal/');
getd('toolbox_general/');

%% Helpers Functions
% We define here a few features (convolution, gradient, etc.) that will be
% used in the sequel.

%%
% Size of the image of \(N=n \times n\) pixels.

n = 256;

%%
% Load an image \(f\).

name = 'hibiscus';
f = load_image(name,n);
f = rescale( sum(f,3) );

%%
% Display it.

clf;
imageplot(f);

%%
% We define circular convolution
% \[ (f \star h)_i = \sum_j f_j h_{i-j}. \]
% Note that here, \(f\) can be multi-channel, in which case each channel is
% convolved with \(h\). This will be useful to blur tensor fields.

cconv = @(f,h)real(ifft2(fft2(f).*repmat(fft2(h),[1 1 size(f,3)])));

%%
% Define a Gaussian blurring kernel of width \(\si\):
% \[ h_\si(x) = \frac{1}{Z} e^{ -\frac{x_1^2+x_2^2}{2\si^2} }\]
% where \(Z\) ensures that \(\hat h_\si(0)=1\).

t = [0:n/2 -n/2+1:-1];
[X2,X1] = meshgrid(t,t);
normalize = @(h)h/sum(h(:));
h = @(sigma)normalize( exp( -(X1.^2+X2.^2)/(2*sigma^2) ) );

%%
% Define the convolution with \(h_\si\).

blur = @(f,sigma)cconv(f,h(sigma));

%%
% We use in the following a centered finite difference approximation of
% \(\nabla f\), which is a vector field in \(\RR^{n \times n \times 2}\).

options.order = 2;
nabla = @(f)grad(f,options);

%%
% We define the tensor product associated to a vector \(u = (u_1,u_2), v=(u_1,u_2)
% \in \RR^{2}\) as the symetric matrix
% \[ 
%       u \otimes v = u v^* = 
%       \begin{pmatrix} u_1 v_1 & v_1 u_2 \\ u_1 v_2 & u_2 v_2 \end{pmatrix}
%   \in \RR^{2 \times 2}.
% \]
% It is extended to vector fields \( (u(x))_x \in \RR^{N \times 2} \) as
% \[  (u \otimes v)(x) = u(x) \otimes v(x) \]

%%
% A tensor field \(T\) is a collection of symmetric positive definite
% matrices \(T(x) \in \RR^{2 \times 2}\).

%%
% A simple way to build a tensor field is by auto-tensorization of a
% vector field \(u(x)\), i.e. \(T = u \otimes u\). 

%%
% Define a shortcut for \(u \otimes u\)
% (we make use of symmetry to only store 3 components).

tensorize = @(u)cat(3, u(:,:,1).^2, u(:,:,2).^2, u(:,:,1).*u(:,:,2));

%%
% Rotate a tensor field by \(\pi/2\) (for display only).

rotate = @(T)cat(3, T(:,:,2), T(:,:,1), -T(:,:,3));

%% Structure Tensor
% The structure tensor is a field of symetric positive matrices 
% that encodes the local orientation and anisotropy of an image.

%%
% It was initially introduced for corner detection <#biblio [HarSteph88]> <#biblio [Forstner86]>
% and oriented texture analysis <#biblio [KassWit85]>.

%%
% Given an image \(f\), its structure tensor with scale \( \sigma>0 \) is
% defined as
% \[ T_\si = h_\si \star T_0 \qwhereq T_0 = \nabla f \otimes \nabla f. \]
% For each location \(x\), \(T_\si(x)\) is thus a positive definite matrix.

T = @(f,sigma)blur( tensorize( nabla(f) ), sigma);

%%
% The matrix \(T_\si(x)\) can be understood as the local covariance matrix
% of the set of gradient vector around \(x\).

%%
% Another way to get some insight about this tensor field is to consider a
% localized version \(f_x\) of the image around point \(x\), defined by 
% \(f_x(y) = h_\si(x-y)^{1/2} f(y)\), which is close to zero when \(y\) is
% far away from \(x\).
% One has the following Taylor expansion of the \(L^2\) norm between two
% close enough localizations:
% \[ \norm{f_x - f_{x+\de}}^2 = \de^* T_\si(x) \de + O(\norm{\de}^3). \]

%%
% To better understand the behavior of \(T_\si\) as a function of \(\si\),
% one can computes its Taylor expansion for small \(\si\)
% \[ T_\si(x) = T_0(x) + \si^2 Hf(x)^2 + O(\si^3), \]
% where \(Hf(x) \in \RR^{2 \times 2}\) is the Hessian matrix of \(f\) at point \(x\).
% This shows that when \(\si\) increases, the intial rank-1 tensor \(T_0(x)\) 
% becomes full rank because it integrates energy from \(Hf(x)^2\).

%%
% A convenient way to display a tensor field 
% such as \(T_\si\) is to draw 
% an ellispe \(\Ee_x\) at each pixel \(x\) as the (scaled and translated) unit ball of the tensor
% \[ \Ee_x = \enscond{\de \in \RR^2}{ \de^* T_\si(x) \de \leq 1 }. \]
% This allows one to visualize the anisotropy and orientation encoded in
% the tensor field.

%% 
% Display \(T_\si\) for \(\si=0.1\) (the tensors are almost rank-1):

options.sub = 8;
clf; sigma = .1;
plot_tensor_field(rotate(T(f,sigma)), f, options);
title(['\sigma=' num2str(sigma)]);

%%
% For \(\si=4\):

clf; sigma = 4;
plot_tensor_field(rotate(T(f,sigma)), f, options);
title(['\sigma=' num2str(sigma)]);


%%
% For \(\si=10\):

clf; sigma = 10;
plot_tensor_field(rotate(T(f,sigma)), f, options);
title(['\sigma=' num2str(sigma)]);

%% Eigen-decomposition and Anisotropy
% A symmetric tensor field \(S(x)\) can be decomposed as
% \[ S(x) = \lambda_1(x) e_1(x) \otimes e_1(x) + \lambda_2(x) e_2(x) \otimes  e_2(x), \]
% where \((e_1(x),e_2(x))\) are the orthogonal eigenvector fields, \(0 \leq \lambda_2(x) \leq \lambda_1(x)\)
% are the eigenvalues.

%%
% Compute the eigenvalues of \(S \in \RR^{2 \times 2}\) as
% \[ \la_i =  \frac{1}{2} \pa{ S_{1,1}+S_{2,2} \pm \sqrt{\Delta(S)} }
%       \qwhereq \Delta(S) = (S_{1,1}-S_{2,2})^2 + 4 S_{1,2}^2, \]
% where one should use the \(+\) sign for \(i=1\).

delta = @(S)(S(:,:,1)-S(:,:,2)).^2 + 4*S(:,:,3).^2;
eigenval = @(S)deal( ...
    (S(:,:,1)+S(:,:,2)+sqrt(delta(S)))/2,  ...
    (S(:,:,1)+S(:,:,2)-sqrt(delta(S)))/2 );

%%
% Compute (at each location \(x\)) the leading eigenvector as
% \[ e_1 = \frac{1}{Z} \begin{pmatrix}
%       2 S_{1,2} \\
%       S_{2,2}-S_{1,1} + \sqrt{\Delta(S)}
%   \end{pmatrix} \]
% where \(Z\) is a normalization factor ensuring \(\norm{e_1}=1\).

normalize = @(u)u./repmat(sqrt(sum(u.^2,3)), [1 1 2]);
eig1 = @(S)normalize( cat(3,2*S(:,:,3), S(:,:,2)-S(:,:,1)+sqrt(delta(S)) ) );

%%
% Vector \(e_2\) is obtained by applying a \(\pi/2\) rotation to \(e_1\), 
% which defines the eigenbasis.

ortho = @(u)deal(u, cat(3,-u(:,:,2), u(:,:,1)));
eigbasis = @(S)ortho(eig1(S));

%%
% Compute the eigendecomposition of \(T_\si\).

sigma = 2;
S = T(f,sigma);
[lambda1,lambda2] = eigenval(S);
[e1,e2] = eigbasis(S);

%%
% Implement the reconstruction formula
% \[ S = \la_1 (e_1 \otimes e_1) + \la_2 (e_2 \otimes e_2). \]

recompose = @(lambda1,lambda2,e1,e2)repmat(lambda1,[1 1 3]).*tensorize(e1) + repmat(lambda2,[1 1 3]).*tensorize(e2);

%%
% Check that the recomposition is exact.

mynorm = @(x)norm(x(:));
S1 = recompose(lambda1,lambda2,e1,e2);
fprintf('Should be 0: %.3f\n', mynorm(S-S1));

%%
% The eigenvalues of \(T_\si\) can be used to detect interest point in the
% image:

%%
% * A flat region is composed of pixels \(x\) with \(\la_1(x) \approx \la_2(x) \approx 0\).
% * A straight edge is composed of pixels \(x\) with \(0 \approx \la_2(x) \ll \la_1(x)\).
% * A corner is composed of pixels \(x\) with \(0 \ll \la_2(x) \approx \la_1(x)\).

%%
% This idea is at the heart of the Forstner/Harris corner detector <#biblio [HarSteph88]> <#biblio [Forstner86]>.

%%
% Compute the energy and anisotropy
% \[ E(x) = \sqrt{\lambda_1(x)+\lambda_2(x)} \qandq
%   A(x) =  \frac{\lambda_1(x)-\la_2(x)}{\la_1(x) + \lambda_2(x)} \in [0,1]. \]

E = sqrt(lambda1+lambda2);
A = (lambda1-lambda2)./(lambda1+lambda2);

%%
% Display it.

clf;
imageplot({E A}, {'E', 'A'});

%% Tensor Driven Anisotropic Diffusion
% A tensor field \(S\) can be used as anisotropic metric to drive a diffusion PDE flow.
% The good reference for such a flow is <#biblio [Weickert98]>.

%%
% This defines an anisotropic diffusion flow \(t \mapsto f_t\)
% \[ \pd{f_t}{t}(x) = \text{div}\pa{ S(x) \nabla f_t(x) } \]
% where \(f_0\) is a given data at time \(t=0\).

%%
% Note that this is actually a linear PDE, since \(S\) does not evolve in
% time. But in practice, \(S\) is usually computed from \(f_0\), so that
% the mapping \(f_0 \mapsto f_t\) is actually non-linear.

%%
% This PDE is discretized in time using a explicit time stepping
% \[ f^{(\ell+1)}(x) = f^{(\ell)}(x) + \tau \text{div}\pa{ S(x) \nabla f^{(\ell)}(x) } \]

%%
% The time step \(\tau\) should be small enough for the diffusion to be stable.

%%
% To produce edge-enhancing diffusion, we define \(S\) from the structure
% tensor field \(T_\si\) by re-normalizing the eigenvalues. 
% \[ S(x) = \phi(\lambda_1(x)) e_1(x)e_1(x)^* + e_2(x)e_2(x)^*, \]
% where \(\phi : \RR^+ \rightarrow \RR^+\) is defined, following
% <#biblio [Weickert98]>, as
% \[ \phi(s) = 1 - \text{exp}\pa{
%      -\frac{C_m}{(s/\la)^m} }. \]
% Here \(m\) is a given exponent, and 
% the constant \(C_m\) ensures that \(s \phi(s)\) is increasing for 
% \(s < \la\) and decreasing for \(s > \la\), which produces the
% edge-enhancing effect.

%%
% Set the values of \(m\) and \(C_m\).

m = 4;
Cm = 3.31488;

%%
% Define \(\phi\).

phi = @(s,lambda)1-exp( -Cm./(s/lambda).^m );

%%
% Display \(\phi(s)\) and \(s\phi(s)\) for \(\la=1\).

s = linspace(0,3,1024)';
clf;
plot(s, [phi(s,1) s.*phi(s,1)], 'LineWidth', 2); 
legend('\phi(s)', 's \phi(s)');

%%
% Select \(\lambda\).

lambda = 1e-3;

%%
% Select \(\si\).

sigma = 2;

%%
% Compute the eigen-decomposition of \(T_\si\).

S = T(f,sigma);
[lambda1,lambda2] = eigenval(S);
[e1,e2] = eigbasis(S);


%%
% Compute \(S\).

S = recompose(phi(lambda1,lambda),ones(n),e1,e2);

%%
% Note that this remapping of the eigenvalues of \(T\) to the eigenvalues
% of \(S\) exchanges the roles of the eigenaxes. This causes the diffusion
% to be stronger along the edges, and to be small perpenticular to it.

%%
% This flow can thus be seen as an anisotropic version of the famous
% Perona-Malick flow <#biblio [PerMal90]>. Note that the Perona-Malick flow
% is often refered to as an _anisotropic diffusion_, but it is actually
% incorrect, because the diffusion tensor associated to is is actually
% isotropic, since it corresponds to using a time-dependent tensor field
% \[ S(x) = \phi(\norm{\nabla f_t(x)}) \text{Id}_2 . \] 

%%
% Shortcut for the multiplication \(S u\) of tensor
% \(S\) by vector field \(u\).

Mult = @(S,u)cat(3, S(:,:,1).*u(:,:,1) + S(:,:,3).*u(:,:,2), ...
                          S(:,:,3).*u(:,:,1) + S(:,:,2).*u(:,:,2) );
                        
%%
% Step size \(\tau\).
                        
tau = .05;

%%
% First initialize the image to diffuse at time \(t=0\).

f1 = f;

%%
% Perform one step of the diffusion.

f1 = f1 + tau * div( Mult(S, nabla(f1) ) );

%%
% _Exercice 1:_ (<../missing-exo/ check the solution>)
% Perform the full diffusion up to a large enough time.

exo1;


%% Bibliography
% <html><a name="biblio"></a></html>

%%
% * [Weickert98] Joachim Weickert, <http://www.mia.uni-saarland.de/weickert/book.html _Anisotropic Diffusion in Image Processing_>, ECMI Series, Teubner-Verlag, Stuttgart, Germany, 1998.
% * [KassWit85] Michael Kass, Andrew P. Witkin, <http://dx.doi.org/10.1016/0734-189X(87)90043-0 _Analyzing Oriented Patterns_>,  IJCAI, 1985: 944-952.
% * [HarSteph88] C. Harris and M. Stephens, <http://www.bmva.org/bmvc/1988/avc-88-023.pdf _A combined corner and edge detector_>. Proceedings of the 4th Alvey Vision Conference. pp. 147-151, 1988.
% * [PerMal90] P. Perona and J. Malik, <http://dx.doi.org/doi:10.1109/34.56205 _Scale-space and edge detection using anisotropic diffusion_>. IEEE Transactions on Pattern Analysis and Machine Intelligence, 12 (7): 629-639, 1990. 
% * [Forstner86] W. Forstner, _A Feature Based Correspondence Algorithm for Image Matching_, Intl. Arch. of Photogrammetry and Remote Sensing, vol. 26, pp. 150-166, 1986


##### SOURCE END #####
-->
   </body>
</html>