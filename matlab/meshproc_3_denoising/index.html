
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN">
<html xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      --><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script><p style="font-size:0px">
         \[
         \newcommand{\NN}{\mathbb{N}}
         \newcommand{\CC}{\mathbb{C}}
         \newcommand{\GG}{\mathbb{G}}
         \newcommand{\LL}{\mathbb{L}}
         \newcommand{\PP}{\mathbb{P}}
         \newcommand{\QQ}{\mathbb{Q}}
         \newcommand{\RR}{\mathbb{R}}
         \newcommand{\VV}{\mathbb{V}}
         \newcommand{\ZZ}{\mathbb{Z}}
         \newcommand{\FF}{\mathbb{F}}
         \newcommand{\KK}{\mathbb{K}}
         \newcommand{\UU}{\mathbb{U}}
         \newcommand{\EE}{\mathbb{E}}
         
         \newcommand{\Aa}{\mathcal{A}}
         \newcommand{\Bb}{\mathcal{B}}
         \newcommand{\Cc}{\mathcal{C}}
         \newcommand{\Dd}{\mathcal{D}}
         \newcommand{\Ee}{\mathcal{E}}
         \newcommand{\Ff}{\mathcal{F}}
         \newcommand{\Gg}{\mathcal{G}}
         \newcommand{\Hh}{\mathcal{H}}
         \newcommand{\Ii}{\mathcal{I}}
         \newcommand{\Jj}{\mathcal{J}}
         \newcommand{\Kk}{\mathcal{K}}
         \newcommand{\Ll}{\mathcal{L}}
         \newcommand{\Mm}{\mathcal{M}}
         \newcommand{\Nn}{\mathcal{N}}
         \newcommand{\Oo}{\mathcal{O}}
         \newcommand{\Pp}{\mathcal{P}}
         \newcommand{\Qq}{\mathcal{Q}}
         \newcommand{\Rr}{\mathcal{R}}
         \newcommand{\Ss}{\mathcal{S}}
         \newcommand{\Tt}{\mathcal{T}}
         \newcommand{\Uu}{\mathcal{U}}
         \newcommand{\Vv}{\mathcal{V}}
         \newcommand{\Ww}{\mathcal{W}}
         \newcommand{\Xx}{\mathcal{X}}
         \newcommand{\Yy}{\mathcal{Y}}
         \newcommand{\Zz}{\mathcal{Z}}
         
         \newcommand{\al}{\alpha}
         \newcommand{\la}{\lambda}
         \newcommand{\ga}{\gamma}
         \newcommand{\Ga}{\Gamma}
         \newcommand{\La}{\Lambda}
         \newcommand{\Si}{\Sigma}
         \newcommand{\si}{\sigma}
         \newcommand{\be}{\beta}
         \newcommand{\de}{\delta}
         \newcommand{\De}{\Delta}
         \renewcommand{\phi}{\varphi}
         \renewcommand{\th}{\theta}
         \newcommand{\om}{\omega}
         \newcommand{\Om}{\Omega}
         \renewcommand{\epsilon}{\varepsilon}
         
         \newcommand{\Calpha}{\mathrm{C}^\al}
         \newcommand{\Cbeta}{\mathrm{C}^\be}
         \newcommand{\Cal}{\text{C}^\al}
         \newcommand{\Cdeux}{\text{C}^{2}}
         \newcommand{\Cun}{\text{C}^{1}}
         \newcommand{\Calt}[1]{\text{C}^{#1}}
         
         \newcommand{\lun}{\ell^1}
         \newcommand{\ldeux}{\ell^2}
         \newcommand{\linf}{\ell^\infty}
         \newcommand{\ldeuxj}{{\ldeux_j}}
         \newcommand{\Lun}{\text{\upshape L}^1}
         \newcommand{\Ldeux}{\text{\upshape L}^2}
         \newcommand{\Lp}{\text{\upshape L}^p}
         \newcommand{\Lq}{\text{\upshape L}^q}
         \newcommand{\Linf}{\text{\upshape L}^\infty}
         \newcommand{\lzero}{\ell^0}
         \newcommand{\lp}{\ell^p}
         
         
         \renewcommand{\d}{\ins{d}}
         
         \newcommand{\Grad}{\text{Grad}}
         \newcommand{\grad}{\text{grad}}
         \renewcommand{\div}{\text{div}}
         \newcommand{\diag}{\text{diag}}
         
         \newcommand{\pd}[2]{ \frac{ \partial #1}{\partial #2} }
         \newcommand{\pdd}[2]{ \frac{ \partial^2 #1}{\partial #2^2} }
         
         \newcommand{\dotp}[2]{\langle #1,\,#2\rangle}
         \newcommand{\norm}[1]{|\!| #1 |\!|}
         \newcommand{\normi}[1]{\norm{#1}_{\infty}}
         \newcommand{\normu}[1]{\norm{#1}_{1}}
         \newcommand{\normz}[1]{\norm{#1}_{0}}
         \newcommand{\abs}[1]{\vert #1 \vert}
         
         
         \newcommand{\argmin}{\text{argmin}}
         \newcommand{\argmax}{\text{argmax}}
         \newcommand{\uargmin}[1]{\underset{#1}{\argmin}\;}
         \newcommand{\uargmax}[1]{\underset{#1}{\argmax}\;}
         \newcommand{\umin}[1]{\underset{#1}{\min}\;}
         \newcommand{\umax}[1]{\underset{#1}{\max}\;}
         
         \newcommand{\pa}[1]{\left( #1 \right)}
         \newcommand{\choice}[1]{ \left\{  \begin{array}{l} #1 \end{array} \right. }
         
         \newcommand{\enscond}[2]{ \left\{ #1 \;:\; #2 \right\} }
         
         \newcommand{\qandq}{ \quad \text{and} \quad }
         \newcommand{\qqandqq}{ \qquad \text{and} \qquad }
         \newcommand{\qifq}{ \quad \text{if} \quad }
         \newcommand{\qqifqq}{ \qquad \text{if} \qquad }
         \newcommand{\qwhereq}{ \quad \text{where} \quad }
         \newcommand{\qqwhereqq}{ \qquad \text{where} \qquad }
         \newcommand{\qwithq}{ \quad \text{with} \quad }
         \newcommand{\qqwithqq}{ \qquad \text{with} \qquad }
         \newcommand{\qforq}{ \quad \text{for} \quad }
         \newcommand{\qqforqq}{ \qquad \text{for} \qquad }
         \newcommand{\qqsinceqq}{ \qquad \text{since} \qquad }
         \newcommand{\qsinceq}{ \quad \text{since} \quad }
         \newcommand{\qarrq}{\quad\Longrightarrow\quad}
         \newcommand{\qqarrqq}{\quad\Longrightarrow\quad}
         \newcommand{\qiffq}{\quad\Longleftrightarrow\quad}
         \newcommand{\qqiffqq}{\qquad\Longleftrightarrow\qquad}
         \newcommand{\qsubjq}{ \quad \text{subject to} \quad }
         \newcommand{\qqsubjqq}{ \qquad \text{subject to} \qquad }
         \]
         
      </p>
      <title>Mesh Denoising</title>
      <NOSCRIPT>
         <DIV STYLE="color:#CC0000; text-align:center"><B>Warning: <A HREF="http://www.math.union.edu/locate/jsMath">jsMath</A> 
               	requires JavaScript to process the mathematics on this page.<BR> 
               	If your browser supports JavaScript, be sure it is enabled.</B></DIV>
         <HR>
      </NOSCRIPT>
      <meta name="generator" content="MATLAB 8.2">
      <meta name="date" content="2014-10-21">
      <meta name="m-file" content="index">
      <LINK REL="stylesheet" HREF="../style.css" TYPE="text/css">
   </head>
   <body>
      <div class="content">
         <h1>Mesh Denoising</h1>
         <introduction>
            <p>This tour explores denoising of 3-D meshes using linear filtering, heat diffusion and Sobolev regularization.</p>
         </introduction>
         <h2>Contents</h2>
         <div>
            <ul>
               <li><a href="#1">Installing toolboxes and setting up the path.</a></li>
               <li><a href="#8">3-D Triangulated Meshes</a></li>
               <li><a href="#12">Noisy Mesh</a></li>
               <li><a href="#17">Adjacency Matrix</a></li>
               <li><a href="#31">Laplacian and Gradient Operators</a></li>
               <li><a href="#42">Function Denoising with Filtering</a></li>
               <li><a href="#50">Mesh Denoising with Filtering</a></li>
               <li><a href="#56">Mesh Denoising with Linear Heat Diffusion</a></li>
               <li><a href="#68">Mesh Denoising with Sobolev Regularization</a></li>
            </ul>
         </div>
         <h2>Installing toolboxes and setting up the path.<a name="1"></a></h2>
         <p>You need to download the following files: <a href="../toolbox_signal.zip">signal toolbox</a>, <a href="../toolbox_general.zip">general toolbox</a> and <a href="../toolbox_graph.zip">graph toolbox</a>.
         </p>
         <p>You need to unzip these toolboxes in your working directory, so that you have <tt>toolbox_signal</tt>, <tt>toolbox_general</tt> and <tt>toolbox_graph</tt> in your directory.
         </p>
         <p><b>For Scilab user:</b> you must replace the Matlab comment '%' by its Scilab counterpart '//'.
         </p>
         <p><b>Recommandation:</b> You should create a text file named for instance <tt>numericaltour.sce</tt> (in Scilab) or <tt>numericaltour.m</tt> (in Matlab) to write all the Scilab/Matlab command you want to execute. Then, simply run <tt>exec('numericaltour.sce');</tt> (in Scilab) or <tt>numericaltour;</tt> (in Matlab) to run the commands.
         </p>
         <p>Execute this line only if you are using Matlab.</p><pre class="codeinput">getd = @(p)path(p,path); <span class="comment">% scilab users must *not* execute this</span>
</pre><p>Then you can add the toolboxes to the path.</p><pre class="codeinput">getd(<span class="string">'toolbox_signal/'</span>);
getd(<span class="string">'toolbox_general/'</span>);
getd(<span class="string">'toolbox_graph/'</span>);
</pre><h2>3-D Triangulated Meshes<a name="8"></a></h2>
         <p>The topology of a triangulation is defined via a set of indexes \(\Vv = \{1,\ldots,n\}\) that indexes the \(n\) vertices,
            a set of edges \(\Ee \subset \Vv \times \Vv\) and a set of \(m\) faces \(\Ff \subset \Vv  \times \Vv \times \Vv\).
         </p>
         <p>We load a mesh. The set of faces \(\Ff\) is stored in a matrix \(F \in \{1,\ldots,n\}^{3 \times m}\). The positions \(x_i
            \in \RR^3\), for \(i \in V\), of the \(n\) vertices are stored in a matrix \(X_0 = (x_{0,i})_{i=1}^n \in \RR^{3 \times n}\).
         </p><pre class="codeinput">clear <span class="string">options</span>;
name = <span class="string">'elephant-50kv'</span>;
options.name = name; <span class="comment">% useful for displaying</span>
[X0,F] = read_mesh(name);
</pre><p>Number \(n\) of vertices and number \(m\) of faces.</p><pre class="codeinput">n = size(X0,2);
m = size(F,2);
</pre><p>Display the mesh in 3-D.</p><pre class="codeinput">options.lighting = 1;
clf;
plot_mesh(X0,F,options); axis(<span class="string">'tight'</span>);
</pre><img vspace="5" hspace="5" src="index_01.png"> <h2>Noisy Mesh<a name="12"></a></h2>
         <p>We generate artificially a noisy mesh by random normal displacement along the normal. We only perform normal displacements
            because tangencial displacements do not impact the geometry of the mesh.
         </p>
         <p>The parameter \(\rho&gt;0\) controls the amount of noise.</p><pre class="codeinput">rho = 0.015;
</pre><p>We compute the normals \(N = (N_i)_{i=1}^n\) to the mesh. This is obtained by averaging the normal to the faces ajacent to
            each vertex.
         </p><pre class="codeinput">N = compute_normal(X0,F);
</pre><p>We create a noisy mesh by displacement of the vertices along the normal direction \[ x_i = x_{0,i} + \rho \epsilon_i N_i \in
            \RR^3 \] where \(\epsilon_i \sim \Nn(0,1)\) is a realization of a Gaussian random variable, and where \(N_i \in \RR^3\) is
            the normal of the mesh for each vertex index \(i\).
         </p><pre class="codeinput">X = X0 + repmat(rho*randn(1,n),[3,1]).*N;
</pre><p>Display the noisy mesh.</p><pre class="codeinput">clf;
plot_mesh(X,F,options); axis(<span class="string">'tight'</span>);
</pre><img vspace="5" hspace="5" src="index_02.png"> <h2>Adjacency Matrix<a name="17"></a></h2>
         <p>We define linear operators that compute local averages and differences on the mesh.</p>
         <p>First we compute the index of the edges that are in the mesh, by extracting pairs of index in the \(F\) matrix.</p><pre class="codeinput">E = [F([1 2],:) F([2 3],:) F([3 1],:)];
</pre><p>Add the reversed edges. This defines the set of edges \(\Ee\) that is stored in a matrix \(E \in \{1,\ldots,n\}^{2 \times
            p}\).
         </p><pre class="codeinput">E = unique_rows([E E(2:-1:1,:)]')';
</pre><p>We keep only oriented pairs of index \((i,j)\) such that \(i&lt;j\), to avoid un-necessary computation.</p><pre class="codeinput">E0 = E(:,E(1,:)&lt;E(2,:));
</pre><p>This defines a matrix \(E \in \{1,\ldots,n\}^{2 \times p_0}\) where \(p_0=p/2\).</p><pre class="codeinput">p0 = size(E0,2);
</pre><p>Sort the edge according to the first point (this is optional, this change nothing in the operators ...).</p><pre class="codeinput">[tmp,I] = sort(E0(1,:)');
E0 = E0(:,I);
</pre><p>Display statistics of the mesh.</p><pre class="codeinput">disp([<span class="string">'#vertices='</span> num2str(n) <span class="string">', #faces='</span> num2str(m) <span class="string">', #edges='</span> num2str(p0) <span class="string">'.'</span>]);
</pre><pre class="codeoutput">#vertices=24955, #faces=49918, #edges=74877.
</pre><p>The weight matrix \(W\) is the adjacency matrix defined by \[       W_{i,j} = \choice{           1 \qifq (i,j) \in \Ee, \\
                      0 \quad \text{otherwise.}       } \] Since most of the entries of <tt>W</tt> are zero, we store it as a sparse matrix.
         </p><pre class="codeinput">W = make_sparse( E(1,:), E(2,:), ones(size(E,2),1) );
</pre><p>Compute the connectivity weight vector \( d \in \NN^n \) \[ d_i = \sum_{j} W_{i,j} \] i.e. \(d_i\) is the number of edges
            connected to \(i\).
         </p><pre class="codeinput">d = full( sum(W,1) );
</pre><p>Display the statistics of mesh connectivity.</p><pre class="codeinput">clf;
hist(d,min(d):max(d));
axis(<span class="string">'tight'</span>);
</pre><img vspace="5" hspace="5" src="index_03.png"> <p>Store in sparse diagonal matices <tt>D</tt> and <tt>iD</tt> respectively \(D=\text{diag}_i(d_i)\) and \(D^{-1} = \text{diag}_i(1/d_i)\).
         </p><pre class="codeinput">D = spdiags(d(:), 0, n,n);
iD = spdiags(d(:).^(-1), 0, n,n);
</pre><p>The normalized weight matrix is defined as \[ \tilde W_{i,j} = \frac{1}{d_i} W_{i,j}, \] and hence \(\tilde W = D^{-1} W\).</p><pre class="codeinput">tW = iD * W;
</pre><p>It satisfies \[ \forall i , \quad \sum_j \tilde W_{i,j} = 1, \] i.e. \(\tilde W \text{I} = \text{I}\) where \(\text{I} \in
            \RR^n\) is the vector constant equal to one.
         </p>
         <p>The operator \(\tilde W \in \RR^{n \times n} \), viewed as an operator \(\tilde W : \RR^n \rightarrow \RR^n\), can be thought
            as a low pass filter.
         </p>
         <h2>Laplacian and Gradient Operators<a name="31"></a></h2>
         <p>The un-normalized Laplacian is on the contrary a symmetric high pass operator \[ L = D-W \in \RR^{n \times n}. \] It satisfies
            \(L \text{I} = 0\).
         </p><pre class="codeinput">L = D - W;
</pre><p>The gradient operator compute directional derivative along edges. It can be used to factor the Laplacian operator, but in
            practice it is never computed explicitely since it is never needed in numerical computation.
         </p>
         <p><i>Warning:</i> building sparse matrix seems to be quite slow under Scilab, so you might want to skip this part if you are a Scilab user.
         </p>
         <p>To represent the gradient, we index the set of (oriented) edges \( \Ee_0 = (e_k)_{k=1}^{p_0} \) where each edge is \(e_k =
            (i,j) \in \{1,\ldots,n\}^2\) with \(i&lt;j\).
         </p>
         <p>The gradient operator is a matrix \(G \in \RR^{p_0 \times n}\) defined as, for all \(e_k=(i,j)\) and all \(\ell \notin \{i,j\}\),
            \[ G_{k,i}=1, \quad G_{k,j}=-1, \quad G_{k,\ell}=0. \]
         </p>
         <p>It is stored as a sparse matrix, and can be thought as a derivative operator \(G : \RR^n \rightarrow \RR^{p_0} \) that maps
            signal defined on vertices to differences located along directed edges.
         </p><pre class="codeinput">G = make_sparse( [1:p0 1:p0], [E0(1,:) E0(2,:)], [ones(1,p0) -ones(1,p0)] );
</pre><p>Display the non-zero entries of <tt>G</tt> and <tt>W</tt>.
         </p><pre class="codeinput">clf;
subplot(1,2,1);
spy(W); title(<span class="string">'W'</span>);
subplot(1,2,2);
spy(G); title(<span class="string">'G'</span>);
</pre><img vspace="5" hspace="5" src="index_04.png"> <p>The Laplacian can be factored as follow \[ L = G^* G \] where \(G^*\) is the transposed matrix (i.e. the adjoint operator,
            which can be thought as some kind of divergence).
         </p>
         <p>Check numerically that the factorization indeed hold.</p><pre class="codeinput">err = norm( G'*G - L, <span class="string">'fro'</span>);
disp([<span class="string">'Factorization error (should be 0) = '</span> num2str(err,2) <span class="string">'.'</span>]);
</pre><pre class="codeoutput">Factorization error (should be 0) = 0.
</pre><p>Note that this factorization shows that \(L\) is a positive semi-definite operator, i.e. it satisfies \[ \dotp{L f}{f} = \norm{G
            f}^2 \geq 0. \] If the mesh is connected, then only constant signals \(f \in \RR^n\) satisfies \(Lf=0\).
         </p>
         <p>Note that this convention is the contrary to the usual convention of differential calculus, in which a Laplacian is a negative
            operator.
         </p>
         <h2>Function Denoising with Filtering<a name="42"></a></h2>
         <p>A signal defined on the mesh is a vector \(f \in \RR^n\), where \(f_i \in \RR\) is the value at vertex \(1 \leq i \leq n\).</p>
         <p>Load a texture image \(I\).</p><pre class="codeinput">M = load_image(<span class="string">'lena'</span>,256);
</pre><p>Compute spherical coordinates \( (\theta_i,\phi_i)\) for each vertex \(x_{0,i}\) on the mesh.</p><pre class="codeinput">v = X0 - repmat(mean(X0,2), [1 n]);
theta = acos(v(1,:)./sqrt(sum(v.^2)))/pi;
phi = (atan2(v(2,:),v(3,:))/pi+1)/2;
</pre><p>Interpolate the texture on the mesh.</p><pre class="codeinput">x = linspace(0,1,size(M,1));
f = interp2(x,x,M',theta,phi)';
</pre><p>Display the textured mesh.</p><pre class="codeinput">options.face_vertex_color = f(:);
clf;
plot_mesh(X0,F, options);
lighting <span class="string">none</span>;
</pre><img vspace="5" hspace="5" src="index_05.png"> <p>The operator \(\tilde W : \RR^n \rightarrow \RR^n\) can be used to smooth a function \(f\), simply by computing \(\tilde W
            f \in \RR^n\).
         </p>
         <p>To further smooth the mesh, it is possible to iterate this process, by defining \(f^{(0)} = f\) and \[ f^{(\ell+1)} = \tilde
            W f^{(\ell)}.\] Note that one has \( f^{(\ell)} = \tilde W^{\ell} f, \) but it is preferable to use the iterative algorithm
            to do the computations.
         </p>
         <p><i>Exercice 1:</i> (<a href="../missing-exo/">check the solution</a>) Display the evolution of the image on the mesh as the number of iterations increases.
         </p><pre class="codeinput">exo1;
</pre><img vspace="5" hspace="5" src="index_06.png"> <h2>Mesh Denoising with Filtering<a name="50"></a></h2>
         <p>The quality of a noisy mesh is improved by applying local averagings, that removes noise but also tends to smooth features.</p>
         <p>The operator \(\tilde W : \RR^n \rightarrow \RR^n\) can be used to smooth a function, but it can also be applied to smooth
            the position \(W \in \RR^{3 \times n} \). Since they are stored as row of a matrix, one should applies \(\tilde W^*\) (transposed
            matrix) on the right side. \[ X^{(0)} = X \qandq X^{(\ell+1)} = X^{(\ell)} W^* \]
         </p><pre class="codeinput">niter = 5;
X1 = X;
<span class="keyword">for</span> i=1:niter
    X1 = X1*tW';
<span class="keyword">end</span>
</pre><p>We can compute the errors in dB with respect to the clean mesh, using \[ \text{SNR}(X,Y) = -20 \log_{10} \pa{&nbsp;\norm{X-Y}/\norm{Y}
            }. \]
         </p><pre class="codeinput">pnoisy = snr(X0,X);
pfilt  = snr(X0,X1);
disp(strcat([<span class="string">'Noisy='</span> num2str(pnoisy,2) <span class="string">'dB, denoised='</span> num2str(pfilt,2) <span class="string">'dB.'</span>]));
</pre><pre class="codeoutput">Noisy=27dB, denoised=40dB.
</pre><p>Display the results.</p><pre class="codeinput">clf;
plot_mesh(X1,F, options);
axis(<span class="string">'tight'</span>); shading(<span class="string">'interp'</span>);
</pre><img vspace="5" hspace="5" src="index_07.png"> <p><i>Exercice 2:</i> (<a href="../missing-exo/">check the solution</a>) Determine the optimal number of iterations to maximize the SNR. Record, for each number <tt>i</tt> of iteration, the SNR in <tt>err(i)</tt>.
         </p><pre class="codeinput">exo2;
</pre><img vspace="5" hspace="5" src="index_08.png"> <p>Plot the error as a function of the number of iterations.</p><pre class="codeinput">clf;
plot(0:length(err)-1, err, <span class="string">'.-'</span>); axis(<span class="string">'tight'</span>);
set_label(<span class="string">'Iteration'</span>, <span class="string">'SNR'</span>);
</pre><img vspace="5" hspace="5" src="index_09.png"> <h2>Mesh Denoising with Linear Heat Diffusion<a name="56"></a></h2>
         <p>Iterative filtering is closely related to the heat diffusion. The heat diffusion is a linear partial differential equation
            (PDE) that compute a continuous denoising result for arbitrary time \(t\). It is thus more precise than simple iterative filterings.
         </p>
         <p>This PDE defines a function \(f_t \in \RR^n\) parameterized by the time \(t&gt;0\) as \[ \forall t&gt;0, \quad \pd{f_t}{t} = -\tilde
            L f_t       \qandq f_0 = f, \] where \( \tilde L \) is the symetric normaled Laplacian defined as \[ \tilde L = D^{-1} L =
            \text{Id}_n - \tilde W. \]
         </p><pre class="codeinput">tL = iD * L;
</pre><p>This PDE is applied to the three components of a 3-D mesh to define a surface evolution \[ \forall t&gt;0, \quad \pd{X_t}{t}
            = -X_t \tilde L^*       \qandq f_0 = f. \]
         </p>
         <p>One can approximate the solution to this PDE using explicit finite difference in time (Euler explicit scheme) \[ X^{(\ell+1)}
            = X^{(\ell)} -  \tau X^{(\ell)} \tilde L^*       = (1-\tau) X^{(\ell)} + \tau  X^{(\ell)} \tilde W^* \] where \(0 &lt; \tau &lt;
            1\) is a (small enough) time step and \(f^{(\ell)}\) is intended to be an approximation of \(X_t\) at time \(t=\tau \ell\).
            The smaller \(\tau\), the better the approximation.
         </p>
         <p>One can see that with \(\tau=1\), one recovers the iterative filtering method.</p>
         <p>Time step \(\tau\).</p><pre class="codeinput">tau = .2;
</pre><p>Maximum time of resolution.</p><pre class="codeinput">Tmax = 40;
</pre><p>Number of iterations needed to reach this time.</p><pre class="codeinput">niter = ceil(Tmax/tau);
</pre><p>Initial solution at time \(t=0\).</p><pre class="codeinput">Xt = X;
</pre><p>We use an explicit discretization in time of the PDE. Here is one iteration.</p><pre class="codeinput">Xt = Xt - tau*Xt*tL';
</pre><p><i>Exercice 3:</i> (<a href="../missing-exo/">check the solution</a>) Compute the linear heat diffusion. Monitor the denoising SNR <tt>err(l)</tt> between \(X_t\) and \(X_0\) at iteration index <tt>l</tt>.
         </p><pre class="codeinput">exo3;
</pre><img vspace="5" hspace="5" src="index_10.png"> <p>Plot the error as a function of time.</p><pre class="codeinput">t = linspace(0,Tmax,niter);
clf;
plot(t, err); axis(<span class="string">'tight'</span>);
set_label(<span class="string">'Time'</span>, <span class="string">'SNR'</span>);
</pre><img vspace="5" hspace="5" src="index_11.png"> <h2>Mesh Denoising with Sobolev Regularization<a name="68"></a></h2>
         <p>Instead of solving an evolution PDE, it is possible to do denoising by solving a quadratic regularization.</p>
         <p>Denoting \(G \in \RR^{p_0 \times n}\) the gradient operator, the Soboleb norm of a signal \(f \in \RR^n\) is defined as \[
            J(f) = \norm{G f}^2 = \dotp{L f}{f}. \] It is extended to mesh poisition \(X \in \RR^{3 \times n}\) as \[ J(X) = \norm{X G^*}^2
            = \dotp{X L}{X}, \] (remeber that \(L\) is symmetric).
         </p>
         <p>Denoising of a noisy set of vertices \(X\) is then defined as the solution of a quadratic minimization \[ X_\mu = \uargmin{Z
            \in \RR^{3 \times n}}&nbsp;\norm{Z-X}^2  + \mu J(Z)^2. \] Here \(\mu \geq 0\) controls the amount of denoising, and should be proportional
            to the noise level.
         </p>
         <p>The solution to this problem is obtained by solving the following symmetric linear system \[ X_\mu^* = (\text{Id}_n + \mu
            L )^{-1} X^* \] (remember that the mesh vertex position are stored as rows, hence the transposed).
         </p>
         <p>We select a penalization weight \(\mu\). The larger, the smoother the result will be (more denoising).</p><pre class="codeinput">mu = 10;
</pre><p>We set up the matrix of the system. It is important to use sparse matrix to have fast resolution scheme.</p><pre class="codeinput">A = speye(n,n)+mu*L;
</pre><p>We solve the system for each coordinate of the mesh. Since the matrix is highly sparse, it is very interesting to use an iterative
            method to solve the system, so here we use a conjugate gradient descent (function <tt>perform_cg</tt>)|.
         </p><pre class="codeinput">Xmu = X;
<span class="keyword">for</span> i=1:3
    b = X(i,:)';
    Xmu(i,:) = perform_cg(A,b)';
<span class="keyword">end</span>
</pre><p>Display the result.</p><pre class="codeinput">clf;
plot_mesh(Xmu,F, options);
</pre><img vspace="5" hspace="5" src="index_12.png"> <p><i>Exercice 4:</i> (<a href="../missing-exo/">check the solution</a>) Solve this problem for various \(\mu\) on a 3D mesh. Draw the evolution of the SNR denoising error as a function of \(\mu\).
         </p><pre class="codeinput">exo4;
</pre><img vspace="5" hspace="5" src="index_13.png"> <p class="footer"><br>
            Copyright  (c) 2010 Gabriel Peyre<br></p>
      </div>
      <!--
##### SOURCE BEGIN #####
%% Mesh Denoising
% This tour explores denoising of 3-D meshes using linear filtering, heat
% diffusion and Sobolev regularization.

%% Installing toolboxes and setting up the path.

%%
% You need to download the following files: 
% <../toolbox_signal.zip signal toolbox>, 
% <../toolbox_general.zip general toolbox> and 
% <../toolbox_graph.zip graph toolbox>.

%%
% You need to unzip these toolboxes in your working directory, so
% that you have 
% |toolbox_signal|, 
% |toolbox_general| and 
% |toolbox_graph|
% in your directory.

%%
% *For Scilab user:* you must replace the Matlab comment '%' by its Scilab
% counterpart '//'.

%%
% *Recommandation:* You should create a text file named for instance |numericaltour.sce| (in Scilab) or |numericaltour.m| (in Matlab) to write all the
% Scilab/Matlab command you want to execute. Then, simply run |exec('numericaltour.sce');| (in Scilab) or |numericaltour;| (in Matlab) to run the commands. 

%%
% Execute this line only if you are using Matlab.

getd = @(p)path(p,path); % scilab users must *not* execute this

%%
% Then you can add the toolboxes to the path.

getd('toolbox_signal/');
getd('toolbox_general/');
getd('toolbox_graph/');


%% 3-D Triangulated Meshes
% The topology of a triangulation is defined via a set of indexes \(\Vv = \{1,\ldots,n\}\)
% that indexes the \(n\) vertices, a set of edges \(\Ee \subset \Vv \times \Vv\)
% and a set of \(m\) faces \(\Ff \subset \Vv  \times \Vv \times \Vv\).

%%
% We load a mesh. The set of faces \(\Ff\) is stored in a matrix \(F \in
% \{1,\ldots,n\}^{3 \times m}\).
% The positions \(x_i \in \RR^3\), for \(i \in V\), of the \(n\) vertices
% are stored in a matrix \(X_0 = (x_{0,i})_{i=1}^n \in \RR^{3 \times n}\).


clear options;
name = 'elephant-50kv';
options.name = name; % useful for displaying
[X0,F] = read_mesh(name);

%% 
% Number \(n\) of vertices and number \(m\) of faces.

n = size(X0,2);
m = size(F,2);

%%
% Display the mesh in 3-D.

options.lighting = 1;
clf;
plot_mesh(X0,F,options); axis('tight');


%% Noisy Mesh
% We generate artificially a noisy mesh by random normal displacement along the normal.
% We only perform normal displacements because tangencial displacements 
% do not impact the geometry of the mesh.

%%
% The parameter \(\rho>0\) controls the amount of noise.

rho = 0.015;

%%
% We compute the normals \(N = (N_i)_{i=1}^n\) to the mesh.
% This is obtained by averaging the normal to the faces ajacent to each
% vertex.

N = compute_normal(X0,F);


%%
% We create a noisy mesh by displacement of the vertices along the
% normal direction 
% \[ x_i = x_{0,i} + \rho \epsilon_i N_i \in \RR^3 \]
% where \(\epsilon_i \sim \Nn(0,1)\) is a realization of a Gaussian random
% variable, 
% and where \(N_i \in \RR^3\) is the normal of the mesh for each vertex index
% \(i\).

X = X0 + repmat(rho*randn(1,n),[3,1]).*N;

%%
% Display the noisy mesh.

clf;
plot_mesh(X,F,options); axis('tight');


%% Adjacency Matrix
% We define linear operators that compute local averages and differences on
% the mesh.

%%
% First we compute the index of the edges that are in the mesh, 
% by extracting pairs of index in the \(F\) matrix.

E = [F([1 2],:) F([2 3],:) F([3 1],:)];


%%
% Add the reversed edges. This defines the set of edges \(\Ee\)
% that is stored in a matrix \(E \in \{1,\ldots,n\}^{2 \times p}\).

E = unique_rows([E E(2:-1:1,:)]')';
    
%%
% We keep only oriented pairs of index \((i,j)\) such that \(i<j\), 
% to avoid un-necessary computation. 

E0 = E(:,E(1,:)<E(2,:));

%%
% This defines a matrix
% \(E \in \{1,\ldots,n\}^{2 \times p_0}\) where \(p_0=p/2\).

p0 = size(E0,2);

%% 
% Sort the edge according to the first point (this is optional, this change nothing in the
% operators ...).

[tmp,I] = sort(E0(1,:)');
E0 = E0(:,I);


%%
% Display statistics of the mesh.

disp(['#vertices=' num2str(n) ', #faces=' num2str(m) ', #edges=' num2str(p0) '.']);

%%
% The weight matrix \(W\) is the adjacency matrix
% defined by 
% \[
%       W_{i,j} = \choice{
%           1 \qifq (i,j) \in \Ee, \\
%           0 \quad \text{otherwise.}
%       }
% \]
% Since most of the entries of |W| are zero, we store it as a sparse
% matrix.

W = make_sparse( E(1,:), E(2,:), ones(size(E,2),1) );

%%
% Compute the connectivity weight vector \( d \in \NN^n \)
% \[ d_i = \sum_{j} W_{i,j} \]
% i.e. \(d_i\) is the number of edges connected to \(i\).

d = full( sum(W,1) );

%%
% Display the statistics of mesh connectivity.

clf;
hist(d,min(d):max(d)); 
axis('tight');

%%
% Store in sparse diagonal matices |D| and |iD|
% respectively \(D=\text{diag}_i(d_i)\) and \(D^{-1} = \text{diag}_i(1/d_i)\).

D = spdiags(d(:), 0, n,n);
iD = spdiags(d(:).^(-1), 0, n,n);

%%
% The normalized weight matrix is defined as
% \[ \tilde W_{i,j} = \frac{1}{d_i} W_{i,j}, \]
% and hence \(\tilde W = D^{-1} W\).

tW = iD * W;

%%
% It satisfies 
% \[ \forall i , \quad \sum_j \tilde W_{i,j} = 1, \]
% i.e. \(\tilde W \text{I} = \text{I}\) where \(\text{I} \in \RR^n\) is the vector
% constant equal to one. 

%%
% The operator \(\tilde W \in \RR^{n \times n} \), viewed as an operator
% \(\tilde W : \RR^n \rightarrow \RR^n\), can be thought as a low pass
% filter.


%% Laplacian and Gradient Operators
% The un-normalized Laplacian is on the contrary a symmetric high pass
% operator
% \[ L = D-W \in \RR^{n \times n}. \]
% It satisfies \(L \text{I} = 0\).

L = D - W;

%%
% The gradient operator compute directional derivative along edges.
% It can be used to factor the Laplacian operator, but in practice
% it is never computed explicitely since it is never needed in numerical 
% computation. 

%%
% _Warning:_ building sparse matrix seems to be quite slow under Scilab,
% so you might want to skip this part if you are a Scilab user.

%%
% To represent the gradient, we index the set of (oriented) edges \( \Ee_0 = (e_k)_{k=1}^{p_0} \) 
% where each edge is \(e_k = (i,j) \in \{1,\ldots,n\}^2\) with \(i<j\).

%%
% The gradient operator is a matrix \(G \in \RR^{p_0 \times n}\) defined
% as, for all \(e_k=(i,j)\) and all \(\ell \notin \{i,j\}\), 
% \[ G_{k,i}=1, \quad G_{k,j}=-1, \quad G_{k,\ell}=0. \]

%%
% It is stored as a sparse matrix, and can be thought as a derivative
% operator \(G : \RR^n \rightarrow \RR^{p_0} \) that maps signal defined
% on vertices to differences located along directed edges. 

G = make_sparse( [1:p0 1:p0], [E0(1,:) E0(2,:)], [ones(1,p0) -ones(1,p0)] );

%%
% Display the non-zero entries of |G| and |W|.

clf;
subplot(1,2,1);
spy(W); title('W');
subplot(1,2,2);
spy(G); title('G');

%%
% The Laplacian can be factored as follow
% \[ L = G^* G \]
% where \(G^*\) is the transposed matrix (i.e. the adjoint operator, which
% can be thought as some kind of divergence).

%% 
% Check numerically that the factorization indeed hold.

err = norm( G'*G - L, 'fro');
disp(['Factorization error (should be 0) = ' num2str(err,2) '.']);

%%
% Note that this factorization shows that \(L\) is a positive semi-definite
% operator, i.e. it satisfies
% \[ \dotp{L f}{f} = \norm{G f}^2 \geq 0. \]
% If the mesh is connected, then only constant signals \(f \in \RR^n\) satisfies
% \(Lf=0\).

%%
% Note that this convention is the contrary to the usual convention of
% differential calculus, in which a Laplacian is a negative operator. 



%% Function Denoising with Filtering
% A signal defined on the mesh is a vector \(f \in \RR^n\), where \(f_i \in \RR\)
% is the value at vertex \(1 \leq i \leq n\).

%%
% Load a texture image \(I\).

M = load_image('lena',256);

%%
% Compute spherical coordinates \( (\theta_i,\phi_i)\) for each vertex \(x_{0,i}\)
% on the mesh.

v = X0 - repmat(mean(X0,2), [1 n]);
theta = acos(v(1,:)./sqrt(sum(v.^2)))/pi;
phi = (atan2(v(2,:),v(3,:))/pi+1)/2;

%%
% Interpolate the texture on the mesh.

x = linspace(0,1,size(M,1));
f = interp2(x,x,M',theta,phi)';

%%
% Display the textured mesh.

options.face_vertex_color = f(:);
clf;
plot_mesh(X0,F, options);
lighting none;

%%
% The operator \(\tilde W : \RR^n \rightarrow \RR^n\) can be used to smooth
% a function \(f\), simply by computing \(\tilde W f \in \RR^n\).

%%
% To further smooth the mesh, it is possible to iterate this process, by
% defining \(f^{(0)} = f\) and 
% \[ f^{(\ell+1)} = \tilde W f^{(\ell)}.\]
% Note that one has \( f^{(\ell)} = \tilde W^{\ell} f, \)
% but it is preferable to use the iterative algorithm to do the
% computations. 

%%
% _Exercice 1:_ (<../missing-exo/ check the solution>)
% Display the evolution of the image on the mesh as the number of
% iterations increases.

exo1;


%% Mesh Denoising with Filtering
% The quality of a noisy mesh is improved by applying local averagings,
% that removes noise but also tends to smooth features.


%%
% The operator \(\tilde W : \RR^n \rightarrow \RR^n\) can be used to smooth
% a function, but it can also be applied to smooth the position \(W \in
% \RR^{3 \times n} \). Since they are stored as row of a matrix, one should
% applies \(\tilde W^*\) (transposed matrix) on the right side.
% \[ X^{(0)} = X \qandq X^{(\ell+1)} = X^{(\ell)} W^* \]

niter = 5;
X1 = X;
for i=1:niter
    X1 = X1*tW'; 
end
    
%% 
% We can compute the errors in dB with respect to the clean mesh, using
% \[ \text{SNR}(X,Y) = -20 \log_{10} \pa{ \norm{X-Y}/\norm{Y} }. \]

pnoisy = snr(X0,X);
pfilt  = snr(X0,X1);
disp(strcat(['Noisy=' num2str(pnoisy,2) 'dB, denoised=' num2str(pfilt,2) 'dB.']));

%% 
% Display the results. 

clf;
plot_mesh(X1,F, options);
axis('tight'); shading('interp');  

%%
% _Exercice 2:_ (<../missing-exo/ check the solution>)
% Determine the optimal number of iterations to maximize the SNR.
% Record, for each number |i| of iteration, the SNR in |err(i)|.

exo2;

%%
% Plot the error as a function of the number of iterations.

clf;
plot(0:length(err)-1, err, '.-'); axis('tight');
set_label('Iteration', 'SNR');


%% Mesh Denoising with Linear Heat Diffusion
% Iterative filtering is closely related to the heat diffusion. The heat
% diffusion is a linear partial differential equation (PDE) that compute a continuous denoising result for
% arbitrary time \(t\). It is thus more precise than simple iterative
% filterings.

%%
% This PDE defines a function \(f_t \in \RR^n\) parameterized by the time
% \(t>0\) as
% \[ \forall t>0, \quad \pd{f_t}{t} = -\tilde L f_t 
%       \qandq f_0 = f, \]
% where \( \tilde L \) is the symetric normaled Laplacian defined as
% \[ \tilde L = D^{-1} L = \text{Id}_n - \tilde W. \]

tL = iD * L;

%%
% This PDE is applied to the three components of a 3-D mesh to define a
% surface evolution 
% \[ \forall t>0, \quad \pd{X_t}{t} = -X_t \tilde L^*
%       \qandq f_0 = f. \]

%%
% One can approximate the solution to this PDE using explicit finite
% difference in time (Euler explicit scheme)
% \[ X^{(\ell+1)} = X^{(\ell)} -  \tau X^{(\ell)} \tilde L^* 
%       = (1-\tau) X^{(\ell)} + \tau  X^{(\ell)} \tilde W^* \]
% where \(0 < \tau < 1\) is a (small enough) time step and \(f^{(\ell)}\) is
% intended to be an approximation of \(X_t\) at time \(t=\tau \ell\).
% The smaller \(\tau\), the better the approximation.

%%
% One can see that with \(\tau=1\), one recovers the iterative filtering
% method. 

%%
% Time step \(\tau\).

tau = .2;

%%
% Maximum time of resolution.

Tmax = 40;

%%
% Number of iterations needed to reach this time.

niter = ceil(Tmax/tau);

%%
% Initial solution at time \(t=0\).

Xt = X;

%%
% We use an explicit discretization in time of the PDE. Here is one
% iteration.

Xt = Xt - tau*Xt*tL';

%%
% _Exercice 3:_ (<../missing-exo/ check the solution>)
% Compute the linear heat diffusion.
% Monitor the denoising
% SNR |err(l)| between \(X_t\) and \(X_0\) at iteration index |l|.

exo3;

%% 
% Plot the error as a function of time.

t = linspace(0,Tmax,niter);
clf;
plot(t, err); axis('tight');
set_label('Time', 'SNR');

%% Mesh Denoising with Sobolev Regularization
% Instead of solving an evolution PDE, it is possible to do denoising by
% solving a quadratic regularization.

%%
% Denoting \(G \in \RR^{p_0 \times n}\) the gradient operator, the Soboleb
% norm of a signal \(f \in \RR^n\) is defined as
% \[ J(f) = \norm{G f}^2 = \dotp{L f}{f}. \]
% It is extended to mesh poisition \(X \in \RR^{3 \times n}\) as
% \[ J(X) = \norm{X G^*}^2 = \dotp{X L}{X}, \]
% (remeber that \(L\) is symmetric).


%%
% Denoising of a noisy set of vertices \(X\) is then defined as the solution of a quadratic minimization
% \[ X_\mu = \uargmin{Z \in \RR^{3 \times n}} \norm{Z-X}^2  + \mu J(Z)^2. \]
% Here \(\mu \geq 0\) controls the amount of denoising, and should be
% proportional to the noise level.

%%
% The solution to this problem is obtained by solving the following
% symmetric linear system
% \[ X_\mu^* = (\text{Id}_n + \mu L )^{-1} X^* \]
% (remember that the mesh vertex position are stored as rows, hence the transposed).

%%
% We select a penalization weight \(\mu\). The larger, the smoother the result will
% be (more denoising). 

mu = 10;

%%
% We set up the matrix of the system.
% It is important to use sparse matrix to have fast resolution scheme.

A = speye(n,n)+mu*L;

%%
% We solve the system for each coordinate of the mesh.
% Since the matrix is highly sparse, it is very interesting
% to use an iterative method to solve the system, so here
% we use a conjugate gradient descent (function |perform_cg|)|.

Xmu = X;
for i=1:3
    b = X(i,:)';
    Xmu(i,:) = perform_cg(A,b)';
end

%%
% Display the result.

clf;
plot_mesh(Xmu,F, options);

%%
% _Exercice 4:_ (<../missing-exo/ check the solution>)
% Solve this problem for various \(\mu\) on a 3D mesh.
% Draw the evolution of the SNR denoising error as a function of \(\mu\).

exo4;


##### SOURCE END #####
-->
   </body>
</html>