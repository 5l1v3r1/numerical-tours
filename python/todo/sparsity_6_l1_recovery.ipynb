{
  "metadata": {
    "name": ""
  }, 
  "nbformat": 3, 
  "nbformat_minor": 0, 
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading", 
          "level": 1, 
          "metadata": {}, 
          "source": [
            "Performance of Sparse Recovery Using L1 Minimization"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "This tour explores theoritical garantees for the performance of recovery\n", 
            "using $\\ell^1$ minimization.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "*Important:* You need to download the file `nt_toolbox.py` from the \n", 
            "root of the github repository.\n", 
            "$\\newcommand{\\dotp}[2]{\\langle #1, #2 \\rangle}\n", 
            "\\newcommand{\\enscond}[2]{\\lbrace #1, #2 \\rbrace}\n", 
            "\\newcommand{\\pd}[2]{ \\frac{ \\partial #1}{\\partial #2} }\n", 
            "\\newcommand{\\umin}[1]{\\underset{#1}{\\min}\\;}\n", 
            "\\newcommand{\\norm}[1]{\\|#1\\|}\n", 
            "\\newcommand{\\abs}[1]{\\left|#1\\right|}\n", 
            "\\newcommand{\\choice}[1]{ \\left\\{  \\begin{array}{l} #1 \\end{array} \\right. }\n", 
            "\\newcommand{\\pa}[1]{\\left(#1\\right)}\n", 
            "\\newcommand{\\qandq}{\\quad\\text{and}\\quad}\n", 
            "\\newcommand{\\qwhereq}{\\quad\\text{where}\\quad}\n", 
            "\\newcommand{\\qifq}{ \\quad \\text{if} \\quad }\n", 
            "\\newcommand{\\qarrq}{ \\quad \\Longrightarrow \\quad }\n", 
            "\\newcommand{\\ZZ}{\\mathbb{Z}}\n", 
            "\\newcommand{\\RR}{\\mathbb{R}}\n", 
            "\\newcommand{\\Nn}{\\mathcal{N}}\n", 
            "\\newcommand{\\Hh}{\\mathcal{H}}\n", 
            "\\newcommand{\\Bb}{\\mathcal{B}}\n", 
            "\\newcommand{\\EE}{\\mathbb{E}}\n", 
            "\\newcommand{\\CC}{\\mathbb{C}}\n", 
            "\\newcommand{\\si}{\\sigma}\n", 
            "\\newcommand{\\al}{\\alpha}\n", 
            "\\newcommand{\\la}{\\lambda}\n", 
            "\\newcommand{\\ga}{\\gamma}\n", 
            "\\newcommand{\\Ga}{\\Gamma}\n", 
            "\\newcommand{\\La}{\\Lambda}\n", 
            "\\newcommand{\\si}{\\sigma}\n", 
            "\\newcommand{\\Si}{\\Sigma}\n", 
            "\\newcommand{\\be}{\\beta}\n", 
            "\\newcommand{\\de}{\\delta}\n", 
            "\\newcommand{\\De}{\\Delta}\n", 
            "\\renewcommand{\\phi}{\\varphi}\n", 
            "\\renewcommand{\\th}{\\theta}\n", 
            "\\newcommand{\\om}{\\omega}\n", 
            "\\newcommand{\\Om}{\\Omega}\n", 
            "$"
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "from nt_toolbox import *", 
            "%matplotlib inline", 
            "%load_ext autoreload", 
            "%autoreload 2"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "heading", 
          "level": 2, 
          "metadata": {}, 
          "source": [
            "Sparse \\(\\ell^1\\) Recovery\n"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "We consider the inverse problem of estimating an unknown signal $x_0 \\in\n", 
            "\\RR^N$ from noisy measurements $y=\\Phi x_0 + w \\in \\RR^P$ where $\\Phi \\in \\RR^{P \\times N}$\n", 
            "is a measurement matrix with $P \\leq N$, and $w$ is some noise.\n", 
            "\n", 
            "\n", 
            "This tour is focused on recovery using $\\ell^1$ minimization\n", 
            "$$ x^\\star \\in \\uargmin{x \\in \\RR^N} \\frac{1}{2}\\norm{y-\\Phi x}^2 + \\la \\normu{x}. $$\n", 
            "\n", 
            "\n", 
            "Where there is no noise, we consider the problem $ \\Pp(y) $\n", 
            "$$ x^\\star \\in \\uargmin{\\Phi x = y} \\normu{x}. $$\n", 
            "\n", 
            "\n", 
            "We are not concerned here about the actual way to solve this convex\n", 
            "problem (see the other numerical tours on sparse regularization) but\n", 
            "rather on the theoritical analysis of wether $x^\\star$ is close to\n", 
            "$x_0$.\n", 
            "\n", 
            "\n", 
            "More precisely, we consider the following three key properties\n", 
            "\n", 
            "\n", 
            "* *Noiseless identifiability*: $x_0$ is the unique solution of $\n", 
            "\\Pp(y) $ for $y=\\Phi x_0$.\n", 
            "* *Robustess to small noise:*: one has $\\norm{x^\\star - x_0} =\n", 
            "O(\\norm{w})$ for $y=\\Phi x_0+w$ if $\\norm{w}$ is smaller than\n", 
            "an arbitrary small constant that depends on $x_0$ if $\\la$ is well chosen according to $\\norm{w}$.\n", 
            "* *Robustess to bounded noise:* same as above, but $\\norm{w}$ can be\n", 
            "arbitrary.\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "Note that noise robustness implies identifiability, but the converse\n", 
            "is not true in general.\n", 
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "heading", 
          "level": 2, 
          "metadata": {}, 
          "source": [
            "Coherence Criteria\n"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "The simplest criteria for identifiality are based on the coherence of the\n", 
            "matrix $\\Phi$ and depends only on the sparsity $\\norm{x_0}_0$ of the\n", 
            "original signal. This criteria is thus not very precise and gives very pessimistic\n", 
            "bounds.\n", 
            "\n", 
            "\n", 
            "The coherence of the matrix $\\Phi = ( \\phi_i )_{i=1}^N \\in \\RR^{P \\times\n", 
            "N}$ with unit norm colum $\\norm{\\phi_i}=1$ is\n", 
            "$$ \\mu(\\Phi) = \\umax{i \\neq j} \\abs{\\dotp{\\phi_i}{\\phi_j}}. $$\n", 
            "\n", 
            "\n", 
            "\n", 
            "Compute the correlation matrix (remove the diagonal of 1's).\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "remove_diag = lambda C: C-diag(diag(C))\n", 
            "Correlation = lambda Phi: remove_diag(abs(Phi'*Phi))"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Compute the coherence $\\mu(\\Phi)$.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "maxall = lambda C: max(C(:))\n", 
            "mu = lambda Phi: maxall(Correlation(Phi))"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "The condition\n", 
            "$$ \\normz{x_0} < \\frac{1}{2}\\pa{1 + \\frac{1}{\\mu(\\Phi)}} $$\n", 
            "implies that $x_0$ is identifiable, and also implies to robustess to small and bounded noise.\n", 
            "\n", 
            "\n", 
            "Equivalently, this condition can be written as $\\text{Coh}(\\normz{x_0})<1$\n", 
            "where\n", 
            "$$ \\text{Coh}(k) = \\frac{k \\mu(\\Phi)}{ 1 - (k-1)\\mu(\\Phi) } $$\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "Coh = lambda Phi,k: (k * mu(Phi)) / ( 1 - (k-1) * mu(Phi) )"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Generate a matrix with random unit columns in $\\RR^P$.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "normalize = lambda Phi:  Phi ./ repmat(sqrt(sum(Phi.^2)), [size(Phi,1) 1])\n", 
            "PhiRand = lambda P,N: normalize(randn(P,N))\n", 
            "Phi = PhiRand(250,1000)"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Compute the coherence and the maximum possible sparsity to ensure\n", 
            "recovery using the coherence bound.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "c = mu(Phi)\n", 
            "fprintf('Coherence:    %.2f\\n', c)\n", 
            "fprintf('Sparsity max: %d\\n', floor(1/2*(1+1/c)) )"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "heading", 
          "level": 3, 
          "metadata": {}, 
          "source": [
            "Exercise 1"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "Display how the average coherence of a random matrix\n", 
            "decays with the redundancy $\\eta = P/N$ of\n", 
            "the matrix $\\Phi$. Can you derive an empirical law between\n", 
            "$P$ and the maximal sparsity?\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "h = plot(eta_list, k_mean ); set(h, 'LineWidth', 2);\n", 
            "xlabel('\\eta'); ylabel('1/2(1+1/E(\\mu))');\n", 
            "\n", 
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "## Insert your code here."
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "heading", 
          "level": 2, 
          "metadata": {}, 
          "source": [
            "Support and Sign-based Criteria\n"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "In the following we will consider the support\n", 
            "$$ \\text{supp}(x_0) = \\enscond{i}{x_0(i) \\neq 0} $$\n", 
            "of the vector $x_0$. The co-support is its complementary $I^c$.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "supp   = lambda s: find(abs(s)>1e-5)\n", 
            "cosupp = lambda s: find(abs(s)<1e-5)"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Given some support $ I \\subset \\{0,\\ldots,N-1\\} $, we will denote as\n", 
            "$ \\Phi = (\\phi_m)_{m \\in I} \\in \\RR^{N \\times \\abs{I}}$ the\n", 
            "sub-matrix extracted from $\\Phi$ using the columns indexed by $I$.\n", 
            "\n", 
            "\n", 
            "J.J. Fuchs introduces a criteria $F$ for identifiability that depends on the\n", 
            "sign of $x_0$.\n", 
            "\n", 
            "\n", 
            "J.J. Fuchs. _Recovery of exact sparse representations in the presence of\n", 
            "bounded noise._ IEEE Trans. Inform. Theory, 51(10), p. 3601-3608, 2005\n", 
            "\n", 
            "\n", 
            "Under the condition that $\\Phi_I$ has full rank, the $F$ measure\n", 
            "of a sign vector $s \\in \\{+1,0,-1\\}^N$ with $\\text{supp}(s)=I$ reads\n", 
            "$$ \\text{F}(s) = \\norm{ \\Psi_I s_I }_\\infty\n", 
            "      \\qwhereq \\Psi_I = \\Phi_{I^c}^* \\Phi_I^{+,*} $$\n", 
            "where $ A^+ = (A^* A)^{-1} A^* $ is the pseudo inverse of a\n", 
            "matrix $A$.\n", 
            "\n", 
            "\n", 
            "The condition\n", 
            "$$ \\text{F}(\\text{sign}(x_0))<1 $$\n", 
            "implies that $x_0$ is identifiable, and also implies to robustess to\n", 
            "small noise. It does not however imply robustess to a bounded noise.\n", 
            "\n", 
            "\n", 
            "Compute $\\Psi_I$ matrix.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "PsiI = lambda Phi,I: Phi(:, setdiff(1:size(Phi,2),I) )' * pinv(Phi(:,I))'"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Compute $\\text{F}(s)$.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "F = lambda Phi,s: norm(PsiI(Phi,supp(s))*s(supp(s)), 'inf')"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "The Exact Recovery Criterion (ERC) of a support $I$,\n", 
            "introduced by Tropp in\n", 
            "\n", 
            "\n", 
            "J. A. Tropp. _Just relax: Convex programming methods for identifying\n", 
            "sparse signals._ IEEE Trans. Inform. Theory, vol. 52, num. 3, pp. 1030-1051, Mar. 2006.\n", 
            "\n", 
            "\n", 
            "Under the condition that $\\Phi_I$ has full rank, this condition reads\n", 
            "$$ \\text{ERC}(I) = \\norm{\\Psi_{I}}_{\\infty,\\infty}\n", 
            "      =  \\umax{j \\in I^c} \\norm{ \\Phi_I^+ \\phi_j }_1. $$\n", 
            "where $\\norm{A}_{\\infty,\\infty}$ is the $\\ell^\\infty-\\ell^\\infty$\n", 
            "operator norm of a matrix $A$,\n", 
            "computed with the Matlab command |norm(A,'inf')|.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "erc = lambda Phi,I: norm(PsiI(Phi,I), 'inf')"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "The condition\n", 
            "$$ \\text{ERC}(\\text{supp}(x_0))<1 $$\n", 
            "implies that $x_0$ is identifiable, and also implies to robustess to\n", 
            "small and bounded noise.\n", 
            "\n", 
            "\n", 
            "One can prove that the ERC is the maximum of the F criterion for all signs of the given\n", 
            "support\n", 
            "$$ \\text{ERC}(I) = \\umax{ s, \\text{supp}(s) \\subset I } \\text{F}(s). $$\n", 
            "\n", 
            "\n", 
            "The weak-ERC is an approximation of the ERC using only the correlation\n", 
            "matrix\n", 
            "$$ \\text{w-ERC}(I) = \\frac{\n", 
            "      \\umax{j \\in I^c} \\sum_{i \\in I} \\abs{\\dotp{\\phi_i}{\\phi_j}}\n", 
            " }{\n", 
            "      1-\\umax{j \\in I} \\sum_{i \\neq j \\in I} \\abs{\\dotp{\\phi_i}{\\phi_j}}\n", 
            " }$$\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "g = lambda C,I: sum(C(:,I),2)\n", 
            "werc_g = lambda g,I,J: max(g(J)) / (1-max(g(I)))\n", 
            "werc = lambda Phi,I: werc_g( g(Correlation(Phi),I), I, setdiff(1:size(Phi,2),I) )"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "One has, if $\\text{w-ERC}(I)>0$,  for $ I = \\text{supp}(s) $,\n", 
            "$$ \\text{F}(s) \\leq \\text{ERC}(I) \\leq \\text{w-ERC}(I) \\leq\n", 
            "      \\text{Coh}(\\abs{I}).$$\n", 
            "\n", 
            "\n", 
            "This shows in particular that the condition\n", 
            "$$ \\text{w-ERC}(\\text{supp}(x_0))<1 $$\n", 
            "implies identifiability and robustess to small and bounded noise.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "heading", 
          "level": 3, 
          "metadata": {}, 
          "source": [
            "Exercise 2"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "Show that this inequality holds on a given matrix.\n", 
            "What can you conclude about the sharpness of these criteria ?\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "## Insert your code here."
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "heading", 
          "level": 3, 
          "metadata": {}, 
          "source": [
            "Exercise 3"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "For a given matrix $\\Phi$ generated using |PhiRand|, draw as a function of the sparsity $k$\n", 
            "the probability that a random sign vector $s$ of sparsity\n", 
            "$\\norm{s}_0=k$ satisfies the conditions $\\text{F}(x_0)<1$,\n", 
            "$\\text{ERC}(x_0)<1$ and $\\text{w-ERC}(x_0)<1$\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "## Insert your code here."
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "heading", 
          "level": 2, 
          "metadata": {}, 
          "source": [
            "Restricted Isometry Criteria\n"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "The restricted isometry constants $\\de_k^1,\\de_k^2$ of a matrix $\\Phi$ are the\n", 
            "smallest $\\de^1,\\de^2$ that satisfy\n", 
            "$$ \\forall x \\in \\RR^N, \\quad \\norm{x}_0 \\leq k \\qarrq\n", 
            "      (1-\\de^1)\\norm{x}^2 \\leq \\norm{\\Phi x}^2 \\leq (1+\\de^2)\\norm{x}^2.  $$\n", 
            "\n", 
            "\n", 
            "E. Candes shows in\n", 
            "\n", 
            "\n", 
            "E. J. Cands. _The restricted isometry property and its implications for\n", 
            "compressed sensing_. Compte Rendus de l'Academie des Sciences, Paris, Serie I, 346 589-592\n", 
            "\n", 
            "\n", 
            "that if\n", 
            "$$ \\de_{2k} \\leq \\sqrt{2}-1 ,$$\n", 
            "then $\\norm{x_0} \\leq k$ implies identifiability as well as robustness to small and bounded noise.\n", 
            "\n", 
            "\n", 
            "The stability constant $\\la^1(A), \\la^2(A)$ of a matrix\n", 
            "$A = \\Phi_I$ extracted from $\\Phi$ is the smallest $\\tilde \\la_1,\\tilde \\la_2$ such that\n", 
            "$$ \\forall \\al \\in \\RR^{\\abs{I}}, \\quad\n", 
            "      (1-\\tilde\\la_1)\\norm{\\al}^2 \\leq \\norm{A \\al}^2 \\leq (1+\\tilde \\la_2)\\norm{\\al}^2.  $$\n", 
            "\n", 
            "\n", 
            "These constants $\\la^1(A), \\la^2(A)$ are easily computed from the\n", 
            "largest and smallest eigenvalues of $A^* A \\in \\RR^{\\abs{I} \\times \\abs{I}}$\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "minmax = lambda v: deal(1-min(v),max(v)-1)\n", 
            "ric = lambda A: minmax(eig(A'*A))"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "The restricted isometry constant of $\\Phi$ are computed as the largest\n", 
            "stability constants of extracted matrices\n", 
            "$$ \\de^\\ell_k = \\umax{ \\abs{I}=k } \\la^\\ell( \\Phi_I ).  $$\n", 
            "\n", 
            "\n", 
            "The eigenvalues of $\\Phi$ are essentially contained in the\n", 
            "interval $ [a,b] $ where $a=(1-\\sqrt{\\be})^2$ and $b=(1+\\sqrt{\\be})^2$\n", 
            "with $\\beta = k/P$\n", 
            "More precisely, as $k=\\be P$ tends to infinity, the distribution of the\n", 
            "eigenvalues tends to the Marcenko-Pastur law\n", 
            "$ f_\\be(\\la) = \\frac{1}{2\\pi \\be \\la}\\sqrt{ (\\la-b)^+ (a-\\la)^+ }. $\n", 
            ""
          ]
        }, 
        {
          "cell_type": "heading", 
          "level": 3, 
          "metadata": {}, 
          "source": [
            "Exercise 4"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "Display, for an increasing value of $k$ the histogram of repartition\n", 
            "of the eigenvalues $A^* A$ where $A$ is a Gaussian matrix of size $(P,k)$ and\n", 
            "variance $1/P$. For this, accumulate the eigenvalues for many\n", 
            "realization of $A$.\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "## Insert your code here."
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "heading", 
          "level": 3, 
          "metadata": {}, 
          "source": [
            "Exercise 5"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "Estimate numerically lower bound on $\\de_k^1,\\de_k^2$ by Monte-Carlo\n", 
            "sampling of sub-matrices.\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "## Insert your code here."
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "heading", 
          "level": 2, 
          "metadata": {}, 
          "source": [
            "Sparse Spikes Deconvolution\n"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "We now consider a convolution dictionary $ \\Phi $.\n", 
            "Such a dictionary is used with sparse regulariz\n", 
            "\n", 
            "\n", 
            "Second derivative of Gaussian kernel $g$ with a given variance $\\si^2$.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "sigma = 6\n", 
            "g = lambda x: (1-x.^2/sigma^2).*exp(-x.^2/(2*sigma^2))"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Create a matrix $\\Phi$ so that $\\Phi x = g \\star x$ with periodic\n", 
            "boundary conditions.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "P = 1024\n", 
            "[Y,X] = meshgrid(1:P,1:P)\n", 
            "Phi = normalize(g(mod(X-Y+P/2, P)-P/2))"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "To improve the conditionning of the dictionary, we sub-sample its atoms,\n", 
            "so that $ P = \\eta N > N $.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "eta = 2\n", 
            "N = P/eta\n", 
            "Phi = Phi(:,1:eta:end)"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Plot the correlation function associated to the filter.\n", 
            "Can you determine the value of the coherence $\\mu(\\Phi)$?\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "c = Phi'*Phi\n", 
            "c = abs(c(:,end/2))\n", 
            "\n", 
            "h = plot(c(end/2-50:end/2+50), '.-'); set(h, 'LineWidth', 1)\n", 
            "axis tight"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Create a data a sparse $x_0$ with two diracs of opposite signes with spacing $d$.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "twosparse = lambda d: circshift([1; zeros(d,1); -1; zeros(N-d-2,1)], round(N/2-d/2))"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Display $x_0$ and $\\Phi x_0$.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "x0 = twosparse(50)\n", 
            "\n", 
            "subplot(2,1,1)\n", 
            "h = plot(x0, 'r'); axis tight\n", 
            "subplot(2,1,2)\n", 
            "h = plot(Phi*x0, 'b'); axis tight\n", 
            "set(h, 'LineWidth', 2)"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "heading", 
          "level": 3, 
          "metadata": {}, 
          "source": [
            "Exercise 6"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "Plot the evolution of the criteria F, ERC and Coh as a function of $d$.\n", 
            "Do the same plot for other signs patterns for $x_0$.\n", 
            "Do the same plot for a Dirac comb with a varying spacing $d$.\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "## Insert your code here."
          ], 
          "language": "python", 
          "outputs": []
        }
      ]
    }
  ]
}