{
  "metadata": {
    "name": ""
  }, 
  "nbformat": 3, 
  "nbformat_minor": 0, 
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading", 
          "level": 1, 
          "metadata": {}, 
          "source": [
            "Conjugate Gradient"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "This tour explores the use of the conjugate gradient method for the\n", 
            "solution of large scale symmetric linear systems.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "*Important:* You need to download the file `nt_toolbox.py` from the \n", 
            "root of the github repository.\n", 
            "$\\newcommand{\\dotp}[2]{\\langle #1, #2 \\rangle}\n", 
            "\\newcommand{\\enscond}[2]{\\lbrace #1, #2 \\rbrace}\n", 
            "\\newcommand{\\pd}[2]{ \\frac{ \\partial #1}{\\partial #2} }\n", 
            "\\newcommand{\\umin}[1]{\\underset{#1}{\\min}\\;}\n", 
            "\\newcommand{\\norm}[1]{\\|#1\\|}\n", 
            "\\newcommand{\\abs}[1]{\\left|#1\\right|}\n", 
            "\\newcommand{\\choice}[1]{ \\left\\{  \\begin{array}{l} #1 \\end{array} \\right. }\n", 
            "\\newcommand{\\pa}[1]{\\left(#1\\right)}\n", 
            "\\newcommand{\\qandq}{\\quad\\text{and}\\quad}\n", 
            "\\newcommand{\\qwhereq}{\\quad\\text{where}\\quad}\n", 
            "\\newcommand{\\qifq}{ \\quad \\text{if} \\quad }\n", 
            "\\newcommand{\\qarrq}{ \\quad \\Longrightarrow \\quad }\n", 
            "\\newcommand{\\ZZ}{\\mathbb{Z}}\n", 
            "\\newcommand{\\RR}{\\mathbb{R}}\n", 
            "\\newcommand{\\Nn}{\\mathcal{N}}\n", 
            "\\newcommand{\\Hh}{\\mathcal{H}}\n", 
            "\\newcommand{\\Bb}{\\mathcal{B}}\n", 
            "\\newcommand{\\EE}{\\mathbb{E}}\n", 
            "\\newcommand{\\CC}{\\mathbb{C}}\n", 
            "\\newcommand{\\si}{\\sigma}\n", 
            "\\newcommand{\\al}{\\alpha}\n", 
            "\\newcommand{\\la}{\\lambda}\n", 
            "\\newcommand{\\ga}{\\gamma}\n", 
            "\\newcommand{\\Ga}{\\Gamma}\n", 
            "\\newcommand{\\La}{\\Lambda}\n", 
            "\\newcommand{\\si}{\\sigma}\n", 
            "\\newcommand{\\Si}{\\Sigma}\n", 
            "\\newcommand{\\be}{\\beta}\n", 
            "\\newcommand{\\de}{\\delta}\n", 
            "\\newcommand{\\De}{\\Delta}\n", 
            "\\renewcommand{\\phi}{\\varphi}\n", 
            "\\renewcommand{\\th}{\\theta}\n", 
            "\\newcommand{\\om}{\\omega}\n", 
            "\\newcommand{\\Om}{\\Omega}\n", 
            "$"
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "from nt_toolbox import *", 
            "%matplotlib inline", 
            "%load_ext autoreload", 
            "%autoreload 2"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "heading", 
          "level": 2, 
          "metadata": {}, 
          "source": [
            "Conjugate Gradient to Solve Symmetric Linear Systems\n"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "The conjugate gradient method is an iterative method that is taylored to\n", 
            "solve large  symmetric linear systems $Ax=b$.\n", 
            "\n", 
            "\n", 
            "We first give an example using a full explicit matrix $A$, but one should keep in mind that this method\n", 
            "is efficient especially when the matrix $A$ is sparse or more generally when it is fast\n", 
            "to apply $A$ to a vector. This is usually the case in image processing, where $A$\n", 
            "is often composed of convolution, fast transform (wavelet, fourier) or\n", 
            "diagonal operator (e.g. for inpainting).\n", 
            "\n", 
            "\n", 
            "One initializes the CG method as\n", 
            "$$ x_0 \\in \\RR^N, \\quad r_0 = b - x_0, \\quad p_0 = r_0 $$\n", 
            "The iterations of the method reads\n", 
            "$$\n", 
            "   \\choice{\n", 
            "   \\alpha_k = \\frac{ \\dotp{r_k}{r_k} }{ \\dotp{p_k}{A p_k} } \\\\\n", 
            "   x_{k+1} = x_k + \\alpha_k p_k         \\\\\n", 
            "   r_{k+1} = r_k - \\alpha_k A p_k       \\\\\n", 
            "   \\beta_k = \\frac{ \\dotp{r_{k+1}}{r_{k+1}} }{ \\dotp{r_k}{r_k} }   \\\\\n", 
            "   p_{k+1} = r_k + \\beta_k p_k\n", 
            "   }\n", 
            "$$\n", 
            "\n", 
            "\n", 
            "\n", 
            "Note that one has $r_k = b - Ax_k$ which is the residual at iteration\n", 
            "$k$. One can thus stop the method when $\\norm{r_k}$ is smaller than\n", 
            "some user-defined threshold.\n", 
            "\n", 
            "\n", 
            "Dimension of the problem.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "n = 500"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Matrix $A$ of the linear system. We use here a random positive symmetric matrix and\n", 
            "shift its diagonal to make it well conditionned.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "A = randn(n)\n", 
            "A = A*A' + .1*eye(n)"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Right hand side of the linear system. We use here a random vector.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "b = randn(n,1)"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Canonical inner product in $\\RR^N$.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "dotp = lambda a,b: sum(a(:).*b(:))"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "heading", 
          "level": 3, 
          "metadata": {}, 
          "source": [
            "Exercise 1"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "Implement the conjugate gradient method, and monitor the decay of the\n", 
            "energy $\\norm{r_k}=\\norm{Ax_k-b}$.\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "## Insert your code here."
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "heading", 
          "level": 2, 
          "metadata": {}, 
          "source": [
            "Gradient and Divergence of Images\n"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "Local differential operators like gradient, divergence and laplacian are\n", 
            "the building blocks for variational image processing.\n", 
            "\n", 
            "\n", 
            "Load an image $g \\in \\RR^N$ of $N=n \\times n$ pixels.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "n = 256\n", 
            "g = rescale( load_image('lena',n) )"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Display it.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "\n", 
            "imageplot(g)"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "For continuous functions, the gradient reads\n", 
            "$$ \\nabla g(x) = \\pa{ \\pd{g(x)}{x_1}, \\pd{g(x)}{x_2} } \\in \\RR^2. $$\n", 
            "(note that here, the variable $x$ denotes the 2-D spacial position).\n", 
            "\n", 
            "\n", 
            "We discretize this differential operator using first order finite\n", 
            "differences.\n", 
            "$$ (\\nabla g)_i = ( g_{i_1,i_2}-g_{i_1-1,i_2}, g_{i_1,i_2}-g_{i_1,i_2-1} ) \\in \\RR^2. $$\n", 
            "Note that for simplity we use periodic boundary conditions.\n", 
            "\n", 
            "\n", 
            "Compute its gradient, using finite differences.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "s = [n 1:n-1]\n", 
            "grad = lambda f: cat(3, f-f(s,:), f-f(:,s))"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "One thus has $ \\nabla : \\RR^N \\mapsto \\RR^{N \\times 2}. $\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "v = grad(g)"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "One can display each of its components.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "\n", 
            "imageplot(v(:,:,1), 'd/dx', 1,2,1)\n", 
            "imageplot(v(:,:,2), 'd/dy', 1,2,2)"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "One can also display it using a color image.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "\n", 
            "imageplot(v)"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "One can display its magnitude $\\norm{\\nabla g(x)}$, which is large near edges.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "\n", 
            "imageplot( sqrt( sum3(v.^2,3) ) )"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "The divergence operator maps vector field to images.\n", 
            "For continuous vector fields $v(x) \\in \\RR^2$, it is defined as\n", 
            "$$ \\text{div}(v)(x) = \\pd{v_1(x)}{x_1} +  \\pd{v_2(x)}{x_2} \\in \\RR. $$\n", 
            "(note that here, the variable $x$ denotes the 2-D spacial position).\n", 
            "It is minus the adjoint of the gadient, i.e. $\\text{div} = - \\nabla^*$.\n", 
            "\n", 
            "\n", 
            "It is discretized, for $v=(v^1,v^2)$ as\n", 
            "$$ \\text{div}(v)_i = v^1_{i_1+1,i_2} - v^1_{i_1,i_2} + v^2_{i_1,i_2+1} - v^2_{i_1,i_2} . $$\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "t = [2:n 1]\n", 
            "div = lambda v: v(t,:,1)-v(:,:,1) + v(:,t,2)-v(:,:,2)"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "\n", 
            "The Laplacian operatore is defined as $\\Delta=\\text{div} \\circ  \\nabla =\n", 
            "-\\nabla^* \\circ \\nabla$. It is thus a negative symmetric operator.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "delta = lambda f: div(grad(f))"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Display $\\Delta f_0$.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "\n", 
            "imageplot(delta(g))"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "\n", 
            "Check that the relation $ \\norm{\\nabla f} = - \\dotp{\\Delta f}{f}.  $\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "dotp = lambda a,b: sum(a(:).*b(:))\n", 
            "fprintf('Should be 0: %.3i\\n', dotp(grad(g), grad(g)) + dotp(delta(g),g) )"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "heading", 
          "level": 2, 
          "metadata": {}, 
          "source": [
            "Conjugate Gradient for Lagrangian Inpainting\n"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "We consider here the inpainting problem, which corresponds to the\n", 
            "interpolation of missing data in the image.\n", 
            "\n", 
            "\n", 
            "We define a binary mask $M \\in \\RR^N$ where $M_i=0$ if the pixel indexed\n", 
            "by $i$ is missing, and $M_i=1$  otherwise.\n", 
            "We consider here random missing pixel, and a large missing region in the\n", 
            "upper left corner.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "M = rand(n)>.7\n", 
            "w = 30\n", 
            "M(end/4-w:end/4+w,end/4-w:end/4+w) = 0"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Define the degradation operator $\\Phi : \\RR^N \\rightarrow \\RR^N$, that\n", 
            "corresponds to the masking with $M$, i.e. a diagonal operator\n", 
            "$$ \\Phi = \\text{diag}_i(M_i). $$\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "Phi = lambda x: M.*x"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Compute the observations $y = \\Phi(x)$ with damaged pixels.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "y = Phi(g)"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Display the observed image.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "\n", 
            "imageplot(y)"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "To perform the recovery of an image from the damaged observations $y$,\n", 
            "we aim at finding an image $x$ that agrees as much with the\n", 
            "measurements, i.e. $\\Phi x \\approx y$, but at the same time is smooth.\n", 
            "We measure the smoothness using the norm of the gradient $\\norm{\\nabla\n", 
            "x}^2$, which corresponds to a discret Sobolev norm.\n", 
            "\n", 
            "\n", 
            "This leads us to consider the following quadratic minimization problem\n", 
            "$$ \\umin{x \\in \\RR^N} F(x) = \\norm{y-\\Phi x}^2 + \\la \\norm{\\nabla x}^2. $$\n", 
            "\n", 
            "\n", 
            "This problem as a unique solution if\n", 
            "$\\text{ker}(\\Phi) \\cap \\text{ker}(\\nabla) = \\{0\\}$. This condition\n", 
            "holds in our case since $\\text{ker}(\\nabla)$ is the set of constant\n", 
            "images.\n", 
            "\n", 
            "\n", 
            "The solution can be obtained by solving the following linear system\n", 
            "$$ A x = b \\qwhereq\n", 
            "      \\choice{\n", 
            "          A = \\Phi^*\\Phi - \\la \\Delta, \\\\\n", 
            "          b = \\Phi^* y.\n", 
            "      }\n", 
            "  $$\n", 
            "Here we can remark that for the inpainting problem, $\\Phi^*\\Phi=\\Phi$\n", 
            "and $\\Phi^*y=y$.\n", 
            "\n", 
            "\n", 
            "\n", 
            "The value of the parameter $\\lambda$ should be small.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "lambda = .01"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Operator to invert.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "A = lambda x: Phi(x) - lambda*delta(x)"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Right hand side of the linear system is\n", 
            "$$ b = \\Phi^*(y) = y. $$\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "b = y"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "heading", 
          "level": 3, 
          "metadata": {}, 
          "source": [
            "Exercise 2"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "Implement the conjugate gradient method, and monitor the decay of the\n", 
            "energy $F(x_k)$.\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "## Insert your code here."
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "\n", 
            "Display the result.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "\n", 
            "imageplot(clamp(x))"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "heading", 
          "level": 2, 
          "metadata": {}, 
          "source": [
            "Conjugate Gradient for Constrained Inpainting\n"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "Since there is no noise perturbating the observation, it makes sense to\n", 
            "use a $\\lambda$ that is as small as possible.\n", 
            "\n", 
            "\n", 
            "When $\\lambda \\rightarrow 0$, the problem becomes\n", 
            "$$ \\umin{\\Phi x = y} \\norm{\\nabla x}^2. $$\n", 
            "This problem as a unique solution if $y\\in \\text{Im}(\\Phi)$ and if\n", 
            "$\\text{ker}(\\Phi) \\cap \\text{ker}(\\nabla) = \\{0\\}$. This condition\n", 
            "holds in our case, as we have already seen.\n", 
            "\n", 
            "\n", 
            "Introducing Lagrange multiplizers $u \\in \\RR^N$, this problem is\n", 
            "equivalent to the resolution of the following couple of linear equations\n", 
            "$$ \\choice{\n", 
            "      -\\Delta x + \\Phi^* u = 0, \\\\\n", 
            "      \\Phi x = y.\n", 
            "  } $$\n", 
            "\n", 
            "\n", 
            "This corresponds to a single linear system over $z = (x,u) \\in \\RR^{N}\n", 
            "\\times \\RR^N \\sim \\RR^{N \\times 2}$\n", 
            "$$ A z = b \\qwhereq\n", 
            "      A = \\begin{pmatrix} -\\Delta & \\Phi^* \\\\ \\Phi & 0 \\end{pmatrix}\n", 
            "  \\qandq\n", 
            "  b = \\begin{pmatrix} 0 \\\\ y \\end{pmatrix}\n", 
            " $$\n", 
            "\n", 
            "\n", 
            "Define the operator $A$. Note that $x$ is encoded in |z(:,:,1)|\n", 
            "and $u$ in |z(:,:,2)|.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "A = lambda z: cat(3, -delta(z(:,:,1)) + Phi(z(:,:,2)), Phi(z(:,:,1)) )"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "Define the right hand side $b$.\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "b = cat(3, zeros(n), y)"
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "heading", 
          "level": 3, 
          "metadata": {}, 
          "source": [
            "Exercise 3"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "Implement the conjugate gradient method, and monitor the decay of the\n", 
            "energy $F(x_k)) = \\norm{\\nabla x_k}$\n", 
            "and the constraint $C(x_k) = \\norm{y-\\Phi x_k}^2$.\n", 
            "_Important:_ be carefull at the initialization of the method.\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            "\n", 
            ""
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "## Insert your code here."
          ], 
          "language": "python", 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n", 
            "\n", 
            "\n", 
            "Display the result.\n", 
            ""
          ]
        }
      ]
    }
  ]
}