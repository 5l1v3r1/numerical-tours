{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary Learning\n",
    "===================\n",
    "\n",
    "*Important:* Please read the [installation page](http://gpeyre.github.io/numerical-tours/installation_python/) for details about how to install the toolboxes.\n",
    "$\\newcommand{\\dotp}[2]{\\langle #1, #2 \\rangle}$\n",
    "$\\newcommand{\\enscond}[2]{\\lbrace #1, #2 \\rbrace}$\n",
    "$\\newcommand{\\pd}[2]{ \\frac{ \\partial #1}{\\partial #2} }$\n",
    "$\\newcommand{\\umin}[1]{\\underset{#1}{\\min}\\;}$\n",
    "$\\newcommand{\\umax}[1]{\\underset{#1}{\\max}\\;}$\n",
    "$\\newcommand{\\umin}[1]{\\underset{#1}{\\min}\\;}$\n",
    "$\\newcommand{\\uargmin}[1]{\\underset{#1}{argmin}\\;}$\n",
    "$\\newcommand{\\norm}[1]{\\|#1\\|}$\n",
    "$\\newcommand{\\abs}[1]{\\left|#1\\right|}$\n",
    "$\\newcommand{\\choice}[1]{ \\left\\{  \\begin{array}{l} #1 \\end{array} \\right. }$\n",
    "$\\newcommand{\\pa}[1]{\\left(#1\\right)}$\n",
    "$\\newcommand{\\diag}[1]{{diag}\\left( #1 \\right)}$\n",
    "$\\newcommand{\\qandq}{\\quad\\text{and}\\quad}$\n",
    "$\\newcommand{\\qwhereq}{\\quad\\text{where}\\quad}$\n",
    "$\\newcommand{\\qifq}{ \\quad \\text{if} \\quad }$\n",
    "$\\newcommand{\\qarrq}{ \\quad \\Longrightarrow \\quad }$\n",
    "$\\newcommand{\\ZZ}{\\mathbb{Z}}$\n",
    "$\\newcommand{\\CC}{\\mathbb{C}}$\n",
    "$\\newcommand{\\RR}{\\mathbb{R}}$\n",
    "$\\newcommand{\\EE}{\\mathbb{E}}$\n",
    "$\\newcommand{\\Zz}{\\mathcal{Z}}$\n",
    "$\\newcommand{\\Ww}{\\mathcal{W}}$\n",
    "$\\newcommand{\\Vv}{\\mathcal{V}}$\n",
    "$\\newcommand{\\Nn}{\\mathcal{N}}$\n",
    "$\\newcommand{\\NN}{\\mathcal{N}}$\n",
    "$\\newcommand{\\Hh}{\\mathcal{H}}$\n",
    "$\\newcommand{\\Bb}{\\mathcal{B}}$\n",
    "$\\newcommand{\\Ee}{\\mathcal{E}}$\n",
    "$\\newcommand{\\Cc}{\\mathcal{C}}$\n",
    "$\\newcommand{\\Gg}{\\mathcal{G}}$\n",
    "$\\newcommand{\\Ss}{\\mathcal{S}}$\n",
    "$\\newcommand{\\Pp}{\\mathcal{P}}$\n",
    "$\\newcommand{\\Ff}{\\mathcal{F}}$\n",
    "$\\newcommand{\\Xx}{\\mathcal{X}}$\n",
    "$\\newcommand{\\Mm}{\\mathcal{M}}$\n",
    "$\\newcommand{\\Ii}{\\mathcal{I}}$\n",
    "$\\newcommand{\\Dd}{\\mathcal{D}}$\n",
    "$\\newcommand{\\Ll}{\\mathcal{L}}$\n",
    "$\\newcommand{\\Tt}{\\mathcal{T}}$\n",
    "$\\newcommand{\\si}{\\sigma}$\n",
    "$\\newcommand{\\al}{\\alpha}$\n",
    "$\\newcommand{\\la}{\\lambda}$\n",
    "$\\newcommand{\\ga}{\\gamma}$\n",
    "$\\newcommand{\\Ga}{\\Gamma}$\n",
    "$\\newcommand{\\La}{\\Lambda}$\n",
    "$\\newcommand{\\si}{\\sigma}$\n",
    "$\\newcommand{\\Si}{\\Sigma}$\n",
    "$\\newcommand{\\be}{\\beta}$\n",
    "$\\newcommand{\\de}{\\delta}$\n",
    "$\\newcommand{\\De}{\\Delta}$\n",
    "$\\newcommand{\\phi}{\\varphi}$\n",
    "$\\newcommand{\\th}{\\theta}$\n",
    "$\\newcommand{\\om}{\\omega}$\n",
    "$\\newcommand{\\Om}{\\Omega}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using a fixed data representation such as wavelets or Fourier,\n",
    "one can learn the representation (the dictionary) to optimize the\n",
    "sparsity of the representation for a large class of exemplar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from nt_toolbox.signal import load_image, imageplot, plot_dictionary\n",
    "from nt_toolbox.general import crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary Learning as a Non-convex Optimization Problem\n",
    "--------------------------------------------------------\n",
    "Given a set $Y = (y_j)_{j=1}^m \\in \\RR^{n \\times m} $ of $m$ signals\n",
    "$y_j \\in \\RR^m$, dictionary learning aims at finding the best\n",
    "dictionary $D=(d_i)_{i=1}^p$ of $p$ atoms $d_i \\in \\RR^n$ to sparse\n",
    "code all the data.\n",
    "\n",
    "\n",
    "In this numerical tour, we consider an application to image denoising, so\n",
    "that each $y_j \\in \\RR^n$ is a patch of size $n=w \\times w$ extracted\n",
    "from the noisy image.\n",
    "\n",
    "\n",
    "The idea of learning dictionaries to sparse code image patch was first\n",
    "proposed in:\n",
    "\n",
    "\n",
    "Olshausen BA, and Field DJ.,\n",
    "<http://www.nature.com/nature/journal/v381/n6583/abs/381607a0.html Emergence of Simple-Cell Receptive Field Properties by Learning a Sparse Code for Natural Images.>\n",
    "Nature, 381: 607-609, 1996.\n",
    "\n",
    "\n",
    "The sparse coding of a single data $y=y_j$ for some $j=1,\\ldots,m$\n",
    "is obtained by minimizing a $\\ell^0$ constrained optimization\n",
    "$$ \\umin{ \\norm{x}_0 \\leq k } \\frac{1}{2}\\norm{y-Dx}^2 .  $$\n",
    "where the $\\ell^0$ pseudo-norm of $x \\in \\RR^p$ is\n",
    "$$ \\norm{x}_0 = \\abs{\\enscond{i}{x(i) \\neq 0}}. $$\n",
    "\n",
    "\n",
    "The parameter $k>0$ controls the amount of sparsity.\n",
    "\n",
    "\n",
    "Dictionary learning performs an optimization both on the dictionary $D$\n",
    "and the set of coefficients $ X = (x_j)_{j=1}^m \\in \\RR^{p \\times m} $\n",
    "where, for $j=1,\\ldots,m$, $ x_j $\n",
    "is the set of coefficients of the data $y_j$. This joint optimization reads\n",
    "$$ \\umin{ D \\in \\Dd, X \\in \\Xx_k } E(X,D) = \\frac{1}{2}\\norm{Y-DX}^2 =\n",
    "\\frac{1}{2} \\sum_{j=1}^m \\norm{y_j - D x_j}^2. $$\n",
    "\n",
    "\n",
    "The constraint set on $D$ reads\n",
    "$$ \\Dd = \\enscond{D \\in \\RR^{n \\times p} }{\n",
    "      \\forall i=1,\\ldots,p, \\quad \\norm{D_{\\cdot,i}} \\leq 1  }, $$\n",
    "(the columns of the dictionary are unit normalized).\n",
    "The sparsity constraint set on $X$ reads\n",
    "$$ \\Xx_k = \\enscond{X \\in \\RR^{p \\times m}}{ \\forall j, \\: \\norm{X_{\\cdot,j}}_0 \\leq k }. $$\n",
    "\n",
    "\n",
    "We propose to use a block-coordinate descent method to minimize $E$:\n",
    "$$ X^{(\\ell+1)} \\in \\uargmin{X \\in \\Xx_k} E(X,D^{(\\ell)}), $$\n",
    "$$ D^{(\\ell+1)} \\in \\uargmin{D \\in \\Dd} E(X^{(\\ell+1)},D). $$\n",
    "\n",
    "\n",
    "One can show the convergence of this minimization scheme, see for\n",
    "instance\n",
    "\n",
    "\n",
    "P. Tseng, <http://www.math.washington.edu/~tseng/papers/archive/bcr_jota.pdf Convergence of Block Coordinate Descent Method for Nondifferentiable Minimization>,\n",
    "J. Optim. Theory Appl., 109, 2001, 475-494.\n",
    "\n",
    "\n",
    "We now define the parameter of the problem.\n",
    "\n",
    "\n",
    "Width $w$ of the patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimension $n= w \\times w$ of the data to be sparse coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = w*w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of atoms $p$ in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = 2*n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number $m$ of patches used for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = 20*p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target sparsity $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patch Extraction\n",
    "----------------\n",
    "Since the learning is computationnaly intensive, one can only apply it to\n",
    "small patches extracted from an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = crop(load_image(\"nt_toolbox/data/barb.bmp\"), 256)\n",
    "n0 = f.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "imageplot(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random patch location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = 3*m\n",
    "\n",
    "# Random sampling of coordinates of the top left corner or the patches\n",
    "x = (np.random.random((1, 1, q))*(n0-w)).astype(int)\n",
    "y = (np.random.random((1, 1, q))*(n0-w)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract lots of patches $y_j \\in \\RR^n$, and store them in a matrix $Y=(y_j)_{j=1}^m$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[dY, dX] = np.meshgrid(range(w), range(w))\n",
    "dX = np.tile(dX, (q, 1, 1)).transpose((1, 2, 0))\n",
    "dY = np.tile(dY, (q, 1, 1)).transpose((1, 2, 0))\n",
    "Xp = np.tile(x, (w, w, 1)) + dX\n",
    "Yp = dY + np.tile(y, (w, w, 1))\n",
    "\n",
    "# Extract patches\n",
    "Y = f.flatten()[Yp+Xp*n0]\n",
    "Y = Y.reshape((w*w, q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the mean, since we are going to learn a dictionary of\n",
    "zero-mean and unit norm atom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y -= Y.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep those with largest energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "energies = np.sum(Y**2, axis=0)\n",
    "indexes = np.argsort(energies)[::-1]\n",
    "Y = Y[:, indexes[:m]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a dictionary $D \\in \\RR^{n \\times p} $ of $p \\geq n$ atoms in $\\RR^n$.\n",
    "The initial dictionary $D$ is computed by a random selection of patches, and we normalize them to be unit-norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def projC(Y):\n",
    "    ''' Scale the patches to unit norm '''\n",
    "    norm = np.tile(np.linalg.norm(Y, axis=0), (Y.shape[0], 1))\n",
    "    Y = np.divide(Y, norm)\n",
    "    return  Y \n",
    "\n",
    "# Pick p indexes at random to pick patches from Y\n",
    "sel = np.random.permutation(range(m))[:p]\n",
    "D = projC(Y[:, sel])\n",
    "D0 = D.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the initial dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plot_dictionary(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update of the Coefficients $X$\n",
    "--------------------------------\n",
    "The optimization on the coefficients $X$ requires, for each $y_j =\n",
    "Y_{\\cdot,j}$ to compute $x_j = X_{\\cdot,j}$ that solves\n",
    "$$ \\umin{ \\norm{x_j}_0 \\leq k } \\frac{1}{2} \\norm{y-D x_j}^2. $$\n",
    "\n",
    "\n",
    "This is a non-smooth and non-convex minimization, that can be shown to be\n",
    "NP-hard. A heuristic to solve this method is to compute a stationary\n",
    "point of the energy using the Foward-Backward iterative scheme (projected gradient descent):\n",
    "$$ x_j \\leftarrow \\text{Proj}_{\\Xx_k}\\pa{\n",
    "      x_j - \\tau D^* ( D x_j - y )\n",
    "      }$\n",
    "      \\qwhereq \\tau < \\frac{2}{\\norm{D D^*}}. $$\n",
    "\n",
    "\n",
    "Denoting $\\abs{\\bar x(1)} \\leq \\ldots \\leq \\abs{\\bar x(n)}$ the ordered\n",
    "magnitudes of a vector $ x \\in \\RR^n $, the orthogonal projector on\n",
    "$\\Xx_k$ reads $z = \\text{Proj}_{\\Xx_k}(x)$ with\n",
    "$$ \\forall i=1,\\ldots,n, \\quad\n",
    "      z(i) = \\choice{ x(i) \\qifq \\abs{x(i)} \\geq \\abs{\\bar x(k)}, \\\\\n",
    "      z(i) = 0 \\quad \\text{otherwise}.\n",
    "  }$\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def projX(X, k):\n",
    "    ''' Sparsity projection, keeps the k largest coefficients '''\n",
    "    X = X * (abs(X) >= np.sort(abs(X), axis=0)[-k, :])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1__\n",
    "\n",
    "Perform the iterative hard thresholding,\n",
    "and display the decay of the energy $J(x_j) = \\norm{y_j-D x_j}^2$ for several $j$.\n",
    "_Remark:_ note that the iteration can be performed in parallel on all\n",
    "$x_j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run -i nt_solutions/sparsity_4_dictionary_learning/exo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Insert your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the Dictionary $D$\n",
    "---------------------------\n",
    "Once the sparse coefficients $X$ have been computed, one\n",
    "can udpate the dictionary. This is achieve by performing the minimization\n",
    "$$ \\umin{D \\in \\Dd} \\frac{1}{2}\\norm{Y-D X}^2. $$\n",
    "\n",
    "\n",
    "One can perform this minimization with a projected gradient descent\n",
    "$$ D \\leftarrow \\text{Proj}_{\\Cc}\\pa{ D - \\tau (DX - Y)X^* } $$\n",
    "where $ \\tau < 2/\\norm{XX^*}. $\n",
    "\n",
    "\n",
    "Note that the orthogonal projector $\\text{Proj}_{\\Cc}$ is implemented in the function\n",
    "|ProjC| already defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 2__\n",
    "\n",
    "Perform this gradient descent, and monitor the decay of the energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run -i nt_solutions/sparsity_4_dictionary_learning/exo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Insert your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 3__\n",
    "\n",
    "Perform the dictionary learning by iterating between sparse coding and\n",
    "dictionary update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run -i nt_solutions/sparsity_4_dictionary_learning/exo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Insert your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plot_dictionary(D)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
